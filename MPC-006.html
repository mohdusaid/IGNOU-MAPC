<!DOCTYPE html>
<html lang="en" class="dark">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Statistics in Psychology MPC006</title>
  <link href="https://fonts.googleapis.com/css2?family=Merriweather:wght@400;700&family=Open+Sans:wght@400;600;700&display=swap" rel="stylesheet">
  <style>
    /* --- Variables for easy theme switching and consistent palette --- */
    :root {
      /* Base Colors */
      --bg-light: #F0F4F8; /* Soft light background */
      --bg-dark: #1A202C; /* Deep dark background */
      --card-light: #FFFFFF; /* Pure white cards in light mode */
      --card-dark: #2D3748; /* Darker grey for cards in dark mode */
      --text-light: #2C3E50; /* Strong dark text */
      --text-dark: #E2E8F0; /* Off-white text */
      --border-light: #CBD5E0; /* Subtle light border */
      --border-dark: #4A5568; /* Subtle dark border */

      /* Primary Accent (Calming Blue-Green) */
      --primary-accent-light: #3182CE; /* Vibrant Blue */
      --primary-accent-dark: #63B3ED; /* Lighter Blue for contrast on dark */

      /* Secondary Accent (Subtle Green for active/success) */
      --secondary-accent-light: #38A169; /* Medium Green */
      --secondary-accent-dark: #48BB78; /* Lighter Green */

      /* Tertiary Accent (Warm for highlights/warnings) */
      --tertiary-accent-light: #DD6B20; /* Orange */
      --tertiary-accent-dark: #F6AD55; /* Lighter Orange */

      /* Status Colors */
      --status-read-bg-light: #E6FFFA; /* Very light green */
      --status-read-bg-dark: #285E61; /* Dark teal */
      --status-read-border: #38A169;   /* Green */
      --status-read-text-light: #155724; /* Dark green for readability on light */
      --status-read-text-dark: #A7F3D0; /* Light green for readability on dark */

      --status-doubt-bg-light: #FFF5F5; /* Very light red */
      --status-doubt-bg-dark: #7B3432;  /* Dark terracotta */
      --status-doubt-border: #E53E3E;   /* Red */
      --status-doubt-text-light: #721C24; /* Dark red for readability on light */
      --status-doubt-text-dark: #FED7D7; /* Light red for readability on dark */

      --status-unread-btn: #4299E1; /* Blue for unread/default button */

      /* Pie Chart Colors */
      --chart-read-color: #38A169; /* Green */
      --chart-doubt-color: #E53E3E; /* Red */
      --chart-unread-color: #4299E1; /* Blue */

      /* Notes Floater Colors */
      --notes-floater-bg-light: rgba(255, 255, 255, 0.95);
      --notes-floater-bg-dark: rgba(45, 55, 72, 0.95);
      --notes-floater-border-color: #805AD5; /* Deep Purple */
      --notes-floater-header-bg-light: #805AD5;
      --notes-floater-header-bg-dark: #9F7AEA;

      /* Stats Floater Colors */
      --stats-floater-bg-light: rgba(255, 255, 255, 0.95);
      --stats-floater-bg-dark: rgba(45, 55, 72, 0.95);
      --stats-floater-border-color: #DD6B20; /* Orange */
      --stats-floater-header-bg-light: #DD6B20;
      --stats-floater-header-bg-dark: #F6AD55;
    }

    /* --- Base Styles --- */
    body {
      margin: 0;
      font-family: 'Open Sans', sans-serif; /* Readable sans-serif for body */
      background-color: var(--bg-light);
      color: var(--text-light);
      transition: background-color 0.4s ease, color 0.4s ease;
      line-height: 1.65; /* Improved line height for readability */
      display: flex;
      flex-direction: column;
      min-height: 100vh;
      scroll-behavior: smooth; /* Smooth scrolling for navigation */
    }

    body.dark {
      background-color: var(--bg-dark);
      color: var(--text-dark);
    }

    /* --- Header & Search --- */
    header {
      text-align: center;
      padding: 2.5rem 1.5rem 1.5rem;
      border-bottom: 4px solid var(--primary-accent-light); /* Stronger accent border */
      background: linear-gradient(to right, var(--bg-light) 0%, var(--bg-light) 70%, var(--primary-accent-light) 100%); /* Subtle gradient */
      transition: background 0.4s ease, border-color 0.4s ease;
    }

    body.dark header {
      border-bottom-color: var(--primary-accent-dark);
      background: linear-gradient(to right, var(--bg-dark) 0%, var(--bg-dark) 70%, var(--primary-accent-dark) 100%);
    }

    h1 {
      font-family: 'Merriweather', serif; /* Elegant serif for headings */
      font-size: 3.2rem; /* Larger, more impactful heading */
      margin: 0;
      color: var(--primary-accent-light);
      text-shadow: 1px 1px 2px rgba(0,0,0,0.1);
      transition: color 0.4s ease;
    }

    body.dark h1 {
        color: var(--primary-accent-dark);
        text-shadow: 1px 1px 2px rgba(0,0,0,0.3);
    }

    header p {
      font-size: 1.15rem;
      color: var(--text-light);
      margin-top: 0.75rem;
      opacity: 0.9;
      transition: color 0.4s ease;
    }

    body.dark header p {
      color: var(--text-dark);
    }

    .search-wrapper {
      display: flex;
      justify-content: center;
      margin: 2rem 0;
      padding: 0 1.5rem;
    }

    .search-input {
      padding: 0.9rem 1.4rem;
      width: 100%;
      max-width: 650px;
      font-size: 1.1rem;
      border: 2px solid var(--border-light);
      border-radius: 10px; /* Slightly more rounded */
      box-sizing: border-box;
      background-color: var(--card-light);
      color: var(--text-light);
      box-shadow: inset 0 1px 3px rgba(0,0,0,0.05);
      transition: border-color 0.3s ease, background-color 0.3s ease, color 0.3s ease, box-shadow 0.3s ease;
    }

    .search-input:focus {
        outline: none;
        border-color: var(--primary-accent-light);
        box-shadow: 0 0 0 3px rgba(49, 130, 206, 0.2); /* Focus glow */
    }

    body.dark .search-input {
      border: 2px solid var(--border-dark);
      background-color: #232B38; /* Slightly darker than card-dark */
      color: var(--text-dark);
    }
    body.dark .search-input:focus {
        border-color: var(--primary-accent-dark);
        box-shadow: 0 0 0 3px rgba(99, 179, 237, 0.2);
    }

    /* --- Theme Toggle Button --- */
    .toggle-theme {
      position: fixed;
      top: 1.2rem;
      right: 1.2rem;
      background: none;
      border: none;
      font-size: 1.8rem;
      cursor: pointer;
      color: var(--text-light);
      transition: color 0.3s ease, transform 0.2s ease;
      z-index: 100;
      padding: 5px; /* Make clickable area larger */
    }

    body.dark .toggle-theme {
      color: var(--text-dark);
    }
    .toggle-theme:hover {
        transform: scale(1.1);
    }

    /* --- Topic Cards (Containers for Questions) --- */
    main {
      flex-grow: 1;
      padding: 1rem; /* Overall padding for main content */
    }

    .topic-card {
      background: var(--card-light);
      border-radius: 15px; /* More rounded */
      padding: 1.5rem 2rem; /* Increased padding */
      margin: 1.5rem auto; /* Larger margins */
      max-width: 750px; /* Slightly wider */
      box-shadow: 0 8px 30px rgba(0,0,0,0.1); /* Softer, larger shadow */
      border-left: 8px solid var(--primary-accent-light); /* Thicker accent border */
      transition: transform 0.2s ease-in-out, box-shadow 0.2s ease-in-out, background-color 0.4s ease, border-color 0.4s ease;
      position: relative;
    }

    .topic-card:hover {
      transform: translateY(-7px); /* More pronounced lift */
      box-shadow: 0 12px 40px rgba(0,0,0,0.15); /* More pronounced shadow */
    }

    body.dark .topic-card {
      background: var(--card-dark);
      border-color: var(--primary-accent-dark);
    }

    .topic-card h2 { /* Styling for the main topic heading */
        font-family: 'Merriweather', serif;
        font-size: 2.4rem; /* Larger topic heading */
        margin-top: 0;
        margin-bottom: 1.8rem;
        color: var(--primary-accent-light);
        border-bottom: 2px solid var(--border-light); /* Solid border */
        padding-bottom: 0.8rem;
        transition: color 0.4s ease, border-color 0.4s ease;
    }
    body.dark .topic-card h2 {
        border-bottom-color: var(--border-dark);
        color: var(--primary-accent-dark);
    }

    /* --- Details (Individual Questions) Styling --- */
    .topic-card details {
        margin-bottom: 1.2rem;
        padding: 0.8rem 0; /* More padding around each question */
        border-bottom: 1px solid var(--border-light);
        transition: background-color 0.4s ease, border-color 0.4s ease, transform 0.2s ease;
        position: relative;
    }
    .topic-card details:last-of-type {
        border-bottom: none;
        margin-bottom: 0;
        padding-bottom: 0;
    }
    body.dark .topic-card details {
        border-bottom-color: var(--border-dark);
    }

    /* Status-specific styles for details */
    .topic-card details[data-status="read"] {
        background-color: var(--status-read-bg-light);
        color: var(--status-read-text-light);
        border-left: 6px solid var(--status-read-border);
        padding-left: 1rem; /* Make space for the new border */
    }
    body.dark .topic-card details[data-status="read"] {
        background-color: var(--status-read-bg-dark);
        color: var(--status-read-text-dark);
        border-left-color: var(--status-read-border);
    }
    .topic-card details[data-status="read"] .status-icon {
        color: var(--status-read-border);
    }

    .topic-card details[data-status="doubt"] {
        background-color: var(--status-doubt-bg-light);
        color: var(--status-doubt-text-light);
        border-left: 6px solid var(--status-doubt-border);
        padding-left: 1rem;
    }
    body.dark .topic-card details[data-status="doubt"] {
        background-color: var(--status-doubt-bg-dark);
        color: var(--status-doubt-text-dark);
        border-left-color: var(--status-doubt-border);
    }
    .topic-card details[data-status="doubt"] .status-icon {
        color: var(--status-doubt-border);
    }

    /* Highlighted question (for scroll-to-note) */
    .topic-card details.highlighted {
        box-shadow: 0 0 0 4px var(--notes-floater-border-color); /* Purple glow */
        transform: translateY(-5px);
        background-color: var(--notes-floater-bg-light); /* Make it slightly stand out */
        border-color: var(--notes-floater-border-color);
        transition: box-shadow 0.3s ease-out, transform 0.2s ease-out, background-color 0.2s ease;
    }
    body.dark .topic-card details.highlighted {
        background-color: var(--notes-floater-bg-dark);
        border-color: var(--notes-floater-border-color);
    }


    /* Status icons per question */
    .status-icon {
        position: absolute;
        top: 15px; /* Aligned with summary */
        left: -20px; /* Positioned slightly outside the main padding, near the border */
        font-size: 1.3rem;
        display: none;
        padding: 0 3px;
        border-radius: 4px;
        background-color: inherit; /* Blend with details background */
    }
    .topic-card details[data-status="read"] .status-icon.read,
    .topic-card details[data-status="doubt"] .status-icon.doubt {
        display: block;
    }


    /* Details/Summary (Dropdown) Styles */
    summary {
      cursor: pointer;
      font-weight: 600; /* Slightly bolder */
      font-size: 1.25rem; /* Larger for questions */
      position: relative;
      padding-right: 30px; /* Space for the +/- icon */
      outline: none;
      display: flex;
      align-items: center;
      justify-content: space-between;
      padding-left: 0.5rem; /* Align text within the details padding */
      color: var(--primary-accent-light);
      transition: color 0.3s ease;
    }
    body.dark summary {
        color: var(--primary-accent-dark);
    }

    summary:hover {
        text-decoration: underline;
        color: var(--secondary-accent-light);
    }
    body.dark summary:hover {
        color: var(--secondary-accent-dark);
    }

    summary > span:first-child {
        flex-grow: 1;
        margin-right: 15px;
    }

    summary::-webkit-details-marker {
      display: none;
    }

    /* Icon for +/- toggle */
    summary::before {
      content: "+";
      position: absolute;
      right: 0;
      top: 50%;
      transform: translateY(-50%);
      font-size: 1.8rem; /* Larger toggle icon */
      font-weight: bold;
      color: var(--primary-accent-light);
      transition: transform 0.2s ease, color 0.3s ease;
    }

    details[open] summary::before {
      content: "-";
      color: var(--tertiary-accent-light); /* Orange for open state */
    }
    body.dark details[open] summary::before {
        color: var(--tertiary-accent-dark);
    }

    /* Notes indicator icon within summary */
    .notes-indicator-icon {
        font-size: 1em; /* Matches summary font size better */
        color: var(--notes-floater-border-color); /* Purple to match notes button */
        display: none;
        flex-shrink: 0;
        margin-left: 8px; /* Space from title */
    }
    body.dark .notes-indicator-icon {
        color: var(--notes-floater-header-bg-dark);
    }

    .content {
      padding-top: 1.2rem;
      line-height: 1.75; /* Slightly more relaxed line height */
      font-size: 1.05rem;
      padding-left: 0.5rem;
      color: var(--text-light);
      transition: color 0.4s ease;
    }
    body.dark .content {
        color: var(--text-dark);
    }

    .content h3 {
        font-family: 'Merriweather', serif; /* Consistent serif for sub-headings */
        font-size: 1.5rem;
        margin-top: 1.8rem;
        margin-bottom: 1rem;
        color: var(--secondary-accent-light); /* Secondary accent for subheadings */
        border-bottom: 1px dashed var(--border-light);
        padding-bottom: 0.5rem;
        transition: color 0.4s ease, border-color 0.4s ease;
    }
    body.dark .content h3 {
        border-bottom-color: var(--border-dark);
        color: var(--secondary-accent-dark);
    }

    .content ul {
        list-style: disc;
        padding-left: 30px;
        margin-bottom: 1.2rem;
    }

    .content ul li {
        margin-bottom: 0.6rem;
    }

    .content p {
        margin-bottom: 1.2rem;
    }

    /* Button Group Styles */
    .button-group {
        display: flex;
        gap: 0.9rem; /* Increased gap */
        margin-top: 2rem; /* More space from content */
        flex-wrap: wrap;
        justify-content: flex-start;
    }

    .copy-btn, .status-btn, .notes-card-btn {
      padding: 0.7rem 1.4rem; /* Larger buttons */
      font-weight: 700;
      border: none;
      border-radius: 8px; /* More rounded */
      cursor: pointer;
      transition: background-color 0.3s ease, color 0.3s ease, transform 0.15s ease, box-shadow 0.2s ease;
      flex-grow: 0;
      min-width: fit-content;
      white-space: nowrap;
      box-shadow: 0 2px 5px rgba(0,0,0,0.1); /* Subtle button shadow */
    }

    .copy-btn {
      background-color: var(--primary-accent-light);
      color: var(--card-light); /* White text on accent */
    }

    .copy-btn:hover {
      background-color: var(--secondary-accent-light); /* Green on hover */
      color: white;
      transform: translateY(-2px);
      box-shadow: 0 4px 8px rgba(0,0,0,0.15);
    }
    body.dark .copy-btn {
        background-color: var(--primary-accent-dark);
        color: var(--bg-dark); /* Dark text on accent in dark mode */
    }
    body.dark .copy-btn:hover {
        background-color: var(--secondary-accent-dark);
    }

    /* Status buttons */
    .status-btn {
        background-color: var(--status-unread-btn);
        color: white;
    }
    body.dark .status-btn {
        background-color: #555; /* A bit more neutral in dark mode default */
    }

    .status-btn[data-current-status="read"] {
        background-color: var(--status-read-border);
        color: white;
    }
    .status-btn[data-current-status="doubt"] {
        background-color: var(--status-doubt-border);
        color: white;
    }

    .status-btn:hover {
        opacity: 0.9;
        transform: translateY(-2px);
    }

    /* Notes section within card */
    .notes-section {
        margin-top: 2rem;
        background-color: var(--bg-light); /* Match body bg for notes section */
        border: 1px solid var(--border-light);
        border-radius: 10px;
        padding: 1.2rem;
        display: none;
        box-shadow: inset 0 1px 5px rgba(0,0,0,0.05); /* Inner shadow for depth */
        transition: background-color 0.4s ease, border-color 0.4s ease;
    }
    body.dark .notes-section {
        background-color: #232B38;
        border-color: var(--border-dark);
    }

    .notes-section textarea {
        width: calc(100% - 20px);
        min-height: 120px; /* Taller textarea */
        padding: 12px;
        border: 1px solid var(--border-light);
        border-radius: 6px;
        font-family: 'Open Sans', sans-serif;
        font-size: 1rem;
        resize: vertical;
        background-color: var(--card-light);
        color: var(--text-light);
        transition: background-color 0.3s ease, color 0.3s ease, border-color 0.3s ease;
    }
    body.dark .notes-section textarea {
        background-color: var(--card-dark);
        border-color: var(--border-dark);
        color: var(--text-dark);
    }
    .notes-section textarea:focus {
        outline: none;
        border-color: var(--notes-floater-border-color); /* Purple focus border */
        box-shadow: 0 0 0 3px rgba(128, 90, 213, 0.2);
    }

    .notes-card-btn {
        background-color: var(--notes-floater-border-color);
        color: white;
    }
    body.dark .notes-card-btn {
        background-color: var(--notes-floater-header-bg-dark);
    }
    .notes-card-btn:hover {
        background-color: #9F7AEA; /* Lighter purple on hover */
        transform: translateY(-2px);
    }
    .notes-card-btn.saved {
        background-color: var(--secondary-accent-light); /* Green when notes are saved */
        color: white;
    }
    .notes-card-btn.saved:hover {
        background-color: #2F855A;
    }

    /* --- Notification Pop-up --- */
    .notification {
      position: fixed;
      bottom: 25px;
      right: 25px;
      padding: 15px 28px;
      background: #2ECC71; /* Default success color */
      color: white;
      font-weight: 600;
      border-radius: 10px;
      opacity: 0;
      transition: opacity 0.4s ease-in-out, transform 0.3s ease-out;
      z-index: 1000;
      box-shadow: 0 6px 20px rgba(0,0,0,0.2);
      transform: translateY(20px);
    }
    .notification.show {
        opacity: 1;
        transform: translateY(0);
    }


    /* --- Floating Buttons (Notes & Stats) --- */
    .floating-btn {
        position: fixed;
        bottom: 25px;
        background-color: #555;
        color: white;
        padding: 14px 22px; /* Larger padding */
        border-radius: 35px; /* More pill-shaped */
        font-size: 1.05rem;
        font-weight: bold;
        border: none;
        box-shadow: 0 6px 20px rgba(0,0,0,0.25); /* Stronger shadow */
        cursor: pointer;
        z-index: 999;
        transition: background-color 0.3s ease, transform 0.2s ease, box-shadow 0.3s ease;
        display: flex;
        align-items: center;
        gap: 10px;
    }
    .floating-btn:hover {
        transform: translateY(-5px); /* More pronounced lift */
        box-shadow: 0 8px 25px rgba(0,0,0,0.3);
    }

    .floating-notes-btn {
        left: 25px;
        background-color: var(--notes-floater-border-color); /* Purple */
    }
    body.dark .floating-notes-btn {
        background-color: var(--notes-floater-header-bg-dark);
    }
    .floating-notes-btn:hover {
        background-color: #9F7AEA;
    }

    .floating-stats-btn {
        right: 25px;
        background-color: var(--stats-floater-border-color); /* Orange */
    }
    body.dark .floating-stats-btn {
        background-color: var(--stats-floater-header-bg-dark);
    }
    .floating-stats-btn:hover {
        background-color: #F6AD55;
    }

    /* --- Floating Floater Base Styles (Notes & Stats) --- */
    .floater {
        position: fixed;
        bottom: 90px; /* Above the floating buttons */
        width: 350px; /* Slightly wider */
        max-height: 450px; /* Taller */
        background-color: var(--notes-floater-bg-light);
        backdrop-filter: blur(10px); /* Stronger blur */
        -webkit-backdrop-filter: blur(10px);
        border-radius: 20px; /* More rounded */
        box-shadow: 0 12px 40px rgba(0,0,0,0.3); /* Stronger shadow */
        z-index: 1000;
        display: flex;
        flex-direction: column;
        overflow: hidden;
        color: var(--text-light);

        opacity: 0;
        visibility: hidden;
        transform: translateY(30px) scale(0.9); /* More pronounced animation */
        transition: opacity 0.4s ease-out, visibility 0.4s ease-out, transform 0.4s ease-out;
    }
    body.dark .floater {
        background-color: var(--notes-floater-bg-dark);
        color: var(--text-dark);
    }

    .floater.open {
        opacity: 1;
        visibility: visible;
        transform: translateY(0) scale(1);
    }

    .floater.translucent {
        opacity: 0.6; /* Slightly less translucent */
        pointer-events: auto;
    }

    .floater-header {
        display: flex;
        justify-content: space-between;
        align-items: center;
        padding: 1rem 1.5rem; /* More padding */
        border-bottom: 1px solid rgba(255,255,255,0.2); /* Lighter border for contrast */
        color: white;
        font-weight: bold;
        background: linear-gradient(to right, var(--floater-header-bg-light), var(--floater-header-bg-light) 80%, rgba(255,255,255,0.1)); /* Subtle gradient header */
        transition: background 0.4s ease, border-color 0.4s ease;
    }
    body.dark .floater-header {
        border-bottom-color: var(--border-dark);
        background: linear-gradient(to right, var(--floater-header-bg-dark), var(--floater-header-bg-dark) 80%, rgba(0,0,0,0.1));
    }
    .floater-header span {
        font-family: 'Merriweather', serif; /* Consistent heading font */
        font-size: 1.4rem;
    }
    .floater-close {
        background: none;
        border: none;
        font-size: 2rem; /* Larger close icon */
        cursor: pointer;
        color: white;
        transition: transform 0.2s ease, opacity 0.2s ease;
    }
    .floater-close:hover {
        transform: rotate(90deg) scale(1.1);
        opacity: 0.8;
    }

    .floater-content {
        padding: 1.2rem 1.5rem; /* More padding */
        overflow-y: auto;
        flex-grow: 1;
    }

    /* --- Notes Floater Specific Styles --- */
    .notes-floater {
        left: 25px;
        border: 2px solid var(--notes-floater-border-color);
        --floater-header-bg-light: var(--notes-floater-header-bg-light);
        --floater-header-bg-dark: var(--notes-floater-header-bg-dark);
    }
    body.dark .notes-floater {
        border-color: var(--notes-floater-header-bg-dark);
    }
    .notes-floater-content p {
        margin: 0;
        padding: 0;
    }
    .notes-floater-content .note-item {
        margin-bottom: 1.8rem; /* More space */
        padding-bottom: 1.8rem;
        border-bottom: 1px dashed var(--border-light);
        cursor: pointer; /* Indicate clickable */
        transition: background-color 0.2s ease, transform 0.1s ease;
    }
    .notes-floater-content .note-item:hover {
        background-color: rgba(0,0,0,0.03); /* Subtle hover effect */
        transform: translateX(3px);
    }
    body.dark .notes-floater-content .note-item {
        border-bottom-color: var(--border-dark);
    }
    body.dark .notes-floater-content .note-item:hover {
        background-color: rgba(255,255,255,0.05);
    }
    .notes-floater-content .note-item:last-child {
        border-bottom: none;
        margin-bottom: 0;
        padding-bottom: 0;
    }
    .notes-floater-content .note-item h4 {
        font-family: 'Open Sans', sans-serif; /* Keep notes headings readable */
        font-size: 1.1rem; /* Slightly smaller for notes titles */
        font-weight: 600;
        margin-top: 0;
        margin-bottom: 0.6rem;
        color: var(--primary-accent-light);
        transition: color 0.4s ease;
    }
    body.dark .notes-floater-content .note-item h4 {
        color: var(--primary-accent-dark);
    }
    .notes-floater-content .note-item p {
        font-size: 0.95rem;
        white-space: pre-wrap;
        color: var(--text-light); /* Ensure note text is readable */
        transition: color 0.4s ease;
    }
    body.dark .notes-floater-content .note-item p {
        color: var(--text-dark);
    }


    /* --- Stats Floater Specific Styles (Smaller Pie Chart) --- */
    .stats-floater {
        right: 25px;
        border: 2px solid var(--stats-floater-border-color);
        width: 280px; /* Slightly wider stats floater */
        max-height: 380px;
        --floater-header-bg-light: var(--stats-floater-header-bg-light);
        --floater-header-bg-dark: var(--stats-floater-header-bg-dark);
    }
    body.dark .stats-floater {
        border-color: var(--stats-floater-header-bg-dark);
    }

    .stats-floater-content {
        display: flex;
        flex-direction: column;
        align-items: center;
        gap: 1.2rem;
        padding: 1.2rem;
    }

    .stats-floater-content h4 {
        font-family: 'Merriweather', serif;
        color: var(--primary-accent-light);
        margin: 0 0 0.5rem 0;
        font-size: 1.25rem;
        transition: color 0.4s ease;
    }
    body.dark .stats-floater-content h4 {
        color: var(--primary-accent-dark);
    }

    .pie-chart {
        width: 120px; /* Slightly larger chart */
        height: 120px;
        border-radius: 50%;
        background: conic-gradient(
            var(--chart-read-color) 0%,
            var(--chart-read-color) var(--read-percentage, 0%),
            var(--chart-doubt-color) var(--read-percentage, 0%),
            var(--chart-doubt-color) calc(var(--read-percentage, 0%) + var(--doubt-percentage, 0%)),
            var(--chart-unread-color) calc(var(--read-percentage, 0%) + var(--doubt-percentage, 0%)),
            var(--chart-unread-color) 100%
        );
        box-shadow: 0 4px 15px rgba(0,0,0,0.15); /* More prominent shadow */
        transition: background 0.5s ease-in-out;
    }

    .stats-legend {
        list-style: none;
        padding: 0;
        margin: 0;
        text-align: left;
        width: 100%;
        font-size: 1rem; /* Slightly larger legend text */
    }

    .stats-legend li {
        margin-bottom: 0.5rem;
        display: flex;
        align-items: center;
    }

    .legend-color-box {
        width: 18px; /* Larger color boxes */
        height: 18px;
        border-radius: 4px;
        margin-right: 10px;
        flex-shrink: 0;
    }

    .legend-color-box.read { background-color: var(--chart-read-color); }
    .legend-color-box.doubt { background-color: var(--chart-doubt-color); }
    .legend-color-box.unread { background-color: var(--chart-unread-color); }

    /* --- Footer --- */
    footer {
      text-align: center;
      padding: 3rem 1.5rem;
      font-size: 0.95rem;
      color: #7F8C8D;
      border-top: 1px solid var(--border-light);
      margin-top: 2.5rem;
      transition: border-color 0.4s ease;
    }

    body.dark footer {
      border-color: var(--border-dark);
    }


    .time-tooltip {
      background-color: rgba(0, 0, 0, 0.85); /* Dark, semi-transparent background */
      color: #fff; /* White text */
      padding: 8px 12px;
      border-radius: 6px; /* Slightly rounded corners */
      font-size: 0.8rem; /* Small font size for tooltip */
      max-width: 200px; /* Max width to prevent overly wide tooltips */
      white-space: normal; /* Allow text to wrap inside the tooltip */
      word-wrap: break-word; /* Ensure long words break */
      box-shadow: 0 4px 12px rgba(0, 0, 0, 0.4); /* Subtle shadow */
      z-index: 10000; /* Ensure it's on top of other content */
      opacity: 0; /* Start invisible */
      transform: translateY(-5px); /* Slight initial offset for transition */
      transition: opacity 0.2s ease-out, transform 0.2s ease-out; /* Smooth fade and slide */
      pointer-events: none; /* Allows clicks to pass through when hidden */
    }

    .time-tooltip.is-visible {
      opacity: 1; /* Make visible */
      transform: translateY(0); /* Slide into place */
      pointer-events: auto; /* Allow clicks when visible */
    }


    summary time {
      white-space: nowrap;
      overflow: hidden;
      text-overflow: ellipsis;
    }

    /* --- Responsive Adjustments --- */
    @media (max-width: 768px) {
        h1 {
            font-size: 2.5rem;
        }
        header p {
            font-size: 1.05rem;
        }
        .topic-card {
            padding: 1rem 1.2rem;
            margin: 1rem auto;
            border-left: 5px solid;
        }
        .topic-card h2 {
            font-size: 2rem;
            margin-bottom: 1.2rem;
        }
        summary {
            font-size: 1.15rem;
            padding-right: 25px;
        }
        summary::before {
            font-size: 1.5rem;
        }
        .content {
            font-size: 0.95rem;
            padding-top: 1rem;
        }
        .content h3 {
            font-size: 1.3rem;
            margin-top: 1.2rem;
        }
        .copy-btn, .status-btn, .notes-card-btn {
            padding: 0.6rem 1rem;
            font-size: 0.9rem;
        }
        .button-group {
            gap: 0.7rem;
            margin-top: 1.5rem;
        }
        .notes-section {
            padding: 1rem;
            margin-top: 1.5rem;
        }
        .notes-section textarea {
            min-height: 90px;
        }

        .toggle-theme {
            top: 0.8rem;
            right: 0.8rem;
            font-size: 1.5rem;
        }

        .floating-btn {
            bottom: 15px;
            padding: 10px 15px;
            font-size: 0.9rem;
            gap: 6px;
            border-radius: 25px;
        }
        .floating-notes-btn {
            left: 15px;
        }
        .floating-stats-btn {
            right: 15px;
        }

        .floater {
            bottom: 70px;
            width: calc(100% - 30px);
            max-height: 65vh;
            border-radius: 15px;
        }
        .notes-floater {
            left: 15px;
        }
        .stats-floater {
            right: 15px;
            width: 250px;
        }
        .floater-header {
            padding: 0.7rem 1.2rem;
        }
        .floater-header span {
            font-size: 1.2rem;
        }
        .floater-close {
            font-size: 1.7rem;
        }
        .floater-content {
            padding: 1rem 1.2rem;
        }
        .notes-floater-content .note-item {
            margin-bottom: 1.5rem;
            padding-bottom: 1.5rem;
        }
        .notes-floater-content .note-item h4 {
            font-size: 1rem;
        }
        .notes-floater-content .note-item p {
            font-size: 0.85rem;
        }
        .pie-chart {
            width: 90px;
            height: 90px;
        }
        .stats-legend {
            font-size: 0.9rem;
        }
        .legend-color-box {
            width: 15px;
            height: 15px;
        }
    }
  </style>
  <head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Your Document Title</title>
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.8/dist/katex.min.css" crossorigin="anonymous">

    <script type="text/javascript">
        // Function to load and configure MathJax
        function loadMathJax() {
            // Basic MathJax configuration for common delimiters ($$..$$ and $..$)
            window.MathJax = {
                tex: {
                    inlineMath: [['$', '$'], ['\\(', '\\)']],
                    displayMath: [['$$', '$$'], ['\\[', '\\]']],
                    processEscapes: true // Allows \$ to render as a literal dollar sign
                },
                options: {
                    // Reduce initial processing time by not auto-typesetting
                    // We'll call typeset explicitly later
                    skipHtmlTags: ['pre', 'code', 'textarea', 'script', 'style']
                }
            };

            const script = document.createElement('script');
            script.type = 'text/javascript';
            script.src = 'https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js';
            script.async = true; // Load asynchronously
            script.onload = () => {
                // MathJax loaded, now attempt to render
                if (window.MathJax && window.MathJax.typesetPromise) {
                    MathJax.typesetPromise()
                        .then(() => console.log('MathJax typeset complete.'))
                        .catch(err => {
                            console.error('MathJax typeset error:', err);
                            loadKaTeX(); // Fallback to KaTeX if MathJax typeset fails
                        });
                } else {
                    console.warn('MathJax loaded but not initialized properly. Falling back to KaTeX.');
                    loadKaTeX(); // Fallback if MathJax fails to initialize correctly
                }
            };
            script.onerror = () => {
                console.error('Failed to load MathJax script. Falling back to KaTeX.');
                loadKaTeX(); // Fallback if MathJax script fails to load
            };
            document.head.appendChild(script);
        }

        // Function to load and configure KaTeX
        function loadKaTeX() {
            console.log('Attempting to load KaTeX...');
            // Check if KaTeX is already loaded (from a previous attempt or direct inclusion)
            if (typeof katex !== 'undefined' && typeof renderMathInElement !== 'undefined') {
                 console.log('KaTeX already loaded, rendering...');
                 renderMath(); // Just render if already available
                 return;
            }

            const script = document.createElement('script');
            script.type = 'text/javascript';
            script.src = 'https://cdn.jsdelivr.net/npm/katex@0.16.8/dist/contrib/auto-render.min.js';
            script.defer = true; // Defer execution until HTML is parsed
            script.onload = () => {
                if (typeof renderMathInElement !== 'undefined') {
                    renderMath(); // Render if auto-render is available
                } else {
                    console.error('KaTeX auto-render failed to load. Falling back to plain text.');
                    fallbackToPlainText();
                }
            };
            script.onerror = () => {
                console.error('Failed to load KaTeX script. Falling back to plain text.');
                fallbackToPlainText();
            };
            document.head.appendChild(script);
        }

        // Function to render math using KaTeX (after auto-render is loaded)
        function renderMath() {
            try {
                // Apply KaTeX auto-render to the entire document body
                renderMathInElement(document.body, {
                    // KaTeX delimiters (must match your usage)
                    delimiters: [
                        {left: '$$', right: '$$', display: true},
                        {left: '\\[', right: '\\]', display: true},
                        {left: '$', right: '$', display: true},
                        {left: '\\(', right: '\\)', display: true}
                    ],
                    // Increase maxSize for larger equations if needed, default is 500
                    // maxSize: Infinity,
                    // minRuleThickness: 0.05, // Adjust for better rendering of thin lines
                    throwOnError: false // Do not throw errors for malformed math, just render as plain text
                });
                console.log('KaTeX typeset complete.');
            } catch (e) {
                console.error('KaTeX rendering error:', e);
                fallbackToPlainText(); // Critical fallback if KaTeX itself errors
            }
        }

        // Final fallback: show raw LaTeX and highlight the issue
        function fallbackToPlainText() {
            console.warn('Math rendering failed. Displaying raw LaTeX.');
            const mathElements = document.querySelectorAll('.math-formula'); // Target a class for math content
            mathElements.forEach(el => {
                // Remove any previously rendered math and display raw text
                el.innerHTML = `<span style="color: red; font-weight: bold;">[Math Error]</span> ${el.dataset.latex || el.textContent}`;
                el.style.fontFamily = 'monospace'; // Make raw LaTeX easier to read
                el.style.border = '1px dashed red';
                el.style.padding = '2px';
            });
            // If the math is just in plain text, you can try to parse and wrap them
            // This is more complex and depends on how your content is generated.
            // For general content, we assume content is already wrapped or handled by a pre-processor.
        }

        // Initiate MathJax loading when the DOM is ready
        document.addEventListener('DOMContentLoaded', loadMathJax);

    </script>
</head>
</head>
<body>
  <button class="toggle-theme" onclick="toggleTheme()">🌓</button>
  <header>
    <h1>MPC006 Statistics in Psychology</h1>
    <p>Dive into the depths of statistics-related psychological concepts from the IGNOU MAPC syllabus.</p>
  </header>

  <div class="search-wrapper">
    <input type="search" class="search-input" placeholder="Search topics and questions..." oninput="filterContent(this.value)"/>
	<a href="stats.html" style="
            display: inline-flex;
            align-items: center;
            justify-content: center;
            padding: 8px 15px;
            margin-top: 10px; /* Space from search bar */
            background-image: linear-gradient(to right, #4CAF50, #8BC34A); /* Green gradient */
            color: white;
            border: none;
            border-radius: 25px; /* More rounded corners */
            text-decoration: none;
            font-weight: bold;
            font-size: 1.0em;
            cursor: pointer;
            box-shadow: 0 4px 8px rgba(0, 0, 0, 0.2); /* Softer shadow */
            transition: all 0.3s ease; /* Smooth transitions */
            letter-spacing: 0.5px; /* A bit of letter spacing */
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif; /* Modern font */
        " onmouseover="this.style.boxShadow='0 6px 12px rgba(0, 0, 0, 0.3)'; this.style.transform='translateY(-2px)'"
           onmouseout="this.style.boxShadow='0 4px 8px rgba(0, 0, 0, 0.2)'; this.style.transform='translateY(0)'">
            <span style="margin-right: 8px; font-size: 1.2em;">&sum;</span> All Formulas
        </a>
  </div>

  <main>
  
  
<section class="topic-card" id="card-hypothesis-testing-all">
    <h2> 📊 HYPOTHESIS TESTING</h2>

    <details data-status="unread">
        <span class="status-icon read" title="Read">✓</span>
        <span class="status-icon doubt" title="Doubt">!</span>
        <summary>
            <span>What is hypothesis testing? Discuss the steps involved in setting up the level of significance with suitable examples.</span>
            <time class="ml-2 text-gray-500 dark:text-gray-400" style="white-space: nowrap; overflow: hidden; text-overflow: ellipsis; font-size: clamp(0.4rem, 1.7vw, 0.9rem); color: #888; font-style: italic;">
June 12, 2025
</time>
            <span class="notes-indicator-icon" title="Notes added">📝</span>
        </summary>
        <div class="content">
            <p><strong>Hypothesis testing</strong> is a formal procedure for investigating our ideas about the world using statistics. It is a systematic method used to make decisions about a population based on sample data. Essentially, it helps determine if a certain assertion or assumption about a population parameter (e.g., mean, proportion) is supported by empirical evidence. The goal is to evaluate if a sample provides enough evidence to reject a null hypothesis in favor of an alternative hypothesis.</p>
            <p>This process involves setting up two competing hypotheses: the <strong>null hypothesis ($H_0$)</strong>, which represents a statement of no effect or no difference, and the <strong>alternative hypothesis ($H_1$ or $H_a$)</strong>, which is what the researcher is trying to prove.</p>

            <h3>Steps Involved in Setting Up the Level of Significance</h3>
            <p>The <strong>level of significance ($\alpha$)</strong> is a critical component of hypothesis testing. It is the probability of rejecting the null hypothesis when it is actually true. This is also known as a <strong>Type I error</strong>. Setting $\alpha$ appropriately is crucial as it dictates the threshold for decision-making. Here are the steps involved:</p>
            <ul>
                <li>
                    <strong>1. Formulate the Null Hypothesis ($H_0$) and Alternative Hypothesis ($H_1$):</strong>
                    <p>Before determining the level of significance, you must clearly define what you are testing.</p>
                    <ul>
                        <li><strong>Null Hypothesis ($H_0$):</strong> This is the statement of no effect, no difference, or no relationship. It represents the status quo or the existing belief. For example, if a company claims its new drug cures a disease in 80% of patients, $H_0: p = 0.80$.</li>
                        <li><strong>Alternative Hypothesis ($H_1$):</strong> This is the statement that contradicts the null hypothesis. It's what the researcher is trying to find evidence for. For example, if the researcher believes the drug's effectiveness is different from 80%, $H_1: p \neq 0.80$. If they believe it's higher, $H_1: p > 0.80$.</li>
                    </ul>
                </li>
                <li>
                    <strong>2. Choose the Appropriate Test Statistic:</strong>
                    <p>The choice of test statistic depends on the nature of the data, the population parameters being tested, and the sample size. Common test statistics include:</p>
                    <ul>
                        <li><strong>Z-test:</strong> Used for means when the population standard deviation is known, or for large sample sizes.</li>
                        <li><strong>T-test:</strong> Used for means when the population standard deviation is unknown and sample sizes are small.</li>
                        <li><strong>Chi-square test ($\chi^2$):</strong> Used for categorical data, like testing for independence between two variables or goodness-of-fit.</li>
                        <li><strong>F-test:</strong> Used in ANOVA (Analysis of Variance) to compare variances between two or more groups.</li>
                    </ul>
                </li>
                <li>
                    <strong>3. Determine the Level of Significance ($\alpha$):</strong>
                    <p>This is the probability threshold below which the null hypothesis will be rejected. It defines how much risk of making a Type I error (false positive) you are willing to take. Common values for $\alpha$ are:</p>
                    <ul>
                        <li><strong>$\alpha = 0.05$ (5%):</strong> This is the most commonly used level. It means there is a 5% chance of incorrectly rejecting the null hypothesis when it is true.</li>
                        <li><strong>$\alpha = 0.01$ (1%):</strong> A stricter level, meaning there's only a 1% chance of a Type I error. This is often used in situations where the consequences of a Type I error are severe (e.g., medical trials, quality control for critical components).</li>
                        <li><strong>$\alpha = 0.10$ (10%):</strong> A more lenient level, indicating a 10% chance of a Type I error. Sometimes used in exploratory research where missing a potential effect (Type II error) is considered worse than a false positive.</li>
                    </ul>
                    <p><strong>Example:</strong> A pharmaceutical company tests a new drug's effectiveness. If they set $\alpha = 0.01$, they are saying they only want a 1% chance of concluding the drug is effective when it actually isn't (a very serious error in medicine). If a marketing team is testing two ad campaigns, they might set $\alpha = 0.10$, being more willing to risk a false positive to identify a potentially better campaign.</p>
                </li>
                <li>
                    <strong>4. Determine the Critical Region (Rejection Region):</strong>
                    <p>Based on the chosen $\alpha$ and the distribution of the test statistic, a critical value(s) is determined. The critical region consists of the values of the test statistic that would lead to the rejection of the null hypothesis. For a two-tailed test, there are two critical regions (one in each tail); for a one-tailed test, there is one critical region.</p>
                </li>
                <li>
                    <strong>5. Calculate the Test Statistic from Sample Data:</strong>
                    <p>Collect the sample data and compute the value of the chosen test statistic.</p>
                </li>
                <li>
                    <strong>6. Make a Decision:</strong>
                    <p>Compare the calculated test statistic to the critical value(s) or compare the p-value to $\alpha$.</p>
                    <ul>
                        <li>If the calculated test statistic falls into the critical region (or if the p-value $&lt; \alpha$), then <strong>reject the null hypothesis ($H_0$)</strong>.</li>
                        <li>Otherwise, <strong>do not reject the null hypothesis ($H_0$)</strong>. (Note: We do not "accept" $H_0$, as we only have evidence to reject or not reject.)</li>
                    </ul>
                </li>
                <li>
                    <strong>7. State the Conclusion:</strong>
                    <p>Interpret the statistical decision in the context of the original problem. Clearly state what the findings mean in practical terms.</p>
                    <p><strong>Example:</strong> If a p-value of $0.03$ was obtained and $\alpha$ was set to $0.05$, since $0.03 < 0.05$, we would reject $H_0$. The conclusion would be: "There is sufficient statistical evidence at the $5\%$ level of significance to conclude that..." (and then state the alternative hypothesis in plain language).</p>
                </li>
            </ul>
            <p>The choice of $\alpha$ is a crucial decision that balances the risk of a Type I error against the risk of a Type II error (failing to reject a false null hypothesis). A lower $\alpha$ reduces the risk of Type I error but increases the risk of Type II error, and vice-versa.</p>
            <div class="button-group">
                <button class="copy-btn" onclick="copyText(this)">Copy Answer</button>
                <button class="status-btn" data-status-action="read" onclick="setQuestionStatus(this.closest('details'), 'read')">Mark as Read</button>
                <button class="status-btn" data-status-action="unread" onclick="setQuestionStatus(this.closest('details'), 'unread')">Mark as Unread</button>
                <button class="status-btn" data-status-action="doubt" onclick="setQuestionStatus(this.closest('details'), 'doubt')">Mark as Doubt</button>
                <button class="notes-card-btn" onclick="toggleNotes(this.closest('details'))">Add/View Notes</button>
            </div>
            <div class="notes-section">
                <textarea placeholder="Write your notes here..." oninput="saveNotes(this.closest('details'), this.value)"></textarea>
            </div>
        </div>
    </details>

    <details data-status="unread">
        <span class="status-icon read" title="Read">✓</span>
        <span class="status-icon doubt" title="Doubt">!</span>
        <summary>
            <span>Explain hypothesis testing and describe its errors (Type I/II).</span>
            <time class="ml-2 text-gray-500 dark:text-gray-400" style="white-space: nowrap; overflow: hidden; text-overflow: ellipsis; font-size: clamp(0.4rem, 1.7vw, 0.9rem); color: #888; font-style: italic;">
June 12, 2025
</time>
            <span class="notes-indicator-icon" title="Notes added">📝</span>
        </summary>
        <div class="content">
            <p><strong>Hypothesis testing</strong> is a statistical inference method used to make decisions about a population parameter based on sample data. It's a structured approach to evaluate a claim or assumption about a population. The core idea is to start with a tentative assumption (the null hypothesis) and then use sample data to determine if there's enough evidence to reject that assumption.</p>
            <p>The process typically involves:</p>
            <ul>
                <li>Formulating a <strong>null hypothesis ($H_0$)</strong> and an <strong>alternative hypothesis ($H_1$)</strong>.</li>
                <li>Choosing a <strong>level of significance ($\alpha$)</strong>.</li>
                <li>Collecting sample data and calculating a <strong>test statistic</strong>.</li>
                <li>Making a decision: either reject $H_0$ or fail to reject $H_0$.</li>
            </ul>

            <h3>Errors in Hypothesis Testing</h3>
            <p>Since hypothesis testing relies on sample data, there's always a possibility of making an incorrect decision. There are two types of errors:</p>
            <ul>
                <li>
                    <strong>Type I Error ($\alpha$ - Alpha Error):</strong>
                    <p>A Type I error occurs when you <strong>incorrectly reject a true null hypothesis</strong>. It's often referred to as a "false positive".</p>
                    <ul>
                        <li><strong>Definition:</strong> Rejecting $H_0$ when $H_0$ is actually true.</li>
                        <li><strong>Probability:</strong> The probability of making a Type I error is denoted by $\alpha$ (alpha), which is also the chosen level of significance.</li>
                        <li><strong>Consequences:</strong> The consequences depend on the context. For example, in medical testing, concluding a healthy person has a disease; in quality control, recalling a perfectly good product; in research, claiming a drug is effective when it isn't.</li>
                        <li><strong>Control:</strong> The probability of a Type I error is directly controlled by the researcher through the choice of the level of significance ($\alpha$). Lowering $\alpha$ reduces the risk of Type I error but increases the risk of Type II error.</li>
                    </ul>
                    <p><strong>Example:</strong> A court finding an innocent person guilty. $H_0$: The person is innocent. $H_1$: The person is guilty. A Type I error would be convicting an innocent person.</p>
                </li>
                <li>
                    <strong>Type II Error ($\beta$ - Beta Error):</strong>
                    <p>A Type II error occurs when you <strong>fail to reject a false null hypothesis</strong>. It's often referred to as a "false negative".</p>
                    <ul>
                        <li><strong>Definition:</strong> Failing to reject $H_0$ when $H_0$ is actually false.</li>
                        <li><strong>Probability:</strong> The probability of making a Type II error is denoted by $\beta$ (beta).</li>
                        <li><strong>Consequences:</strong> The consequences also depend on the context. For example, in medical testing, failing to diagnose a sick person; in quality control, approving a defective product; in research, missing a truly effective treatment.</li>
                        <li><strong>Control:</strong> $\beta$ is influenced by several factors, including the sample size, the effect size (the true difference between the parameter and the hypothesized value), and the chosen $\alpha$ level. Increasing sample size generally reduces $\beta$.</li>
                    </ul>
                    <p><strong>Example:</strong> A court finding a guilty person not guilty. $H_0$: The person is innocent. $H_1$: The person is guilty. A Type II error would be letting a guilty person go free.</p>
                </li>
            </ul>
            <h4>Relationship Between Type I and Type II Errors</h4>
            <p>There is an inverse relationship between Type I and Type II errors. Decreasing the probability of one type of error typically increases the probability of the other, assuming all other factors remain constant. Researchers must balance these risks based on the specific context and the severity of each type of error.</p>
            <div class="button-group">
                <button class="copy-btn" onclick="copyText(this)">Copy Answer</button>
                <button class="status-btn" data-status-action="read" onclick="setQuestionStatus(this.closest('details'), 'read')">Mark as Read</button>
                <button class="status-btn" data-status-action="unread" onclick="setQuestionStatus(this.closest('details'), 'unread')">Mark as Unread</button>
                <button class="status-btn" data-status-action="doubt" onclick="setQuestionStatus(this.closest('details'), 'doubt')">Mark as Doubt</button>
                <button class="notes-card-btn" onclick="toggleNotes(this.closest('details'))">Add/View Notes</button>
            </div>
            <div class="notes-section">
                <textarea placeholder="Write your notes here..." oninput="saveNotes(this.closest('details'), this.value)"></textarea>
            </div>
        </div>
    </details>

    <details data-status="unread">
        <span class="status-icon read" title="Read">✓</span>
        <span class="status-icon doubt" title="Doubt">!</span>
        <summary>
            <span>Discuss the meaning and concept of levels of significance.</span>
            <time class="ml-2 text-gray-500 dark:text-gray-400" style="white-space: nowrap; overflow: hidden; text-overflow: ellipsis; font-size: clamp(0.4rem, 1.7vw, 0.9rem); color: #888; font-style: italic;">
June 12, 2025
</time>
            <span class="notes-indicator-icon" title="Notes added">📝</span>
        </summary>
        <div class="content">
            <p>The <strong>level of significance</strong>, denoted by the Greek letter <strong>alpha ($\alpha$)</strong>, is a crucial concept in hypothesis testing. It represents the probability of making a Type I error, which is the error of rejecting a true null hypothesis.</p>
            <h3>Meaning of Level of Significance ($\alpha$)</h3>
            <p>In simpler terms, $\alpha$ is the threshold for statistical decision-making. Before conducting a hypothesis test, a researcher pre-defines this probability. If the probability of observing the sample data (or more extreme data) given that the null hypothesis is true (known as the p-value) falls below this predetermined $\alpha$ level, the null hypothesis is rejected. Otherwise, it is not rejected.</p>
            <ul>
                <li>It is the maximum acceptable probability of committing a Type I error.</li>
                <li>It defines the "critical region" or "rejection region" in the sampling distribution of the test statistic. If the calculated test statistic falls into this region, we reject $H_0$.</li>
                <li>Commonly chosen values for $\alpha$ are $0.05$ (5%), $0.01$ (1%), or $0.10$ (10%). The choice depends on the specific context and the consequences associated with making a Type I error.</li>
            </ul>

            <h3>Concept of Level of Significance</h3>
            <p>To understand the concept, consider the following:</p>
            <ul>
                <li>
                    <strong>1. Setting the Risk:</strong> When you set $\alpha = 0.05$, you are essentially saying that you are willing to accept a 5% chance of falsely concluding that there is an effect or difference when, in reality, there is none. This is the risk you are comfortable taking.
                    <p><strong>Example:</strong> A company claims a new manufacturing process reduces defects. $H_0$: The new process does not reduce defects. $H_1$: The new process reduces defects. If $\alpha = 0.05$, there's a 5% chance you'll conclude the new process is better (and invest in it) when, in fact, it's not.</p>
                </li>
                <li>
                    <strong>2. Critical Values:</strong> The level of significance directly determines the critical values. These are the boundary values that separate the rejection region from the non-rejection region. For a two-tailed test with $\alpha = 0.05$, for example, the critical z-values would be approximately $\pm 1.96$. Any test statistic falling beyond these values would lead to rejection of $H_0$.
                    <p><strong>Example:</strong> In a Z-test for a population mean, if $\alpha = 0.05$ and it's a two-tailed test, the critical values are $Z = \pm 1.96$. If your calculated Z-statistic is $2.10$, it falls in the rejection region (as $2.10 > 1.96$), and you would reject $H_0$.</p>
                </li>
                <li>
                    <strong>3. P-value Comparison:</strong> In modern statistical software, decisions are often made by comparing the p-value with the $\alpha$ level. The p-value is the probability of observing a test statistic as extreme as, or more extreme than, the one calculated from the sample data, assuming the null hypothesis is true.
                    <ul>
                        <li>If <strong>p-value $&lt; \alpha$</strong>, reject $H_0$. This means the observed data is unlikely to occur if $H_0$ were true, suggesting evidence against $H_0$.</li>
                        <li>If <strong>p-value $\ge \alpha$</strong>, do not reject $H_0$. This means the observed data is not sufficiently unusual to reject $H_0$.</li>
                    </ul>
                    <p><strong>Example:</strong> A research study reports a p-value of $0.02$. If the researcher set $\alpha = 0.05$, then since $0.02 < 0.05$, they would reject the null hypothesis. If $\alpha$ was set to $0.01$, then since $0.02 > 0.01$, they would not reject the null hypothesis.</p>
                </li>
                <li>
                    <strong>4. Balancing Errors:</strong> The choice of $\alpha$ involves a trade-off. A very small $\alpha$ (e.g., $0.001$) makes it harder to reject $H_0$, thus reducing the chance of a Type I error but increasing the chance of a Type II error (failing to detect a real effect). Conversely, a large $\alpha$ (e.g., $0.10$) makes it easier to reject $H_0$, increasing the chance of a Type I error but reducing the chance of a Type II error. The selection of $\alpha$ should reflect the relative costs of making each type of error in a given situation.
                </li>
            </ul>
            <p>In summary, the level of significance is a predefined threshold that helps determine the strength of the evidence against the null hypothesis. It quantifies the acceptable risk of concluding that an effect or difference exists when, in reality, it does not.</p>
            <div class="button-group">
                <button class="copy-btn" onclick="copyText(this)">Copy Answer</button>
                <button class="status-btn" data-status-action="read" onclick="setQuestionStatus(this.closest('details'), 'read')">Mark as Read</button>
                <button class="status-btn" data-status-action="unread" onclick="setQuestionStatus(this.closest('details'), 'unread')">Mark as Unread</button>
                <button class="status-btn" data-status-action="doubt" onclick="setQuestionStatus(this.closest('details'), 'doubt')">Mark as Doubt</button>
                <button class="notes-card-btn" onclick="toggleNotes(this.closest('details'))">Add/View Notes</button>
            </div>
            <div class="notes-section">
                <textarea placeholder="Write your notes here..." oninput="saveNotes(this.closest('details'), this.value)"></textarea>
            </div>
        </div>
    </details>

</section>


<section class="topic-card" id="card-parametric-nonparametric-statistics">
    <h2> 📊 TYPES OF STATISTICS: PARAMETRIC VS NON-PARAMETRIC</h2>

    <details data-status="unread">
        <span class="status-icon read" title="Read">✓</span>
        <span class="status-icon doubt" title="Doubt">!</span>
        <summary>
            <span>Define/differentiate parametric and non-parametric statistics. Discuss their assumptions, advantages, and disadvantages.</span>
            <time class="ml-2 text-gray-500 dark:text-gray-400" style="white-space: nowrap; overflow: hidden; text-overflow: ellipsis; font-size: clamp(0.4rem, 1.7vw, 0.9rem); color: #888; font-style: italic;">
June 12, 2025
</time>
            <span class="notes-indicator-icon" title="Notes added">📝</span>
        </summary>
        <div class="content">
            <p>In the realm of statistical analysis, distinguishing between <strong>parametric</strong> and <strong>non-parametric statistics</strong> is fundamental to choosing the appropriate analytical method for a given dataset. The primary difference lies in the assumptions made about the population distribution from which the data is drawn.</p>

            <h3>Defining and Differentiating</h3>
            <ul>
                <li>
                    <strong>Parametric Statistics:</strong>
                    <p>Parametric statistical tests are those that make specific assumptions about the parameters of the population distribution from which the sample data is drawn. Most commonly, these tests assume that the data follows a specific distribution, such as a <strong>normal distribution</strong>, and that population parameters like the mean and standard deviation are relevant for the analysis. They are generally more powerful than non-parametric tests when their assumptions are met.</p>
                </li>
                <li>
                    <strong>Non-Parametric Statistics:</strong>
                    <p>Non-parametric statistical tests, often referred to as "distribution-free" tests, do not rely on specific assumptions about the shape or parameters of the population distribution. Instead, they are typically used when data do not meet the assumptions of parametric tests (e.g., non-normal distribution, ordinal or nominal data, small sample sizes) or when the research question does not concern population parameters directly (e.g., comparing medians or ranks).</p>
                </li>
            </ul>

            <h4>Key Differentiators:</h4>
            <div style="overflow-x:auto;">
                <table style="width:100%; border-collapse: collapse;">
                    <thead>
                        <tr style="background-color: #f2f2f2;">
                            <th style="padding: 8px; border: 1px solid #ddd; text-align: left;">Feature</th>
                            <th style="padding: 8px; border: 1px solid #ddd; text-align: left;">Parametric Statistics</th>
                            <th style="padding: 8px; border: 1px solid #ddd; text-align: left;">Non-Parametric Statistics</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td style="padding: 8px; border: 1px solid #ddd;"><strong>Assumptions about Distribution</strong></td>
                            <td style="padding: 8px; border: 1px solid #ddd;">Assumes data comes from a specific distribution (e.g., normal distribution).</td>
                            <td style="padding: 8px; border: 1px solid #ddd;">Makes no or few assumptions about the data distribution.</td>
                        </tr>
                        <tr>
                            <td style="padding: 8px; border: 1px solid #ddd;"><strong>Data Type</strong></td>
                            <td style="padding: 8px; border: 1px solid #ddd;">Requires interval or ratio scale data.</td>
                            <td style="padding: 8px; border: 1px solid #ddd;">Suitable for nominal, ordinal, interval, or ratio scale data, especially when assumptions for parametric tests are violated.</td>
                        </tr>
                        <tr>
                            <td style="padding: 8px; border: 1px solid #ddd;"><strong>Measures of Central Tendency</strong></td>
                            <td style="padding: 8px; border: 1px solid #ddd;">Focuses on means.</td>
                            <td style="padding: 8px; border: 1px solid #ddd;">Focuses on medians or ranks.</td>
                        </tr>
                        <tr>
                            <td style="padding: 8px; border: 1px solid #ddd;"><strong>Statistical Power</strong></td>
                            <td style="padding: 8px; border: 1px solid #ddd;">Generally more powerful when assumptions are met.</td>
                            <td style="padding: 8px; border: 1px solid #ddd;">Less powerful than parametric tests, but more robust to assumption violations.</td>
                        </tr>
                        <tr>
                            <td style="padding: 8px; border: 1px solid #ddd;"><strong>Sample Size</strong></td>
                            <td style="padding: 8px; border: 1px solid #ddd;">Requires generally larger sample sizes for validity of assumptions.</td>
                            <td style="padding: 8px; border: 1px solid #ddd;">Can be used with small sample sizes.</td>
                        </tr>
                        <tr>
                            <td style="padding: 8px; border: 1px solid #ddd;"><strong>Examples of Tests</strong></td>
                            <td style="padding: 8px; border: 1px solid #ddd;">T-test, ANOVA, Pearson correlation, Z-test.</td>
                            <td style="padding: 8px; border: 1px solid #ddd;">Mann-Whitney U test, Wilcoxon signed-rank test, Kruskal-Wallis H test, Spearman's rank correlation.</td>
                        </tr>
                    </tbody>
                </table>
            </div>

            <h3>Assumptions, Advantages, and Disadvantages</h3>

            <h4>Parametric Statistics</h4>
            <ul>
                <li>
                    <strong>Assumptions:</strong>
                    <ul>
                        <li><strong>Normality:</strong> The dependent variable is normally distributed in the population.</li>
                        <li><strong>Homogeneity of Variance (Homoscedasticity):</strong> The variances of the groups being compared are approximately equal.</li>
                        <li><strong>Independence of Observations:</strong> Each observation is independent of all other observations.</li>
                        <li><strong>Interval or Ratio Scale Data:</strong> The data must be measured on an interval or ratio scale.</li>
                    </ul>
                </li>
                <li>
                    <strong>Advantages:</strong>
                    <ul>
                        <li><strong>More Powerful:</strong> If assumptions are met, parametric tests have greater statistical power, meaning they are more likely to detect a true effect or difference if one exists.</li>
                        <li><strong>Robustness:</strong> Some parametric tests (like t-tests) can be robust to minor violations of normality, especially with large sample sizes, due to the Central Limit Theorem.</li>
                        <li><strong>More Information Utilized:</strong> They utilize more information from the data (mean, standard deviation), leading to more precise estimates and conclusions.</li>
                        <li><strong>Widely Understood:</strong> Parametric tests are well-established and widely understood in various scientific disciplines.</li>
                    </ul>
                </li>
                <li>
                    <strong>Disadvantages:</strong>
                    <ul>
                        <li><strong>Strict Assumptions:</strong> Violation of assumptions can lead to inaccurate or misleading results.</li>
                        <li><strong>Sensitivity to Outliers:</strong> Parametric tests, especially those based on means, can be heavily influenced by outliers.</li>
                        <li><strong>Not Suitable for All Data Types:</strong> Cannot be used with nominal or purely ordinal data.</li>
                        <li><strong>Requires Larger Samples:</strong> Often requires larger sample sizes to satisfy the normality assumption, particularly if the underlying distribution is non-normal.</li>
                    </ul>
                </li>
            </ul>

            <h4>Non-Parametric Statistics</h4>
            <ul>
                <li>
                    <strong>Assumptions:</strong>
                    <ul>
                        <li><strong>Independence of Observations:</strong> Similar to parametric tests, observations should be independent.</li>
                        <li><strong>Random Sampling:</strong> Data should be obtained through random sampling.</li>
                        <li><strong>(Sometimes) Symmetry:</strong> Some non-parametric tests assume symmetry of the distribution, though not necessarily normality.</li>
                    </ul>
                </li>
                <li>
                    <strong>Advantages:</strong>
                    <ul>
                        <li><strong>No Distributional Assumptions:</strong> They do not require the data to be normally distributed, making them suitable for skewed data or when the population distribution is unknown.</li>
                        <li><strong>Handles All Data Types:</strong> Can be used with nominal, ordinal, interval, and ratio data.</li>
                        <li><strong>Robust to Outliers:</strong> Less sensitive to outliers compared to parametric tests because they often use ranks or medians instead of means.</li>
                        <li><strong>Suitable for Small Sample Sizes:</strong> Can be effectively used with small sample sizes where parametric assumptions might not hold.</li>
                        <li><strong>Ease of Computation:</strong> Historically, they were simpler to compute manually, though this is less relevant with modern software.</li>
                    </ul>
                </li>
                <li>
                    <strong>Disadvantages:</strong>
                    <ul>
                        <li><strong>Less Powerful:</strong> Generally have less statistical power than their parametric counterparts when the assumptions of parametric tests are met. This means they might fail to detect a real effect that a parametric test would find.</li>
                        <li><strong>Less Information Utilized:</strong> They often convert data to ranks or categories, thus losing some of the detailed information present in the original data.</li>
                        <li><strong>Limited Scope:</strong> Parametric tests can often answer a broader range of questions about population parameters (e.g., confidence intervals for means).</li>
                        <li><strong>Less Familiarity:</strong> Researchers may be less familiar with non-parametric tests, leading to underutilization even when appropriate.</li>
                    </ul>
                </li>
            </ul>
            <div class="button-group">
                <button class="copy-btn" onclick="copyText(this)">Copy Answer</button>
                <button class="status-btn" data-status-action="read" onclick="setQuestionStatus(this.closest('details'), 'read')">Mark as Read</button>
                <button class="status-btn" data-status-action="unread" onclick="setQuestionStatus(this.closest('details'), 'unread')">Mark as Unread</button>
                <button class="status-btn" data-status-action="doubt" onclick="setQuestionStatus(this.closest('details'), 'doubt')">Mark as Doubt</button>
                <button class="notes-card-btn" onclick="toggleNotes(this.closest('details'))">Add/View Notes</button>
            </div>
            <div class="notes-section">
                <textarea placeholder="Write your notes here..." oninput="saveNotes(this.closest('details'), this.value)"></textarea>
            </div>
        </div>
    </details>

    <details data-status="unread">
        <span class="status-icon read" title="Read">✓</span>
        <span class="status-icon doubt" title="Doubt">!</span>
        <summary>
            <span>Elucidate parametric and non-parametric statistics.</span>
            <time class="ml-2 text-gray-500 dark:text-gray-400" style="white-space: nowrap; overflow: hidden; text-overflow: ellipsis; font-size: clamp(0.4rem, 1.7vw, 0.9rem); color: #888; font-style: italic;">
June 12, 2025
</time>
            <span class="notes-indicator-icon" title="Notes added">📝</span>
        </summary>
        <div class="content">
            <p><strong>Parametric and non-parametric statistics</strong> are two major branches of inferential statistics, each with its own set of assumptions and applicability. The choice between them largely depends on the characteristics of the data and the research question.</p>

            <h3>Parametric Statistics: Elucidation</h3>
            <p>Parametric tests are called "parametric" because they make assumptions about the <strong>parameters</strong> of the population distribution. Specifically, they assume that the data comes from a population that follows a known probability distribution, typically the <strong>normal distribution</strong>. These tests work best with continuous data (interval or ratio scale) that can be summarized using parameters like the mean and standard deviation.</p>
            <ul>
                <li><strong>Core Idea:</strong> To estimate population parameters and test hypotheses about them. For instance, comparing the means of two groups (t-test) assumes that the data in both groups are normally distributed.</li>
                <li><strong>Assumptions:</strong>
                    <ul>
                        <li><strong>Normality:</strong> Data are drawn from a normally distributed population.</li>
                        <li><strong>Homogeneity of Variances:</strong> The variances of the groups being compared are roughly equal.</li>
                        <li><strong>Independence of Observations:</strong> Each data point is independent of others.</li>
                        <li><strong>Scale of Measurement:</strong> Data must be on an interval or ratio scale.</li>
                    </ul>
                </li>
                <li><strong>Examples:</strong>
                    <ul>
                        <li><strong>Independent Samples T-test:</strong> Compares means of two independent groups (e.g., mean test scores of two different teaching methods).</li>
                        <li><strong>Paired Samples T-test:</strong> Compares means of two related groups (e.g., pre-test vs. post-test scores for the same individuals).</li>
                        <li><strong>Analysis of Variance (ANOVA):</strong> Compares means of three or more independent groups.</li>
                        <li><strong>Pearson Correlation:</strong> Measures the linear relationship between two normally distributed continuous variables.</li>
                    </ul>
                </li>
                <li><strong>When to Use:</strong> When data are normally distributed, variances are homogeneous, and sample sizes are sufficiently large (often $>30$ for the Central Limit Theorem to apply, even if underlying distribution is not perfectly normal). They are statistically more powerful when their assumptions are met.</li>
            </ul>

            <h3>Non-Parametric Statistics: Elucidation</h3>
            <p>Non-parametric tests are "distribution-free" because they do not assume that the data follows a specific distribution. They are particularly useful when parametric assumptions are violated, or when dealing with ordinal or nominal data that do not fit the requirements of parametric tests. Instead of analyzing means, these tests often work with ranks, medians, or frequencies.</p>
            <ul>
                <li><strong>Core Idea:</strong> To test hypotheses about population medians, ranks, or frequencies, rather than strict parameters. They are robust to outliers and skewed distributions.</li>
                <li><strong>Assumptions:</strong>
                    <ul>
                        <li>Fewer and less stringent assumptions than parametric tests.</li>
                        <li>Often assume independence of observations.</li>
                        <li>Some tests may assume symmetry of the distribution, but not necessarily normality.</li>
                    </ul>
                </li>
                <li><strong>Examples:</strong>
                    <ul>
                        <li><strong>Mann-Whitney U Test:</strong> Non-parametric alternative to the independent samples t-test, comparing the medians or distributions of two independent groups.</li>
                        <li><strong>Wilcoxon Signed-Rank Test:</strong> Non-parametric alternative to the paired samples t-test, comparing two related samples.</li>
                        <li><strong>Kruskal-Wallis H Test:</strong> Non-parametric alternative to one-way ANOVA, for comparing medians of three or more independent groups.</li>
                        <li><strong>Spearman's Rank Correlation:</strong> Measures the monotonic relationship between two variables, based on their ranks.</li>
                        <li><strong>Chi-Square Test:</strong> Used for analyzing categorical data (e.g., testing association between two categorical variables).</li>
                    </ul>
                </li>
                <li><strong>When to Use:</strong> When data are not normally distributed, variances are unequal, dealing with ordinal or nominal data, or when sample sizes are small. While less powerful than parametric tests (if assumptions are met), they offer greater flexibility and robustness.</li>
            </ul>
            <p>The decision to use parametric or non-parametric methods is crucial for the validity of statistical conclusions. It requires careful consideration of data characteristics, research questions, and the underlying assumptions of each test.</p>
            <div class="button-group">
                <button class="copy-btn" onclick="copyText(this)">Copy Answer</button>
                <button class="status-btn" data-status-action="read" onclick="setQuestionStatus(this.closest('details'), 'read')">Mark as Read</button>
                <button class="status-btn" data-status-action="unread" onclick="setQuestionStatus(this.closest('details'), 'unread')">Mark as Unread</button>
                <button class="status-btn" data-status-action="doubt" onclick="setQuestionStatus(this.closest('details'), 'doubt')">Mark as Doubt</button>
                <button class="notes-card-btn" onclick="toggleNotes(this.closest('details'))">Add/View Notes</button>
            </div>
            <div class="notes-section">
                <textarea placeholder="Write your notes here..." oninput="saveNotes(this.closest('details'), this.value)"></textarea>
            </div>
        </div>
    </details>

    <details data-status="unread">
        <span class="status-icon read" title="Read">✓</span>
        <span class="status-icon doubt" title="Doubt">!</span>
        <summary>
            <span>Discuss the rationale for using non-parametric statistics.</span>
            <time class="ml-2 text-gray-500 dark:text-gray-400" style="white-space: nowrap; overflow: hidden; text-overflow: ellipsis; font-size: clamp(0.4rem, 1.7vw, 0.9rem); color: #888; font-style: italic;">
June 12, 2025
</time>
            <span class="notes-indicator-icon" title="Notes added">📝</span>
        </summary>
        <div class="content">
            <p>The rationale for using <strong>non-parametric statistics</strong> stems primarily from situations where the strict assumptions required by parametric tests cannot be met or where the nature of the data itself makes parametric tests inappropriate. While parametric tests are often preferred due to their higher statistical power, non-parametric tests offer robust alternatives in a variety of common research scenarios.</p>

            <h3>Rationale for Using Non-Parametric Statistics</h3>
            <ul>
                <li>
                    <strong>1. Violation of Parametric Assumptions:</strong>
                    <p>The most common reason for using non-parametric tests is when the data seriously violate the assumptions of parametric tests, especially:</p>
                    <ul>
                        <li><strong>Non-Normal Distribution:</strong> Many parametric tests (e.g., t-tests, ANOVA) assume that the data are drawn from a normally distributed population. If the data are significantly skewed, have heavy tails, or show other non-normal patterns, parametric tests can yield inaccurate results or misleading p-values. Non-parametric tests do not require this assumption, making them suitable for such data.</li>
                        <li><strong>Heterogeneity of Variance:</strong> Parametric tests often assume that the variances of the populations being compared are equal (homoscedasticity). If this assumption is violated, particularly with unequal sample sizes, parametric tests can be unreliable. Non-parametric tests are generally more robust to unequal variances.</li>
                    </ul>
                </li>
                <li>
                    <strong>2. Nature of the Data (Scale of Measurement):</strong>
                    <p>Non-parametric tests are particularly well-suited for data measured on non-interval scales:</p>
                    <ul>
                        <li><strong>Ordinal Data:</strong> Data that can be ranked but do not have equal intervals between values (e.g., Likert scales: strongly agree, agree, neutral, disagree, strongly disagree; education levels: high school, bachelor's, master's, PhD). Parametric tests are inappropriate for such data as they operate on means, which are not meaningful for ranks. Non-parametric tests, like the Mann-Whitney U test or Wilcoxon signed-rank test, are designed to work with ranked data.</li>
                        <li><strong>Nominal Data:</strong> Categorical data without any inherent order (e.g., gender, type of car, political affiliation). These data are analyzed using non-parametric tests like the Chi-square test, which deal with frequencies and proportions.</li>
                    </ul>
                </li>
                <li>
                    <strong>3. Small Sample Sizes:</strong>
                    <p>With very small sample sizes, it becomes difficult to assess the distribution of the data, and the Central Limit Theorem (which helps justify parametric tests for non-normal data in large samples) may not apply. In such cases, non-parametric tests are often preferred because they do not rely on large sample assumptions for their validity.</p>
                </li>
                <li>
                    <strong>4. Presence of Outliers:</strong>
                    <p>Parametric tests, especially those based on means, are highly sensitive to extreme values or outliers, which can heavily skew the mean and standard deviation, leading to erroneous conclusions. Non-parametric tests, which often use ranks or medians, are much more robust to outliers as they are less affected by extreme values.</p>
                </li>
                <li>
                    <strong>5. When the Research Question Focuses on Medians or Distributions:</strong>
                    <p>Sometimes, the research question is not about comparing means but rather comparing medians or the overall distributions of groups. For example, if data is heavily skewed (e.g., income), the median might be a more representative measure of central tendency than the mean. Non-parametric tests directly address such questions.</p>
                </li>
            </ul>
            <p>In essence, non-parametric statistics provide a valuable toolkit for researchers when their data do not conform to the ideal conditions for parametric analysis. They offer a flexible and robust alternative, ensuring that meaningful statistical inferences can still be drawn even from challenging datasets, albeit sometimes at the cost of slightly reduced statistical power compared to ideal parametric scenarios.</p>
            <div class="button-group">
                <button class="copy-btn" onclick="copyText(this)">Copy Answer</button>
                <button class="status-btn" data-status-action="read" onclick="setQuestionStatus(this.closest('details'), 'read')">Mark as Read</button>
                <button class="status-btn" data-status-action="unread" onclick="setQuestionStatus(this.closest('details'), 'unread')">Mark as Unread</button>
                <button class="status-btn" data-status-action="doubt" onclick="setQuestionStatus(this.closest('details'), 'doubt')">Mark as Doubt</button>
                <button class="notes-card-btn" onclick="toggleNotes(this.closest('details'))">Add/View Notes</button>
            </div>
            <div class="notes-section">
                <textarea placeholder="Write your notes here..." oninput="saveNotes(this.closest('details'), this.value)"></textarea>
            </div>
        </div>
    </details>

    <details data-status="unread">
        <span class="status-icon read" title="Read">✓</span>
        <span class="status-icon doubt" title="Doubt">!</span>
        <summary>
            <span>Describe the use of non-parametric tests.</span>
            <time class="ml-2 text-gray-500 dark:text-gray-400" style="white-space: nowrap; overflow: hidden; text-overflow: ellipsis; font-size: clamp(0.4rem, 1.7vw, 0.9rem); color: #888; font-style: italic;">
June 12, 2025
</time>
            <span class="notes-indicator-icon" title="Notes added">📝</span>
        </summary>
        <div class="content">
            <p><strong>Non-parametric tests</strong> are statistical methods that do not assume that the data follow a specific probability distribution (like the normal distribution) or that the population parameters are known. They are often called "distribution-free" tests and are particularly useful in situations where parametric assumptions are violated or when dealing with certain types of data.</p>

            <h3>Key Uses of Non-Parametric Tests</h3>
            <p>Non-parametric tests find their application in various scenarios, primarily when:</p>
            <ul>
                <li>
                    <strong>1. Data are Not Normally Distributed:</strong>
                    <p>This is the most common reason. If your continuous data are significantly skewed or have heavy tails, and transformations do not normalize them, non-parametric tests provide valid alternatives. For example, income data is often highly skewed; in such cases, comparing medians using a non-parametric test might be more appropriate than comparing means using a parametric test.</p>
                </li>
                <li>
                    <strong>2. Data are Ordinal:</strong>
                    <p>When data consist of ranks or categories with a meaningful order but unequal intervals between them, non-parametric tests are essential. Examples include:</p>
                    <ul>
                        <li>Ratings (e.g., satisfaction on a scale of 1-5, pain levels: mild, moderate, severe).</li>
                        <li>Educational attainment levels (e.g., high school, bachelor's, master's, PhD).</li>
                        <li>Preference rankings (e.g., ranking products from most to least preferred).</li>
                    </ul>
                    <p>Parametric tests that rely on means and standard deviations are not appropriate for ordinal data, as these measures do not have the same meaning for ordered categories.</p>
                </li>
                <li>
                    <strong>3. Data are Nominal (Categorical):</strong>
                    <p>For purely categorical data with no inherent order (e.g., gender, marital status, yes/no responses), non-parametric tests that analyze frequencies and proportions are used.</p>
                </li>
                <li>
                    <strong>4. Small Sample Sizes:</strong>
                    <p>When sample sizes are small, it's often difficult to definitively assess the distribution of the data, and the Central Limit Theorem (which suggests normality of sample means for large samples) may not apply. Non-parametric tests are often suitable for small samples as they do not impose strict distributional assumptions.</p>
                </li>
                <li>
                    <strong>5. Presence of Outliers:</strong>
                    <p>Non-parametric tests are generally more robust to outliers than parametric tests. Since many non-parametric tests operate on ranks rather than raw data values, extreme scores have less influence on the test statistic. This makes them a safer choice when outliers are present and cannot be justifiably removed or transformed.</p>
                </li>
                <li>
                    <strong>6. When Comparing Medians or Distributions:</strong>
                    <p>Sometimes the research question is specifically about differences in medians rather than means, or about whether two distributions are the same. Non-parametric tests are designed to answer these types of questions directly.</p>
                </li>
            </ul>

            <h4>Examples of Specific Non-Parametric Tests and Their Uses:</h4>
            <ul>
                <li>
                    <strong>Mann-Whitney U Test:</strong> Used to compare the medians or distributions of two independent groups when the dependent variable is ordinal or continuous but not normally distributed (alternative to independent samples t-test).
                    <p><strong>Use Case:</strong> Comparing satisfaction scores (ordinal) between two different customer service teams.</p>
                </li>
                <li>
                    <strong>Wilcoxon Signed-Rank Test:</strong> Used to compare two related (paired) samples or repeated measurements on a single sample when the dependent variable is ordinal or continuous but not normally distributed (alternative to paired samples t-test).
                    <p><strong>Use Case:</strong> Comparing patient pain levels (ordinal) before and after a treatment.</p>
                </li>
                <li>
                    <strong>Kruskal-Wallis H Test:</strong> Used to compare the medians or distributions of three or more independent groups when the dependent variable is ordinal or continuous but not normally distributed (alternative to one-way ANOVA).
                    <p><strong>Use Case:</strong> Comparing the effectiveness rankings of three different types of fertilizers on plant growth.</p>
                </li>
                <li>
                    <strong>Friedman Test:</strong> Used to compare three or more related samples or repeated measurements when the dependent variable is ordinal or continuous but not normally distributed (alternative to repeated measures ANOVA).
                    <p><strong>Use Case:</strong> Comparing the preferences of a group of consumers for three different flavors of a new drink, where each consumer tastes and ranks all three.</p>
                </li>
                <li>
                    <strong>Spearman's Rank Correlation Coefficient:</strong> Used to measure the strength and direction of a monotonic relationship between two ordinal variables, or between one ordinal and one continuous variable (alternative to Pearson correlation when normality is violated or data are ordinal).
                    <p><strong>Use Case:</strong> Assessing the relationship between a student's study hours and their rank in a class.</p>
                </li>
                <li>
                    <strong>Chi-Square Test of Independence:</strong> Used to examine the association between two categorical (nominal) variables.
                    <p><strong>Use Case:</strong> Determining if there's a relationship between gender and preferred political party.</p>
                </li>
            </ul>
            <p>By understanding these uses, researchers can make informed decisions about when to employ non-parametric methods, ensuring the validity and appropriateness of their statistical inferences.</p>
            <div class="button-group">
                <button class="copy-btn" onclick="copyText(this)">Copy Answer</button>
                <button class="status-btn" data-status-action="read" onclick="setQuestionStatus(this.closest('details'), 'read')">Mark as Read</button>
                <button class="status-btn" data-status-action="unread" onclick="setQuestionStatus(this.closest('details'), 'unread')">Mark as Unread</button>
                <button class="status-btn" data-status-action="doubt" onclick="setQuestionStatus(this.closest('details'), 'doubt')">Mark as Doubt</button>
                <button class="notes-card-btn" onclick="toggleNotes(this.closest('details'))">Add/View Notes</button>
            </div>
            <div class="notes-section">
                <textarea placeholder="Write your notes here..." oninput="saveNotes(this.closest('details'), this.value)"></textarea>
            </div>
        </div>
    </details>

</section>

<section class="topic-card" id="card-central-tendency-dispersion">
    <h2> 📊 MEASURES OF CENTRAL TENDENCY & DISPERSION</h2>

    <details data-status="unread">
        <span class="status-icon read" title="Read">✓</span>
        <span class="status-icon doubt" title="Doubt">!</span>
        <summary>
            <span>Describe the measures of central tendency (mean, median, mode) and measures of dispersion (range, SD, variance).</span>
            <time class="ml-2 text-gray-500 dark:text-gray-400" style="white-space: nowrap; overflow: hidden; text-overflow: ellipsis; font-size: clamp(0.4rem, 1.7vw, 0.9rem); color: #888; font-style: italic;">
June 12, 2025
</time>
            <span class="notes-indicator-icon" title="Notes added">📝</span>
        </summary>
        <div class="content">
            <p><strong>Measures of central tendency</strong> and <strong>measures of dispersion</strong> are fundamental concepts in descriptive statistics. They provide concise summaries of a dataset, allowing us to understand its typical value and how spread out its values are.</p>

            <h3>Measures of Central Tendency</h3>
            <p>These measures describe the center point or typical value of a dataset. They represent where most of the data points cluster.</p>
            <ul>
                <li>
                    <strong>1. Mean ($\bar{x}$ or $\mu$):</strong>
                    <p>The most common measure of central tendency, often referred to as the "average." It is calculated by summing all the values in a dataset and dividing by the number of values.</p>
                    <ul>
                        <li><strong>Calculation:</strong>
                            $$ \text{Mean} = \frac{\sum x}{n} $$
                            where $\sum x$ is the sum of all values and $n$ is the number of values.</li>
                        <li><strong>Advantages:</strong> Uses all data points, provides a stable measure for large datasets, and is suitable for further statistical analysis.</li>
                        <li><strong>Disadvantages:</strong> Highly sensitive to outliers (extreme values).</li>
                        <li><strong>Example:</strong> For the dataset $\{10, 20, 30, 40, 50\}$, the mean is $(10+20+30+40+50)/5 = 150/5 = 30$.</li>
                    </ul>
                </li>
                <li>
                    <strong>2. Median:</strong>
                    <p>The middle value in an ordered dataset. To find the median, the data must first be arranged in ascending or descending order.</p>
                    <ul>
                        <li><strong>Calculation:</strong>
                            <ul>
                                <li>If $n$ is odd, the median is the value at the $((n+1)/2)^{th}$ position.</li>
                                <li>If $n$ is even, the median is the average of the two middle values at the $(n/2)^{th}$ and $(n/2 + 1)^{th}$ positions.</li>
                            </ul>
                        </li>
                        <li><strong>Advantages:</strong> Not affected by outliers, suitable for skewed distributions and ordinal data.</li>
                        <li><strong>Disadvantages:</strong> Does not use all data points in its calculation.</li>
                        <li><strong>Example (odd $n$):</strong> For $\{10, 20, 30, 40, 50\}$, the median is $30$.</li>
                        <li><strong>Example (even $n$):</strong> For $\{10, 20, 30, 40\}$, the median is $(20+30)/2 = 25$.</li>
                    </ul>
                </li>
                <li>
                    <strong>3. Mode:</strong>
                    <p>The value that appears most frequently in a dataset.</p>
                    <ul>
                        <li><strong>Calculation:</strong> Simply identify the value(s) with the highest frequency. A dataset can have one mode (unimodal), two modes (bimodal), multiple modes (multimodal), or no mode if all values appear with the same frequency.</li>
                        <li><strong>Advantages:</strong> Can be used for all types of data (nominal, ordinal, interval, ratio), not affected by outliers.</li>
                        <li><strong>Disadvantages:</strong> May not be unique, may not exist, and does not use all data points.</li>
                        <li><strong>Example:</strong> For $\{10, 20, 20, 30, 40\}$, the mode is $20$. For $\{10, 20, 30, 40\}$, there is no mode.</li>
                    </ul>
                </li>
            </ul>

            <h3>Measures of Dispersion (or Variability)</h3>
            <p>These measures describe the spread or variability of a dataset. They indicate how much the individual data points differ from the center or from each other.</p>
            <ul>
                <li>
                    <strong>1. Range:</strong>
                    <p>The simplest measure of dispersion, calculated as the difference between the highest and lowest values in a dataset.</p>
                    <ul>
                        <li><strong>Calculation:</strong>
                            $$ \text{Range} = \text{Maximum Value} - \text{Minimum Value} $$
                        </li>
                        <li><strong>Advantages:</strong> Easy to calculate and understand.</li>
                        <li><strong>Disadvantages:</strong> Only uses two values (extremes), highly sensitive to outliers, and does not provide information about the distribution of values in between.</li>
                        <li><strong>Example:</strong> For $\{10, 20, 30, 40, 50\}$, the range is $50 - 10 = 40$.</li>
                    </ul>
                </li>
                <li>
                    <strong>2. Variance ($s^2$ or $\sigma^2$):</strong>
                    <p>Measures the average of the squared differences from the mean. It quantifies how far each number in the set is from the mean and therefore from every other number in the set.</p>
                    <ul>
                        <li><strong>Calculation (Sample Variance):</strong>
                            $$ s^2 = \frac{\sum (x_i - \bar{x})^2}{n-1} $$
                            where $x_i$ is each data point, $\bar{x}$ is the sample mean, and $n$ is the number of data points. For population variance, divide by $N$.</li>
                        <li><strong>Advantages:</strong> Uses all data points, provides a precise measure of spread, and is a prerequisite for many advanced statistical analyses.</li>
                        <li><strong>Disadvantages:</strong> Units are squared, making it less intuitive to interpret in original units; sensitive to outliers.</li>
                        <li><strong>Example:</strong> For $\{10, 20, 30, 40, 50\}$ (mean $= 30$):
                            $$ s^2 = \frac{(10-30)^2 + (20-30)^2 + (30-30)^2 + (40-30)^2 + (50-30)^2}{5-1} $$
                            $$ s^2 = \frac{(-20)^2 + (-10)^2 + (0)^2 + (10)^2 + (20)^2}{4} = \frac{400 + 100 + 0 + 100 + 400}{4} = \frac{1000}{4} = 250 $$
                        </li>
                    </ul>
                </li>
                <li>
                    <strong>3. Standard Deviation (SD, $s$ or $\sigma$):</strong>
                    <p>The square root of the variance. It is the most commonly used measure of dispersion because it is expressed in the same units as the data, making it easier to interpret than variance.</p>
                    <ul>
                        <li><strong>Calculation:</strong>
                            $$ s = \sqrt{\frac{\sum (x_i - \bar{x})^2}{n-1}} $$
                        </li>
                        <li><strong>Advantages:</strong> Expressed in original units, uses all data points, and is widely understood.</li>
                        <li><strong>Disadvantages:</strong> Still sensitive to outliers.</li>
                        <li><strong>Example:</strong> For the above dataset, the standard deviation is $s = \sqrt{250} \approx 15.81$. This means, on average, each data point is about $15.81$ units away from the mean.</li>
                    </ul>
                </li>
            </ul>
            <p>Together, measures of central tendency and dispersion offer a comprehensive numerical summary of a dataset, providing insights into both its typical value and its variability.</p>
            <div class="button-group">
                <button class="copy-btn" onclick="copyText(this)">Copy Answer</button>
                <button class="status-btn" data-status-action="read" onclick="setQuestionStatus(this.closest('details'), 'read')">Mark as Read</button>
                <button class="status-btn" data-status-action="unread" onclick="setQuestionStatus(this.closest('details'), 'unread')">Mark as Unread</button>
                <button class="status-btn" data-status-action="doubt" onclick="setQuestionStatus(this.closest('details'), 'doubt')">Mark as Doubt</button>
                <button class="notes-card-btn" onclick="toggleNotes(this.closest('details'))">Add/View Notes</button>
            </div>
            <div class="notes-section">
                <textarea placeholder="Write your notes here..." oninput="saveNotes(this.closest('details'), this.value)"></textarea>
            </div>
        </div>
    </details>

    <details data-status="unread">
        <span class="status-icon read" title="Read">✓</span>
        <span class="status-icon doubt" title="Doubt">!</span>
        <summary>
            <span>Explain frequency distribution (grouped/ungrouped) and types.</span>
            <time class="ml-2 text-gray-500 dark:text-gray-400" style="white-space: nowrap; overflow: hidden; text-overflow: ellipsis; font-size: clamp(0.4rem, 1.7vw, 0.9rem); color: #888; font-style: italic;">
June 12, 2025
</time>
            <span class="notes-indicator-icon" title="Notes added">📝</span>
        </summary>
        <div class="content">
            <p>A <strong>frequency distribution</strong> is a tabulation or graphical representation of the number of times each value (or range of values) appears in a dataset. It is a fundamental tool in descriptive statistics used to organize raw data into a more meaningful form, showing how frequencies are distributed across different categories or intervals.</p>

            <h3>Types of Frequency Distributions Based on Grouping</h3>
            <ul>
                <li>
                    <strong>1. Ungrouped Frequency Distribution (or Simple Frequency Distribution):</strong>
                    <p>This type of distribution is used for discrete variables (where values are distinct and countable, often small in range) or for continuous variables when the number of distinct values is small. Each individual value in the dataset is listed, along with the number of times it occurs (its frequency).</p>
                    <ul>
                        <li><strong>When to Use:</strong> Suitable for small datasets or when the data has a limited number of unique values.</li>
                        <li><strong>Example:</strong> Number of siblings for 15 students: $\{1, 0, 2, 1, 3, 0, 1, 2, 1, 0, 1, 2, 0, 1, 1\}$
                            <table style="width:auto; border-collapse: collapse; margin-top: 10px;">
                                <thead>
                                    <tr style="background-color: #f2f2f2;">
                                        <th style="padding: 8px; border: 1px solid #ddd; text-align: left;">Number of Siblings (X)</th>
                                        <th style="padding: 8px; border: 1px solid #ddd; text-align: left;">Tally</th>
                                        <th style="padding: 8px; border: 1px solid #ddd; text-align: left;">Frequency (f)</th>
                                    </tr>
                                </thead>
                                <tbody>
                                    <tr>
                                        <td style="padding: 8px; border: 1px solid #ddd;">0</td>
                                        <td style="padding: 8px; border: 1px solid #ddd;">IIII</td>
                                        <td style="padding: 8px; border: 1px solid #ddd;">4</td>
                                    </tr>
                                    <tr>
                                        <td style="padding: 8px; border: 1px solid #ddd;">1</td>
                                        <td style="padding: 8px; border: 1px solid #ddd;">IIII I</td>
                                        <td style="padding: 8px; border: 1px solid #ddd;">6</td>
                                    </tr>
                                    <tr>
                                        <td style="padding: 8px; border: 1px solid #ddd;">2</td>
                                        <td style="padding: 8px; border: 1px solid #ddd;">III</td>
                                        <td style="padding: 8px; border: 1px solid #ddd;">3</td>
                                    </tr>
                                    <tr>
                                        <td style="padding: 8px; border: 1px solid #ddd;">3</td>
                                        <td style="padding: 8px; border: 1px solid #ddd;">I</td>
                                        <td style="padding: 8px; border: 1px solid #ddd;">1</td>
                                    </tr>
                                    <tr>
                                        <td style="padding: 8px; border: 1px solid #ddd;"><strong>Total</strong></td>
                                        <td style="padding: 8px; border: 1px solid #ddd;"></td>
                                        <td style="padding: 8px; border: 1px solid #ddd;"><strong>14</strong></td>
                                    </tr>
                                </tbody>
                            </table>
                            <p class="text-xs text-gray-600 dark:text-gray-400 mt-1">Note: There seems to be an error in the sum of the frequencies in the example, it should be 15, not 14.</p>
                        </li>
                    </ul>
                </li>
                <li>
                    <strong>2. Grouped Frequency Distribution:</strong>
                    <p>This type is used when dealing with a large number of distinct values or continuous variables spanning a wide range. The data are grouped into classes or intervals, and the frequency for each class interval is recorded. This makes the data more manageable and easier to interpret.</p>
                    <ul>
                        <li><strong>When to Use:</strong> Essential for large datasets, especially with continuous variables, to condense and summarize information effectively.</li>
                        <li><strong>Key Components:</strong>
                            <ul>
                                <li><strong>Class Interval:</strong> A range of values (e.g., 50-59, 60-69).</li>
                                <li><strong>Class Limits:</strong> The lower and upper boundaries of a class interval (e.g., 50 and 59).</li>
                                <li><strong>Class Boundary:</strong> Precise values that separate classes, used to avoid gaps or overlaps (e.g., 49.5, 59.5).</li>
                                <li><strong>Class Midpoint:</strong> The middle value of a class interval, used for calculations (e.g., $(50+59)/2 = 54.5$).</li>
                                <li><strong>Class Width (or Size):</strong> The difference between the upper and lower class boundaries of a class interval (e.g., $59.5 - 49.5 = 10$).</li>
                            </ul>
                        </li>
                        <li><strong>Example:</strong> Test scores of 20 students (out of 100):
                            <table style="width:auto; border-collapse: collapse; margin-top: 10px;">
                                <thead>
                                    <tr style="background-color: #f2f2f2;">
                                        <th style="padding: 8px; border: 1px solid #ddd; text-align: left;">Class Interval (Scores)</th>
                                        <th style="padding: 8px; border: 1px solid #ddd; text-align: left;">Frequency (f)</th>
                                    </tr>
                                </thead>
                                <tbody>
                                    <tr>
                                        <td style="padding: 8px; border: 1px solid #ddd;">50 - 59</td>
                                        <td style="padding: 8px; border: 1px solid #ddd;">3</td>
                                    </tr>
                                    <tr>
                                        <td style="padding: 8px; border: 1px solid #ddd;">60 - 69</td>
                                        <td style="padding: 8px; border: 1px solid #ddd;">7</td>
                                    </tr>
                                    <tr>
                                        <td style="padding: 8px; border: 1px solid #ddd;">70 - 79</td>
                                        <td style="padding: 8px; border: 1px solid #ddd;">5</td>
                                    </tr>
                                    <tr>
                                        <td style="padding: 8px; border: 1px solid #ddd;">80 - 89</td>
                                        <td style="padding: 8px; border: 1px solid #ddd;">3</td>
                                    </tr>
                                    <tr>
                                        <td style="padding: 8px; border: 1px solid #ddd;">90 - 99</td>
                                        <td style="padding: 8px; border: 1px solid #ddd;">2</td>
                                    </tr>
                                    <tr>
                                        <td style="padding: 8px; border: 1px solid #ddd;"><strong>Total</strong></td>
                                        <td style="padding: 8px; border: 1px solid #ddd;"><strong>20</strong></td>
                                    </tr>
                                </tbody>
                            </table>
                        </li>
                    </ul>
                </li>
            </ul>

            <h3>Other Types of Frequency Distributions</h3>
            <p>Beyond grouping, frequency distributions can also be presented in different forms to highlight specific aspects of the data:</p>
            <ul>
                <li>
                    <strong>1. Relative Frequency Distribution:</strong>
                    <p>Shows the proportion or percentage of observations falling into each category or class interval. It is calculated by dividing the frequency of each category by the total number of observations.</p>
                    <ul>
                        <li><strong>Calculation:</strong>
                            $$ \text{Relative Frequency} = \frac{\text{Frequency of Category}}{\text{Total Number of Observations}} $$
                        </li>
                        <li><strong>Use:</strong> Useful for comparing distributions of different sample sizes.</li>
                    </ul>
                </li>
                <li>
                    <strong>2. Cumulative Frequency Distribution:</strong>
                    <p>Shows the total number of observations that fall below the upper boundary of each class interval. It is obtained by successively adding the frequencies from the lowest class interval upwards.</p>
                    <ul>
                        <li><strong>Use:</strong> Helps in understanding the number of observations below a certain value or threshold, particularly useful for percentile calculations.</li>
                    </ul>
                </li>
                <li>
                    <strong>3. Cumulative Relative Frequency Distribution:</strong>
                    <p>Combines relative and cumulative frequencies, showing the proportion of observations falling below the upper boundary of each class interval.</p>
                    <ul>
                        <li><strong>Use:</strong> Provides a quick way to see proportions below certain points.</li>
                    </ul>
                </li>
            </ul>
            <p>Frequency distributions are the first step in analyzing raw data, providing a structured overview that can then be visualized (e.g., using histograms, bar charts, frequency polygons) and further analyzed using measures of central tendency and dispersion.</p>
            <div class="button-group">
                <button class="copy-btn" onclick="copyText(this)">Copy Answer</button>
                <button class="status-btn" data-status-action="read" onclick="setQuestionStatus(this.closest('details'), 'read')">Mark as Read</button>
                <button class="status-btn" data-status-action="unread" onclick="setQuestionStatus(this.closest('details'), 'unread')">Mark as Unread</button>
                <button class="status-btn" data-status-action="doubt" onclick="setQuestionStatus(this.closest('details'), 'doubt')">Mark as Doubt</button>
                <button class="notes-card-btn" onclick="toggleNotes(this.closest('details'))">Add/View Notes</button>
            </div>
            <div class="notes-section">
                <textarea placeholder="Write your notes here..." oninput="saveNotes(this.closest('details'), this.value)"></textarea>
            </div>
        </div>
    </details>
</section>

<section class="topic-card" id="card-4">

<h2>📌 CORRELATION (SPEARMAN, PEARSON, PARTIAL, BISERIAL, ETC.)</h2>



<details data-status="unread">

<span class="status-icon read" title="Read">✓</span>

<span class="status-icon doubt" title="Doubt">!</span>

<summary>

<span>Define correlation and compute Spearman’s Rho/Pearson’s Product Moment Coefficient of Correlation using given datasets.</span>

<time class="ml-2 text-gray-500 dark:text-gray-400" style="white-space: nowrap; overflow: hidden; text-overflow: ellipsis; font-size: clamp(0.4rem, 1.7vw, 0.9rem); color: #888; font-style: italic;">

Dec 15, Jun 15, Jun 16, Dec 16, Dec 17, Jun 18, Dec 19, Jun 20, Dec 21, Jun 22, Jun 23, Dec 23

</time>

<span class="notes-indicator-icon" title="Notes added">📝</span>

</summary>

<div class="content">

<p>
    <b>Correlation</b> is a statistical measure that quantifies the extent to which two or more variables are linearly related. It describes the strength and direction of a relationship between two quantitative variables. It's crucial to remember that correlation does not imply causation; it merely indicates how variables tend to change together. The correlation coefficient typically ranges from -1 to +1.
    <ul>
        <li>A value of <b>+1</b> indicates a perfect positive linear relationship: as one variable increases, the other increases proportionally.</li>
        <li>A value of <b>-1</b> indicates a perfect negative linear relationship: as one variable increases, the other decreases proportionally.</li>
        <li>A value of <b>0</b> indicates no linear relationship between the two variables.</li>
    </ul>
</p>

<h3>Pearson’s Product-Moment Coefficient of Correlation (r)</h3>
<p>
    <b>Pearson's r</b>, often referred to as the Pearson correlation coefficient, is the most widely used measure of correlation. It measures the strength and direction of a <b>linear relationship</b> between two continuous variables. It assumes that the data are normally distributed and homoscedastic (i.e., the variance of the data points is consistent across the range of values). The formula for Pearson's r is:
    $$r = \frac{n\sum(xy) - (\sum x)(\sum y)}{\sqrt{[n\sum x^2 - (\sum x)^2][n\sum y^2 - (\sum y)^2]}}$$
    Where:
    <ul>
        <li>$n$ = number of paired observations</li>
        <li>$\sum(xy)$ = sum of the products of the paired scores</li>
        <li>$\sum x$ = sum of the X scores</li>
        <li>$\sum y$ = sum of the Y scores</li>
        <li>$\sum x^2$ = sum of the squared X scores</li>
        <li>$\sum y^2$ = sum of the squared Y scores</li>
    </ul>
</p>

<h4>Computation for Dec 15:</h4>
<p>
    <b>Data 1 (X):</b> [20, 31, 42, 60, 51, 77, 62, 45, 50, 59]<br>
    <b>Data 2 (Y):</b> [21, 34, 39, 59, 53, 79, 61, 47, 48, 58]
</p>
<table class="correlation-table" style="width: 100%; border-collapse: collapse; margin-top: 15px; text-align: center;">
    <thead>
        <tr style="background-color: #f2f2f2;">
            <th style="padding: 8px; border: 1px solid #ddd;">X</th>
            <th style="padding: 8px; border: 1px solid #ddd;">Y</th>
            <th style="padding: 8px; border: 1px solid #ddd;">XY</th>
            <th style="padding: 8px; border: 1px solid #ddd;">X²</th>
            <th style="padding: 8px; border: 1px solid #ddd;">Y²</th>
        </tr>
    </thead>
    <tbody>
        <tr><td style="padding: 8px; border: 1px solid #ddd;">20</td><td style="padding: 8px; border: 1px solid #ddd;">21</td><td style="padding: 8px; border: 1px solid #ddd;">420</td><td style="padding: 8px; border: 1px solid #ddd;">400</td><td style="padding: 8px; border: 1px solid #ddd;">441</td></tr>
        <tr><td style="padding: 8px; border: 1px solid #ddd;">31</td><td style="padding: 8px; border: 1px solid #ddd;">34</td><td style="padding: 8px; border: 1px solid #ddd;">1054</td><td style="padding: 8px; border: 1px solid #ddd;">961</td><td style="padding: 8px; border: 1px solid #ddd;">1156</td></tr>
        <tr><td style="padding: 8px; border: 1px solid #ddd;">42</td><td style="padding: 8px; border: 1px solid #ddd;">39</td><td style="padding: 8px; border: 1px solid #ddd;">1638</td><td style="padding: 8px; border: 1px solid #ddd;">1764</td><td style="padding: 8px; border: 1px solid #ddd;">1521</td></tr>
        <tr><td style="padding: 8px; border: 1px solid #ddd;">60</td><td style="padding: 8px; border: 1px solid #ddd;">59</td><td style="padding: 8px; border: 1px solid #ddd;">3540</td><td style="padding: 8px; border: 1px solid #ddd;">3600</td><td style="padding: 8px; border: 1px solid #ddd;">3481</td></tr>
        <tr><td style="padding: 8px; border: 1px solid #ddd;">51</td><td style="padding: 8px; border: 1px solid #ddd;">53</td><td style="padding: 8px; border: 1px solid #ddd;">2703</td><td style="padding: 8px; border: 1px solid #ddd;">2601</td><td style="padding: 8px; border: 1px solid #ddd;">2809</td></tr>
        <tr><td style="padding: 8px; border: 1px solid #ddd;">77</td><td style="padding: 8px; border: 1px solid #ddd;">79</td><td style="padding: 8px; border: 1px solid #ddd;">6083</td><td style="padding: 8px; border: 1px solid #ddd;">5929</td><td style="padding: 8px; border: 1px solid #ddd;">6241</td></tr>
        <tr><td style="padding: 8px; border: 1px solid #ddd;">62</td><td style="padding: 8px; border: 1px solid #ddd;">61</td><td style="padding: 8px; border: 1px solid #ddd;">3782</td><td style="padding: 8px; border: 1px solid #ddd;">3844</td><td style="padding: 8px; border: 1px solid #ddd;">3721</td></tr>
        <tr><td style="padding: 8px; border: 1px solid #ddd;">45</td><td style="padding: 8px; border: 1px solid #ddd;">47</td><td style="padding: 8px; border: 1px solid #ddd;">2115</td><td style="padding: 8px; border: 1px solid #ddd;">2025</td><td style="padding: 8px; border: 1px solid #ddd;">2209</td></tr>
        <tr><td style="padding: 8px; border: 1px solid #ddd;">50</td><td style="padding: 8px; border: 1px solid #ddd;">48</td><td style="padding: 8px; border: 1px solid #ddd;">2400</td><td style="padding: 8px; border: 1px solid #ddd;">2500</td><td style="padding: 8px; border: 1px solid #ddd;">2304</td></tr>
        <tr><td style="padding: 8px; border: 1px solid #ddd;">59</td><td style="padding: 8px; border: 1px solid #ddd;">58</td><td style="padding: 8px; border: 1px solid #ddd;">3422</td><td style="padding: 8px; border: 1px solid #ddd;">3481</td><td style="padding: 8px; border: 1px solid #ddd;">3364</td></tr>
    </tbody>
    <tfoot>
        <tr style="background-color: #f2f2f2;">
            <th style="padding: 8px; border: 1px solid #ddd;">ΣX = 500</th>
            <th style="padding: 8px; border: 1px solid #ddd;">ΣY = 499</th>
            <th style="padding: 8px; border: 1px solid #ddd;">ΣXY = 27157</th>
            <th style="padding: 8px; border: 1px solid #ddd;">ΣX² = 27105</th>
            <th style="padding: 8px; border: 1px solid #ddd;">ΣY² = 27247</th>
        </tr>
    </tfoot>
</table>
<p style="margin-top: 15px;">
    $n = 10$<br>
    $r = \frac{10(27157) - (500)(499)}{\sqrt{[10(27105) - (500)^2][10(27247) - (499)^2]}}$<br>
    $r = \frac{271570 - 249500}{\sqrt{[271050 - 250000][272470 - 249001]}}$<br>
    $r = \frac{22070}{\sqrt{[21050][23469]}}$<br>
    $r = \frac{22070}{\sqrt{494056450}}$<br>
    $r = \frac{22070}{22227.389}$<br>
    <b>$r \approx 0.9929$</b>
</p>
<p style="margin-top: 10px;">
    <b>Interpretation:</b> A Pearson's r of approximately 0.9929 indicates a very strong positive linear relationship between Data 1 and Data 2 for the Dec 15 dataset. This means that as values in Data 1 increase, values in Data 2 also tend to increase almost perfectly proportionally.
</p>

<h4>Computation for Jun 15:</h4>
<p>
    <b>Data 1 (X):</b> [11, 10, 7, 9, 5, 8, 3, 6, 12, 13]<br>
    <b>Data 2 (Y):</b> [4, 3, 2, 20, 13, 12, 11, 10, 6, 5]
</p>
<table class="correlation-table" style="width: 100%; border-collapse: collapse; margin-top: 15px; text-align: center;">
    <thead>
        <tr style="background-color: #f2f2f2;">
            <th style="padding: 8px; border: 1px solid #ddd;">X</th>
            <th style="padding: 8px; border: 1px solid #ddd;">Y</th>
            <th style="padding: 8px; border: 1px solid #ddd;">XY</th>
            <th style="padding: 8px; border: 1px solid #ddd;">X²</th>
            <th style="padding: 8px; border: 1px solid #ddd;">Y²</th>
        </tr>
    </thead>
    <tbody>
        <tr><td style="padding: 8px; border: 1px solid #ddd;">11</td><td style="padding: 8px; border: 1px solid #ddd;">4</td><td style="padding: 8px; border: 1px solid #ddd;">44</td><td style="padding: 8px; border: 1px solid #ddd;">121</td><td style="padding: 8px; border: 1px solid #ddd;">16</td></tr>
        <tr><td style="padding: 8px; border: 1px solid #ddd;">10</td><td style="padding: 8px; border: 1px solid #ddd;">3</td><td style="padding: 8px; border: 1px solid #ddd;">30</td><td style="padding: 8px; border: 1px solid #ddd;">100</td><td style="padding: 8px; border: 1px solid #ddd;">9</td></tr>
        <tr><td style="padding: 8px; border: 1px solid #ddd;">7</td><td style="padding: 8px; border: 1px solid #ddd;">2</td><td style="padding: 8px; border: 1px solid #ddd;">14</td><td style="padding: 8px; border: 1px solid #ddd;">49</td><td style="padding: 8px; border: 1px solid #ddd;">4</td></tr>
        <tr><td style="padding: 8px; border: 1px solid #ddd;">9</td><td style="padding: 8px; border: 1px solid #ddd;">20</td><td style="padding: 8px; border: 1px solid #ddd;">180</td><td style="padding: 8px; border: 1px solid #ddd;">81</td><td style="padding: 8px; border: 1px solid #ddd;">400</td></tr>
        <tr><td style="padding: 8px; border: 1px solid #ddd;">5</td><td style="padding: 8px; border: 1px solid #ddd;">13</td><td style="padding: 8px; border: 1px solid #ddd;">65</td><td style="padding: 8px; border: 1px solid #ddd;">25</td><td style="padding: 8px; border: 1px solid #ddd;">169</td></tr>
        <tr><td style="padding: 8px; border: 1px solid #ddd;">8</td><td style="padding: 8px; border: 1px solid #ddd;">12</td><td style="padding: 8px; border: 1px solid #ddd;">96</td><td style="padding: 8px; border: 1px solid #ddd;">64</td><td style="padding: 8px; border: 1px solid #ddd;">144</td></tr>
        <tr><td style="padding: 8px; border: 1px solid #ddd;">3</td><td style="padding: 8px; border: 1px solid #ddd;">11</td><td style="padding: 8px; border: 1px solid #ddd;">33</td><td style="padding: 8px; border: 1px solid #ddd;">9</td><td style="padding: 8px; border: 1px solid #ddd;">121</td></tr>
        <tr><td style="padding: 8px; border: 1px solid #ddd;">6</td><td style="padding: 8px; border: 1px solid #ddd;">10</td><td style="padding: 8px; border: 1px solid #ddd;">60</td><td style="padding: 8px; border: 1px solid #ddd;">36</td><td style="padding: 8px; border: 1px solid #ddd;">100</td></tr>
        <tr><td style="padding: 8px; border: 1px solid #ddd;">12</td><td style="padding: 8px; border: 1px solid #ddd;">6</td><td style="padding: 8px; border: 1px solid #ddd;">72</td><td style="padding: 8px; border: 1px solid #ddd;">144</td><td style="padding: 8px; border: 1px solid #ddd;">36</td></tr>
        <tr><td style="padding: 8px; border: 1px solid #ddd;">13</td><td style="padding: 8px; border: 1px solid #ddd;">5</td><td style="padding: 8px; border: 1px solid #ddd;">65</td><td style="padding: 8px; border: 1px solid #ddd;">169</td><td style="padding: 8px; border: 1px solid #ddd;">25</td></tr>
    </tbody>
    <tfoot>
        <tr style="background-color: #f2f2f2;">
            <th style="padding: 8px; border: 1px solid #ddd;">ΣX = 84</th>
            <th style="padding: 8px; border: 1px solid #ddd;">ΣY = 86</th>
            <th style="padding: 8px; border: 1px solid #ddd;">ΣXY = 659</th>
            <th style="padding: 8px; border: 1px solid #ddd;">ΣX² = 798</th>
            <th style="padding: 8px; border: 1px solid #ddd;">ΣY² = 1024</th>
        </tr>
    </tfoot>
</table>
<p style="margin-top: 15px;">
    $n = 10$<br>
    $r = \frac{10(659) - (84)(86)}{\sqrt{[10(798) - (84)^2][10(1024) - (86)^2]}}$<br>
    $r = \frac{6590 - 7224}{\sqrt{[7980 - 7056][10240 - 7396]}}$<br>
    $r = \frac{-634}{\sqrt{[924][2844]}}$<br>
    $r = \frac{-634}{\sqrt{2627016}}$<br>
    $r = \frac{-634}{1620.801}$<br>
    <b>$r \approx -0.3912$</b>
</p>
<p style="margin-top: 10px;">
    <b>Interpretation:</b> A Pearson's r of approximately -0.3912 indicates a weak negative linear relationship between Data 1 and Data 2 for the Jun 15 dataset. This suggests a slight tendency for Data 1 to decrease as Data 2 increases, but the relationship is not strong.
</p>

<h3>Spearman’s Rank-Order Correlation Coefficient ($\rho$ or $r_s$)</h3>
<p>
    <b>Spearman's Rho</b> is a non-parametric measure of the strength and direction of a <b>monotonic relationship</b> between two ranked variables. It is used when data are ordinal (ranks) or when the assumptions for Pearson's r (normality, linearity) are violated for continuous data. It assesses how well the relationship between two variables can be described using a monotonic function (either consistently increasing or consistently decreasing), without requiring that increase/decrease to be linear. The formula for Spearman's Rho is:
    $$\rho = 1 - \frac{6\sum d^2}{n(n^2 - 1)}$$
    Where:
    <ul>
        <li>$d$ = the difference between the ranks of corresponding values for each paired observation</li>
        <li>$n$ = the number of observations (pairs)</li>
    </ul>
</p>

<h4>Computation for Jun 23:</h4>
<p>
    <b>Data A (X):</b> [16, 19, 18, 10, 12, 13, 17, 9, 7, 5]<br>
    <b>Data B (Y):</b> [15, 17, 16, 9, 10, 12, 19, 8, 6, 4]
</p>
<table class="correlation-table" style="width: 100%; border-collapse: collapse; margin-top: 15px; text-align: center;">
    <thead>
        <tr style="background-color: #f2f2f2;">
            <th style="padding: 8px; border: 1px solid #ddd;">X Value</th>
            <th style="padding: 8px; border: 1px solid #ddd;">Rank X (Rx)</th>
            <th style="padding: 8px; border: 1px solid #ddd;">Y Value</th>
            <th style="padding: 8px; border: 1px solid #ddd;">Rank Y (Ry)</th>
            <th style="padding: 8px; border: 1px solid #ddd;">d (Rx - Ry)</th>
            <th style="padding: 8px; border: 1px solid #ddd;">d²</th>
        </tr>
    </thead>
    <tbody>
        <tr><td style="padding: 8px; border: 1px solid #ddd;">16</td><td style="padding: 8px; border: 1px solid #ddd;">5</td><td style="padding: 8px; border: 1px solid #ddd;">15</td><td style="padding: 8px; border: 1px solid #ddd;">5</td><td style="padding: 8px; border: 1px solid #ddd;">0</td><td style="padding: 8px; border: 1px solid #ddd;">0</td></tr>
        <tr><td style="padding: 8px; border: 1px solid #ddd;">19</td><td style="padding: 8px; border: 1px solid #ddd;">1</td><td style="padding: 8px; border: 1px solid #ddd;">17</td><td style="padding: 8px; border: 1px solid #ddd;">2</td><td style="padding: 8px; border: 1px solid #ddd;">-1</td><td style="padding: 8px; border: 1px solid #ddd;">1</td></tr>
        <tr><td style="padding: 8px; border: 1px solid #ddd;">18</td><td style="padding: 8px; border: 1px solid #ddd;">2</td><td style="padding: 8px; border: 1px solid #ddd;">16</td><td style="padding: 8px; border: 1px solid #ddd;">3</td><td style="padding: 8px; border: 1px solid #ddd;">-1</td><td style="padding: 8px; border: 1px solid #ddd;">1</td></tr>
        <tr><td style="padding: 8px; border: 1px solid #ddd;">10</td><td style="padding: 8px; border: 1px solid #ddd;">7</td><td style="padding: 8px; border: 1px solid #ddd;">9</td><td style="padding: 8px; border: 1px solid #ddd;">7</td><td style="padding: 8px; border: 1px solid #ddd;">0</td><td style="padding: 8px; border: 1px solid #ddd;">0</td></tr>
        <tr><td style="padding: 8px; border: 1px solid #ddd;">12</td><td style="padding: 8px; border: 1px solid #ddd;">6</td><td style="padding: 8px; border: 1px solid #ddd;">10</td><td style="padding: 8px; border: 1px solid #ddd;">6</td><td style="padding: 8px; border: 1px solid #ddd;">0</td><td style="padding: 8px; border: 1px solid #ddd;">0</td></tr>
        <tr><td style="padding: 8px; border: 1px solid #ddd;">13</td><td style="padding: 8px; border: 1px solid #ddd;">4</td><td style="padding: 8px; border: 1px solid #ddd;">12</td><td style="padding: 8px; border: 1px solid #ddd;">4</td><td style="padding: 8px; border: 1px solid #ddd;">0</td><td style="padding: 8px; border: 1px solid #ddd;">0</td></tr>
        <tr><td style="padding: 8px; border: 1px solid #ddd;">17</td><td style="padding: 8px; border: 1px solid #ddd;">3</td><td style="padding: 8px; border: 1px solid #ddd;">19</td><td style="padding: 8px; border: 1px solid #ddd;">1</td><td style="padding: 8px; border: 1px solid #ddd;">2</td><td style="padding: 8px; border: 1px solid #ddd;">4</td></tr>
        <tr><td style="padding: 8px; border: 1px solid #ddd;">9</td><td style="padding: 8px; border: 1px solid #ddd;">8</td><td style="padding: 8px; border: 1px solid #ddd;">8</td><td style="padding: 8px; border: 1px solid #ddd;">8</td><td style="padding: 8px; border: 1px solid #ddd;">0</td><td style="padding: 8px; border: 1px solid #ddd;">0</td></tr>
        <tr><td style="padding: 8px; border: 1px solid #ddd;">7</td><td style="padding: 8px; border: 1px solid #ddd;">9</td><td style="padding: 8px; border: 1px solid #ddd;">6</td><td style="padding: 8px; border: 1px solid #ddd;">9</td><td style="padding: 8px; border: 1px solid #ddd;">0</td><td style="padding: 8px; border: 1px solid #ddd;">0</td></tr>
        <tr><td style="padding: 8px; border: 1px solid #ddd;">5</td><td style="padding: 8px; border: 1px solid #ddd;">10</td><td style="padding: 8px; border: 1px solid #ddd;">4</td><td style="padding: 8px; border: 1px solid #ddd;">10</td><td style="padding: 8px; border: 1px solid #ddd;">0</td><td style="padding: 8px; border: 1px solid #ddd;">0</td></tr>
    </tbody>
    <tfoot>
        <tr style="background-color: #f2f2f2;">
            <th colspan="5" style="padding: 8px; border: 1px solid #ddd;"></th>
            <th style="padding: 8px; border: 1px solid #ddd;">Σd² = 6</th>
        </tr>
    </tfoot>
</table>
<p style="margin-top: 15px;">
    $n = 10$<br>
    $\rho = 1 - \frac{6(6)}{10(10^2 - 1)}$<br>
    $\rho = 1 - \frac{36}{10(100 - 1)}$<br>
    $\rho = 1 - \frac{36}{10(99)}$<br>
    $\rho = 1 - \frac{36}{990}$<br>
    $\rho = 1 - 0.03636...$<br>
    <b>$\rho \approx 0.9636$</b>
</p>
<p style="margin-top: 10px;">
    <b>Interpretation:</b> A Spearman's Rho of approximately 0.9636 indicates a very strong positive monotonic relationship between Data A and Data B for the Jun 23 dataset. This means that as ranks in Data A increase, ranks in Data B also consistently increase, suggesting a strong agreement in their relative order.
</p>

<h4>Computation for Dec 23:</h4>
<p>
    <b>Data A (X):</b> [15, 16, 11, 13, 18, 10, 12, 6, 7, 2]<br>
    <b>Data B (Y):</b> [20, 17, 4, 12, 5, 11, 10, 8, 2, 3]
</p>
<table class="correlation-table" style="width: 100%; border-collapse: collapse; margin-top: 15px; text-align: center;">
    <thead>
        <tr style="background-color: #f2f2f2;">
            <th style="padding: 8px; border: 1px solid #ddd;">X Value</th>
            <th style="padding: 8px; border: 1px solid #ddd;">Rank X (Rx)</th>
            <th style="padding: 8px; border: 1px solid #ddd;">Y Value</th>
            <th style="padding: 8px; border: 1px solid #ddd;">Rank Y (Ry)</th>
            <th style="padding: 8px; border: 1px solid #ddd;">d (Rx - Ry)</th>
            <th style="padding: 8px; border: 1px solid #ddd;">d²</th>
        </tr>
    </thead>
    <tbody>
        <tr><td style="padding: 8px; border: 1px solid #ddd;">15</td><td style="padding: 8px; border: 1px solid #ddd;">3</td><td style="padding: 8px; border: 1px solid #ddd;">20</td><td style="padding: 8px; border: 1px solid #ddd;">1</td><td style="padding: 8px; border: 1px solid #ddd;">2</td><td style="padding: 8px; border: 1px solid #ddd;">4</td></tr>
        <tr><td style="padding: 8px; border: 1px solid #ddd;">16</td><td style="padding: 8px; border: 1px solid #ddd;">2</td><td style="padding: 8px; border: 1px solid #ddd;">17</td><td style="padding: 8px; border: 1px solid #ddd;">2</td><td style="padding: 8px; border: 1px solid #ddd;">0</td><td style="padding: 8px; border: 1px solid #ddd;">0</td></tr>
        <tr><td style="padding: 8px; border: 1px solid #ddd;">11</td><td style="padding: 8px; border: 1px solid #ddd;">6</td><td style="padding: 8px; border: 1px solid #ddd;">4</td><td style="padding: 8px; border: 1px solid #ddd;">8</td><td style="padding: 8px; border: 1px solid #ddd;">-2</td><td style="padding: 8px; border: 1px solid #ddd;">4</td></tr>
        <tr><td style="padding: 8px; border: 1px solid #ddd;">13</td><td style="padding: 8px; border: 1px solid #ddd;">4</td><td style="padding: 8px; border: 1px solid #ddd;">12</td><td style="padding: 8px; border: 1px solid #ddd;">4</td><td style="padding: 8px; border: 1px solid #ddd;">0</td><td style="padding: 8px; border: 1px solid #ddd;">0</td></tr>
        <tr><td style="padding: 8px; border: 1px solid #ddd;">18</td><td style="padding: 8px; border: 1px solid #ddd;">1</td><td style="padding: 8px; border: 1px solid #ddd;">5</td><td style="padding: 8px; border: 1px solid #ddd;">7</td><td style="padding: 8px; border: 1px solid #ddd;">-6</td><td style="padding: 8px; border: 1px solid #ddd;">36</td></tr>
        <tr><td style="padding: 8px; border: 1px solid #ddd;">10</td><td style="padding: 8px; border: 1px solid #ddd;">7</td><td style="padding: 8px; border: 1px solid #ddd;">11</td><td style="padding: 8:px; border: 1px solid #ddd;">5</td><td style="padding: 8px; border: 1px solid #ddd;">2</td><td style="padding: 8px; border: 1px solid #ddd;">4</td></tr>
        <tr><td style="padding: 8px; border: 1px solid #ddd;">12</td><td style="padding: 8px; border: 1px solid #ddd;">5</td><td style="padding: 8px; border: 1px solid #ddd;">10</td><td style="padding: 8px; border: 1px solid #ddd;">6</td><td style="padding: 8px; border: 1px solid #ddd;">-1</td><td style="padding: 8px; border: 1px solid #ddd;">1</td></tr>
        <tr><td style="padding: 8px; border: 1px solid #ddd;">6</td><td style="padding: 8px; border: 1px solid #ddd;">9</td><td style="padding: 8px; border: 1px solid #ddd;">8</td><td style="padding: 8px; border: 1px solid #ddd;">7</td><td style="padding: 8px; border: 1px solid #ddd;">2</td><td style="padding: 8px; border: 1px solid #ddd;">4</td></tr>
        <tr><td style="padding: 8px; border: 1px solid #ddd;">7</td><td style="padding: 8px; border: 1px solid #ddd;">8</td><td style="padding: 8px; border: 1px solid #ddd;">2</td><td style="padding: 8px; border: 1px solid #ddd;">10</td><td style="padding: 8px; border: 1px solid #ddd;">-2</td><td style="padding: 8px; border: 1px solid #ddd;">4</td></tr>
        <tr><td style="padding: 8px; border: 1px solid #ddd;">2</td><td style="padding: 8px; border: 1px solid #ddd;">10</td><td style="padding: 8px; border: 1px solid #ddd;">3</td><td style="padding: 8px; border: 1px solid #ddd;">9</td><td style="padding: 8px; border: 1px solid #ddd;">1</td><td style="padding: 8px; border: 1px solid #ddd;">1</td></tr>
    </tbody>
    <tfoot>
        <tr style="background-color: #f2f2f2;">
            <th colspan="5" style="padding: 8px; border: 1px solid #ddd;"></th>
            <th style="padding: 8px; border: 1px solid #ddd;">Σd² = 58</th>
        </tr>
    </tfoot>
</table>
<p style="margin-top: 15px;">
    $n = 10$<br>
    $\rho = 1 - \frac{6(58)}{10(10^2 - 1)}$<br>
    $\rho = 1 - \frac{348}{10(100 - 1)}$<br>
    $\rho = 1 - \frac{348}{10(99)}$<br>
    $\rho = 1 - \frac{348}{990}$<br>
    $\rho = 1 - 0.351515...$<br>
    <b>$\rho \approx 0.6485$</b>
</p>
<p style="margin-top: 10px;">
    <b>Interpretation:</b> A Spearman's Rho of approximately 0.6485 indicates a moderately strong positive monotonic relationship between Data A and Data B for the Dec 23 dataset. While there's a tendency for ranks to move in the same direction, the relationship is not as perfectly consistent as in the Jun 23 example.
</p>

<h3>Partial Correlation</h3>
<p style="margin-top: 15px;">
    <b>Partial correlation</b> is a statistical technique used to measure the degree of association between two variables while statistically controlling for (or "partialling out") the effects of one or more additional variables. It answers the question: "What is the correlation between variable X and variable Y, if the influence of variable Z were removed from both X and Y?" This is particularly useful in observational studies where confounding variables might obscure or inflate a true relationship.
</p>
<h4>Example:</h4>
<p style="margin-top: 10px;">
    Consider the relationship between <b>hours of sunshine (X)</b> and <b>ice cream sales (Y)</b>. Intuitively, we might expect a strong positive correlation. However, another variable, <b>temperature (Z)</b>, is also highly correlated with both sunshine and ice cream sales. When it's sunny, it's often hot, leading to more ice cream consumption.
</p>
<p>
    If we calculate the simple (zero-order) correlation between sunshine and ice cream sales, it might appear very high. However, to understand the unique relationship between sunshine and ice cream sales, independent of temperature, we would compute the partial correlation ($r_{xy.z}$). If this partial correlation is much lower than the simple correlation, it suggests that temperature was a significant confounding factor.
</p>
<p>
    The formula for the partial correlation between X and Y controlling for Z ($r_{xy.z}$) is:
    $$r_{xy.z} = \frac{r_{xy} - r_{xz}r_{yz}}{\sqrt{(1 - r_{xz}^2)(1 - r_{yz}^2)}}$$
    Where:
    <ul>
        <li>$r_{xy}$ is the Pearson correlation between X and Y</li>
        <li>$r_{xz}$ is the Pearson correlation between X and Z</li>
        <li>$r_{yz}$ is the Pearson correlation between Y and Z</li>
    </ul>
</p>

<h3>Part (Semi-Partial) Correlation</h3>
<p style="margin-top: 15px;">
    <b>Part correlation</b>, also known as <b>semi-partial correlation</b>, is a measure of the unique contribution of one predictor variable to the variance in a dependent variable, after accounting for the influence of another (control) variable from *only one* of the primary variables (typically the dependent variable). Unlike partial correlation which removes the variance of the control variable from both variables, part correlation removes it from only one.
</p>
<h4>Example:</h4>
<p style="margin-top: 10px;">
    Imagine we are studying the relationship between <b>training hours (X)</b> and <b>job performance (Y)</b>, and we know that <b>prior experience (Z)</b> also affects job performance.
    <ul>
        <li>If we compute the <b>partial correlation</b> between training hours and job performance, controlling for prior experience, we are asking: "What is the relationship between training hours and job performance, after removing the variance due to prior experience from *both* training hours and job performance?" This tells us the unique shared variance between X and Y not attributable to Z.</li>
        <li>If we compute the <b>part correlation</b> where prior experience (Z) is partialed out *only from job performance (Y)*, we are asking: "What is the unique contribution of training hours (X) to job performance (Y), after the influence of prior experience (Z) on job performance has been accounted for?" This means we look at the portion of Y's variance that X explains, which Z cannot.</li>
    </ul>
    Part correlation is often used in multiple regression to evaluate the unique contribution of each independent variable to the dependent variable, beyond what other independent variables can explain.
</p>
<p>
    The formula for the part correlation between X and Y, with Z partialed out of Y ($r_{y(x.z)}$), is:
    $$r_{y(x.z)} = \frac{r_{yx} - r_{yz}r_{xz}}{\sqrt{1 - r_{yz}^2}}$$
    This formula measures the correlation between X and the residual of Y after Y has been predicted by Z.
</p>

<h3>Point-Biserial Correlation ($r_{pb}$)</h3>
<p style="margin-top: 15px;">
    The <b>point-biserial correlation ($r_{pb}$)</b> is a special type of Pearson correlation coefficient used when one variable is <b>dichotomous</b> (binary, having only two categories, e.g., male/female, pass/fail, yes/no) and the other variable is <b>continuous</b> (interval or ratio scale). It measures the strength and direction of the association between these two types of variables.
</p>
<h4>Example:</h4>
<p style="margin-top: 10px;">
    We want to investigate the relationship between whether a student <b>attended a review session (Yes=1, No=0)</b> and their <b>score on a subsequent exam (continuous)</b>.
    A positive $r_{pb}$ would suggest that students who attended the review session tended to have higher exam scores. A negative $r_{pb}$ would suggest the opposite, and a value near zero would indicate no significant linear relationship.
</p>
<p>
    The formula for point-biserial correlation is commonly expressed as:
    $$r_{pb} = \frac{\bar{Y}_1 - \bar{Y}_0}{S_Y} \sqrt{\frac{n_1 n_0}{n^2}}$$
    Where:
    <ul>
        <li>$\bar{Y}_1$ = mean of the continuous variable for group 1 (e.g., those who attended)</li>
        <li>$\bar{Y}_0$ = mean of the continuous variable for group 0 (e.g., those who did not attend)</li>
        <li>$S_Y$ = standard deviation of the continuous variable for the entire sample</li>
        <li>$n_1$ = number of observations in group 1</li>
        <li>$n_0$ = number of observations in group 0</li>
        <li>$n$ = total number of observations ($n_1 + n_0$)</li>
    </ul>
</p>

<h3>Phi Coefficient ($\phi$)</h3>
<p style="margin-top: 15px;">
    The <b>Phi coefficient ($\phi$)</b> is a measure of association between <b>two dichotomous variables</b>. Like the point-biserial coefficient, it is a special case of the Pearson product-moment correlation coefficient, but it is applied when both variables are nominal and have only two categories. It is typically calculated from a 2x2 contingency table.
</p>
<h4>Example:</h4>
<p style="margin-top: 10px;">
    Consider a study examining the relationship between <b>smoking status (Smoker/Non-smoker)</b> and <b>developing a specific lung condition (Yes/No)</b>. Both variables are dichotomous.
    The data would be arranged in a 2x2 contingency table:
</p>
<table class="phi-table" style="width:auto; margin: 1em auto; border-collapse: collapse; text-align: center;">
    <thead>
        <tr style="background-color: #f2f2f2;">
            <th style="padding: 8px; border: 1px solid #ddd;"></th>
            <th style="padding: 8px; border: 1px solid #ddd;">Lung Condition (Yes)</th>
            <th style="padding: 8px; border: 1px solid #ddd;">Lung Condition (No)</th>
            <th style="padding: 8px; border: 1px solid #ddd;">Total</th>
        </tr>
    </thead>
    <tbody>
        <tr>
            <td style="padding: 8px; border: 1px solid #ddd;">Smoker</td>
            <td style="padding: 8px; border: 1px solid #ddd;">a</td>
            <td style="padding: 8px; border: 1px solid #ddd;">b</td>
            <td style="padding: 8px; border: 1px solid #ddd;">a+b</td>
        </tr>
        <tr>
            <td style="padding: 8px; border: 1px solid #ddd;">Non-smoker</td>
            <td style="padding: 8px; border: 1px solid #ddd;">c</td>
            <td style="padding: 8px; border: 1px solid #ddd;">d</td>
            <td style="padding: 8px; border: 1px solid #ddd;">c+d</td>
        </tr>
    </tbody>
    <tfoot>
        <tr style="background-color: #f2f2f2;">
            <td style="padding: 8px; border: 1px solid #ddd;">Total</td>
            <td style="padding: 8px; border: 1px solid #ddd;">a+c</td>
            <td style="padding: 8px; border: 1px solid #ddd;">b+d</td>
            <td style="padding: 8px; border: 1px solid #ddd;">N</td>
        </tr>
    </tfoot>
</table>
<p style="margin-top: 15px;">
    The formula for the Phi coefficient is:
    $$\phi = \frac{ad - bc}{\sqrt{(a+b)(c+d)(a+c)(b+d)}}$$
</p>
<p style="margin-top: 10px;">
    <ul>
        <li>A $\phi$ of +1 indicates a perfect positive association (e.g., all smokers have the condition, and all non-smokers do not).</li>
        <li>A $\phi$ of -1 indicates a perfect negative association.</li>
        <li>A $\phi$ of 0 indicates no association between the two dichotomous variables.</li>
    </ul>
    The Phi coefficient is essentially equivalent to Pearson's r when applied to two binary variables.
</p>

</div>
<div class="button-group">

<button class="copy-btn" onclick="copyText(this)">Copy Answer</button>

<button class="status-btn" data-status-action="read" onclick="setQuestionStatus(this.closest('details'), 'read')">Mark as Read</button>

<button class="status-btn" data-status-action="unread" onclick="setQuestionStatus(this.closest('details'), 'unread')">Mark as Unread</button>

<button class="status-btn" data-status-action="doubt" onclick="setQuestionStatus(this.closest('details'), 'doubt')">Mark as Doubt</button>

<button class="notes-card-btn" onclick="toggleNotes(this.closest('details'))">Add/View Notes</button>

</div>

<div class="notes-section">

<textarea placeholder="Write your notes here..." oninput="saveNotes(this.closest('details'), this.value)"></textarea>

</div>

</details>
</section>
<section class="topic-card" id="card-regression-analysis-all">
    <h2>📌 REGRESSION ANALYSIS</h2>

    <details data-status="unread">
        <span class="status-icon read" title="Read">✓</span>
        <span class="status-icon doubt" title="Doubt">!</span>
        <summary>
            <span>Compute for regression analysis using given datasets.</span>
            <time class="ml-2 text-gray-500 dark:text-gray-400" style="white-space: nowrap; overflow: hidden; text-overflow: ellipsis; font-size: clamp(0.4rem, 1.7vw, 0.9rem); color: #888; font-style: italic;">
 Dec 15, Jun 15, Jun 18, Jun 22, Dec 21
 </time>
            <span class="notes-indicator-icon" title="Notes added">📝</span>
        </summary>
        <div class="content">
            <p><strong>Regression analysis</strong> is a statistical method used to model the relationship between a dependent variable (Y) and one or more independent variables (X). The goal is to find the best-fitting line (or curve) that describes how Y changes as X changes, allowing for prediction and understanding of the relationship.</p>

            <h3>Simple Linear Regression Equation:</h3>
            <p>The equation for a simple linear regression line is typically expressed as:
            $$Y = a + bX$$
            Where:</p>
            <ul>
                <li>$Y$ is the dependent variable (the one we are trying to predict).</li>
                <li>$X$ is the independent variable (the one we are using to predict Y).</li>
                <li>$a$ is the Y-intercept, representing the value of Y when X is 0.</li>
                <li>$b$ is the slope of the regression line, representing the change in Y for a one-unit change in X.</li>
            </ul>

            <h3>Formulas for 'a' and 'b':</h3>
            <p>To compute 'a' and 'b' from a dataset, we use the following formulas derived using the method of least squares:</p>
            <p><strong>Slope (b):</strong>
            $$b = \frac{n(\sum XY) - (\sum X)(\sum Y)}{n(\sum X^2) - (\sum X)^2}$$</p>
            <p><strong>Y-intercept (a):</strong>
            $$a = \frac{\sum Y - b(\sum X)}{n}$$
            Alternatively, $a = \bar{Y} - b\bar{X}$ (where $\bar{Y}$ is the mean of Y and $\bar{X}$ is the mean of X).</p>
            <p>Where:</p>
            <ul>
                <li>$n$ is the number of data points.</li>
                <li>$\sum XY$ is the sum of the products of X and Y for each data point.</li>
                <li>$\sum X$ is the sum of all X values.</li>
                <li>$\sum Y$ is the sum of all Y values.</li>
                <li>$\sum X^2$ is the sum of the squares of all X values.</li>
                <li>$(\sum X)^2$ is the square of the sum of all X values.</li>
            </ul>

            <h3>Computations for Recurring Datasets:</h3>

            <h4>1. Dec 15 Dataset:</h4>
            <ul>
                <li>X: [7, 6, 10, 7, 10]</li>
                <li>Y: [9, 7, 10, 4, 5]</li>
            </ul>
            <p><strong>Calculations:</strong></p>
            <ul>
                <li>$n = 5$</li>
                <li>$\sum X = 7 + 6 + 10 + 7 + 10 = 40$</li>
                <li>$\sum Y = 9 + 7 + 10 + 4 + 5 = 35$</li>
                <li>$\sum XY = (7 \times 9) + (6 \times 7) + (10 \times 10) + (7 \times 4) + (10 \times 5) = 63 + 42 + 100 + 28 + 50 = 283$</li>
                <li>$\sum X^2 = 7^2 + 6^2 + 10^2 + 7^2 + 10^2 = 49 + 36 + 100 + 49 + 100 = 334$</li>
                <li>$(\sum X)^2 = (40)^2 = 1600$</li>
            </ul>
            <p><strong>Compute b:</strong>
            $$b = \frac{5(283) - (40)(35)}{5(334) - 1600} = \frac{1415 - 1400}{1670 - 1600} = \frac{15}{70} \approx 0.214$$</p>
            <p><strong>Compute a:</strong>
            $$a = \frac{35 - 0.214(40)}{5} = \frac{35 - 8.56}{5} = \frac{26.44}{5} \approx 5.288$$</p>
            <p><strong>Regression Equation (Dec 15):</strong>
            $$Y = 5.288 + 0.214X$$</p>

            <h4>2. Jun 18 Dataset:</h4>
            <ul>
                <li>X: [2, 3, 2, 5, 8]</li>
                <li>Y: [3, 2, 4, 1, 10]</li>
            </ul>
            <p><strong>Calculations:</strong></p>
            <ul>
                <li>$n = 5$</li>
                <li>$\sum X = 2 + 3 + 2 + 5 + 8 = 20$</li>
                <li>$\sum Y = 3 + 2 + 4 + 1 + 10 = 20$</li>
                <li>$\sum XY = (2 \times 3) + (3 \times 2) + (2 \times 4) + (5 \times 1) + (8 \times 10) = 6 + 6 + 8 + 5 + 80 = 105$</li>
                <li>$\sum X^2 = 2^2 + 3^2 + 2^2 + 5^2 + 8^2 = 4 + 9 + 4 + 25 + 64 = 106$</li>
                <li>$(\sum X)^2 = (20)^2 = 400$</li>
            </ul>
            <p><strong>Compute b:</strong>
            $$b = \frac{5(105) - (20)(20)}{5(106) - 400} = \frac{525 - 400}{530 - 400} = \frac{125}{130} \approx 0.962$$</p>
            <p><strong>Compute a:</strong>
            $$a = \frac{20 - 0.962(20)}{5} = \frac{20 - 19.24}{5} = \frac{0.76}{5} \approx 0.152$$</p>
            <p><strong>Regression Equation (Jun 18):</strong>
            $$Y = 0.152 + 0.962X$$</p>

            <h4>3. Dec 21 Dataset:</h4>
            <ul>
                <li>X: [10, 12, 13, 11, 9, 8, 12, 5, 10, 10]</li>
                <li>Y: [12, 13, 5, 12, 13, 15, 10, 10, 10, 10]</li>
            </ul>
            <p><strong>Calculations:</strong></p>
            <ul>
                <li>$n = 10$</li>
                <li>$\sum X = 10 + 12 + 13 + 11 + 9 + 8 + 12 + 5 + 10 + 10 = 100$</li>
                <li>$\sum Y = 12 + 13 + 5 + 12 + 13 + 15 + 10 + 10 + 10 + 10 = 110$</li>
                <li>$\sum XY = (10 \times 12) + (12 \times 13) + (13 \times 5) + (11 \times 12) + (9 \times 13) + (8 \times 15) + (12 \times 10) + (5 \times 10) + (10 \times 10) + (10 \times 10) = 120 + 156 + 65 + 132 + 117 + 120 + 120 + 50 + 100 + 100 = 1080$</li>
                <li>$\sum X^2 = 10^2 + 12^2 + 13^2 + 11^2 + 9^2 + 8^2 + 12^2 + 5^2 + 10^2 + 10^2 = 100 + 144 + 169 + 121 + 81 + 64 + 144 + 25 + 100 + 100 = 1048$</li>
                <li>$(\sum X)^2 = (100)^2 = 10000$</li>
            </ul>
            <p><strong>Compute b:</strong>
            $$b = \frac{10(1080) - (100)(110)}{10(1048) - 10000} = \frac{10800 - 11000}{10480 - 10000} = \frac{-200}{480} \approx -0.417$$</p>
            <p><strong>Compute a:</strong>
            $$a = \frac{110 - (-0.417)(100)}{10} = \frac{110 + 41.7}{10} = \frac{151.7}{10} \approx 15.17$$</p>
            <p><strong>Regression Equation (Dec 21):</strong>
            $$Y = 15.17 - 0.417X$$</p>

            <p>These regression equations can now be used to predict the value of Y given a value of X for each respective dataset. It's important to remember that these are simple linear regressions and assume a linear relationship between the variables.</p>
            <div class="button-group">
                <button class="copy-btn" onclick="copyText(this)">Copy Answer</button>
                <button class="status-btn" data-status-action="read" onclick="setQuestionStatus(this.closest('details'), 'read')">Mark as Read</button>
                <button class="status-btn" data-status-action="unread" onclick="setQuestionStatus(this.closest('details'), 'unread')">Mark as Unread</button>
                <button class="status-btn" data-status-action="doubt" onclick="setQuestionStatus(this.closest('details'), 'doubt')">Mark as Doubt</button>
                <button class="notes-card-btn" onclick="toggleNotes(this.closest('details'))">Add/View Notes</button>
            </div>
            <div class="notes-section">
                <textarea placeholder="Write your notes here..." oninput="saveNotes(this.closest('details'), this.value)"></textarea>
            </div>
        </div>
    </details>

</section>

<section class="topic-card" id="card-anova-f-test">
    <h2>📌 ANOVA / F-TEST</h2>

    <details data-status="unread">
        <span class="status-icon read" title="Read">✓</span>
        <span class="status-icon doubt" title="Doubt">!</span>
        <summary>
            <span>Compute one-way/two-way ANOVA for the given datasets.</span>
            <time class="ml-2 text-gray-500 dark:text-gray-400" style="white-space: nowrap; overflow: hidden; text-overflow: ellipsis; font-size: clamp(0.4rem, 1.7vw, 0.9rem); color: #888; font-style: italic;">
 Dec 15, Jun 15, Dec 16, Dec 17, Dec 18, Dec 19, Dec 20, Dec 21, Dec 22, Jun 23, Dec 23, Jun 24
 </time>
            <span class="notes-indicator-icon" title="Notes added">📝</span>
        </summary>
        <div class="content">
            <p><strong>ANOVA (Analysis of Variance)</strong> is a statistical hypothesis test that compares the means of two or more groups to determine if there are statistically significant differences between them. The <strong>F-test</strong> is the primary test used in ANOVA, which compares the variance between group means to the variance within the groups. A significant F-statistic indicates that at least one group mean is different from the others.</p>

            <h3>One-Way ANOVA:</h3>
            <p>One-Way ANOVA is used when you have one categorical independent variable (with two or more levels/groups) and one continuous dependent variable. It assesses whether there are statistically significant differences between the means of these groups.</p>

            <h4>Assumptions of One-Way ANOVA:</h4>
            <ul>
                <li><strong>Independence:</strong> Observations within and between groups must be independent.</li>
                <li><strong>Normality:</strong> The dependent variable should be approximately normally distributed within each group.</li>
                <li><strong>Homogeneity of Variances:</strong> The variance of the dependent variable should be approximately equal across all groups (homoscedasticity).</li>
            </ul>

            <h4>Key Concepts and Formulas for One-Way ANOVA:</h4>
            <ul>
                <li>
                    <strong>Total Sum of Squares (SST):</strong> Measures the total variation in the data.
                    $$SST = \sum_{i=1}^{k} \sum_{j=1}^{n_i} (X_{ij} - \bar{X}_{grand})^2$$
                </li>
                <li>
                    <strong>Sum of Squares Between Groups (SSB) or Sum of Squares Treatment (SSTreatment):</strong> Measures the variation between the means of different groups.
                    $$SSB = \sum_{i=1}^{k} n_i (\bar{X}_i - \bar{X}_{grand})^2$$
                </li>
                <li>
                    <strong>Sum of Squares Within Groups (SSW) or Sum of Squares Error (SSE):</strong> Measures the variation within each group.
                    $$SSW = \sum_{i=1}^{k} \sum_{j=1}^{n_i} (X_{ij} - \bar{X}_i)^2$$
                </li>
                <li>
                    <strong>Relationship:</strong> $SST = SSB + SSW$
                </li>
                <li>
                    <strong>Degrees of Freedom Between Groups (dfB):</strong> $dfB = k - 1$ (where $k$ is the number of groups).
                </li>
                <li>
                    <strong>Degrees of Freedom Within Groups (dfW):</strong> $dfW = N - k$ (where $N$ is the total number of observations).
                </li>
                <li>
                    <strong>Degrees of Freedom Total (dfT):</strong> $dfT = N - 1$
                </li>
                <li>
                    <strong>Mean Square Between Groups (MSB):</strong> $MSB = \frac{SSB}{dfB}$
                </li>
                <li>
                    <strong>Mean Square Within Groups (MSW):</strong> $MSW = \frac{SSW}{dfW}$
                </li>
                <li>
                    <strong>F-Statistic:</strong>
                    $$F = \frac{MSB}{MSW}$$
                </li>
            </ul>
            <p>Once the F-statistic is calculated, it is compared to a critical F-value from the F-distribution table (or a p-value is obtained from software) based on the chosen significance level ($\alpha$) and degrees of freedom (dfB, dfW). If $F_{calculated} > F_{critical}$ (or $p < \alpha$), we reject the null hypothesis, concluding that there is a statistically significant difference between at least two group means.</p>

            <h3>Computations for Recurring Datasets (One-Way ANOVA):</h3>

            <h4>1. Dec 15 Dataset:</h4>
            <ul>
                <li>Group A: [6, 12, 10, 10, 9, 7, 9, 12, 8, 7]</li>
                <li>Group B: [10, 11, 5, 8, 10, 7, 11, 15, 9, 11]</li>
                <li>Group C: [13, 18, 13, 10, 8, 11, 10, 8, 11, 12]</li>
            </ul>
            <p><strong>Step 1: Calculate Group Means and Grand Mean</strong></p>
            <ul>
                <li>$n_A = 10, \sum X_A = 90, \bar{X}_A = 9.0$</li>
                <li>$n_B = 10, \sum X_B = 97, \bar{X}_B = 9.7$</li>
                <li>$n_C = 10, \sum X_C = 114, \bar{X}_C = 11.4$</li>
                <li>$N = 30$</li>
                <li>$\sum X_{total} = 90 + 97 + 114 = 301$</li>
                <li>$\bar{X}_{grand} = 301 / 30 \approx 10.033$</li>
            </ul>

            <p><strong>Step 2: Calculate Sum of Squares Total (SST)</strong></p>
            <ul>
                <li>$\sum X^2_A = 6^2+12^2+...+7^2 = 848$</li>
                <li>$\sum X^2_B = 10^2+11^2+...+11^2 = 1011$</li>
                <li>$\sum X^2_C = 13^2+18^2+...+12^2 = 1392$</li>
                <li>$\sum X^2_{total} = 848 + 1011 + 1392 = 3251$</li>
                <li>$SST = \sum X^2_{total} - \frac{(\sum X_{total})^2}{N} = 3251 - \frac{(301)^2}{30} = 3251 - \frac{90601}{30} = 3251 - 3020.033 = 230.967$</li>
            </ul>

            <p><strong>Step 3: Calculate Sum of Squares Between Groups (SSB)</strong></p>
            $$SSB = n_A(\bar{X}_A - \bar{X}_{grand})^2 + n_B(\bar{X}_B - \bar{X}_{grand})^2 + n_C(\bar{X}_C - \bar{X}_{grand})^2$$
            $$SSB = 10(9.0 - 10.033)^2 + 10(9.7 - 10.033)^2 + 10(11.4 - 10.033)^2$$
            $$SSB = 10(-1.033)^2 + 10(-0.333)^2 + 10(1.367)^2$$
            $$SSB = 10(1.067) + 10(0.111) + 10(1.868) = 10.67 + 1.11 + 18.68 = 30.46$$

            <p><strong>Step 4: Calculate Sum of Squares Within Groups (SSW)</strong></p>
            $$SSW = SST - SSB = 230.967 - 30.46 = 200.507$$
            <p>Alternatively, sum of squared deviations from group means:</p>
            <ul>
                <li>$SSW_A = \sum (X_A - \bar{X}_A)^2 = (6-9)^2 + ... + (7-9)^2 = 36 + 9 + 1 + 1 + 0 + 4 + 0 + 9 + 1 + 4 = 65$</li>
                <li>$SSW_B = \sum (X_B - \bar{X}_B)^2 = (10-9.7)^2 + ... + (11-9.7)^2 = 0.09 + 1.69 + 22.09 + 2.89 + 0.09 + 7.29 + 1.69 + 28.09 + 0.49 + 1.69 = 66.5$</li>
                <li>$SSW_C = \sum (X_C - \bar{X}_C)^2 = (13-11.4)^2 + ... + (12-11.4)^2 = 2.56 + 43.56 + 2.56 + 1.96 + 11.56 + 0.0 + 1.96 + 11.56 + 0.0 + 0.36 = 76.08$</li>
                <li>$SSW = SSW_A + SSW_B + SSW_C = 65 + 66.5 + 76.08 = 202.58$ (Differences due to rounding in $\bar{X}_{grand}$ and individual $SSW$ calculations, using $SST-SSB$ is more accurate here).</li>
            </ul>

            <p><strong>Step 5: Calculate Degrees of Freedom</strong></p>
            <ul>
                <li>$dfB = k - 1 = 3 - 1 = 2$</li>
                <li>$dfW = N - k = 30 - 3 = 27$</li>
                <li>$dfT = N - 1 = 30 - 1 = 29$</li>
            </ul>

            <p><strong>Step 6: Calculate Mean Squares</strong></p>
            <ul>
                <li>$MSB = \frac{SSB}{dfB} = \frac{30.46}{2} = 15.23$</li>
                <li>$MSW = \frac{SSW}{dfW} = \frac{200.507}{27} \approx 7.426$</li>
            </ul>

            <p><strong>Step 7: Calculate F-Statistic</strong></p>
            $$F = \frac{MSB}{MSW} = \frac{15.23}{7.426} \approx 2.051$$

            <p><strong>Conclusion for Dec 15:</strong>
            To determine significance, we would compare $F_{calculated} = 2.051$ to the critical F-value for $df_1 = 2$ and $df_2 = 27$ at a chosen $\alpha$ level (e.g., 0.05). If $\alpha = 0.05$, the critical F-value is approximately 3.35. Since $2.051 < 3.35$, we would **fail to reject the null hypothesis**. This suggests there is no statistically significant difference between the means of Group A, B, and C in the Dec 15 dataset.</p>

            <h4>2. Jun 23 Dataset:</h4>
            <ul>
                <li>Group A: [4, 6, 7, 9, 2, 4, 7, 8, 9, 2]</li>
                <li>Group B: [6, 7, 10, 12, 13, 14, 15, 17, 18, 3]</li>
                <li>Group C: [10, 11, 12, 13, 14, 15, 17, 10, 2, 4]</li>
            </ul>
            <p><strong>Step 1: Calculate Group Means and Grand Mean</strong></p>
            <ul>
                <li>$n_A = 10, \sum X_A = 58, \bar{X}_A = 5.8$</li>
                <li>$n_B = 10, \sum X_B = 115, \bar{X}_B = 11.5$</li>
                <li>$n_C = 10, \sum X_C = 108, \bar{X}_C = 10.8$</li>
                <li>$N = 30$</li>
                <li>$\sum X_{total} = 58 + 115 + 108 = 281$</li>
                <li>$\bar{X}_{grand} = 281 / 30 \approx 9.367$</li>
            </ul>

            <p><strong>Step 2: Calculate Sum of Squares Total (SST)</strong></p>
            <ul>
                <li>$\sum X^2_A = 4^2+...+2^2 = 336$</li>
                <li>$\sum X^2_B = 6^2+...+3^2 = 1689$</li>
                <li>$\sum X^2_C = 10^2+...+4^2 = 1383$</li>
                <li>$\sum X^2_{total} = 336 + 1689 + 1383 = 3408$</li>
                <li>$SST = 3408 - \frac{(281)^2}{30} = 3408 - \frac{78961}{30} = 3408 - 2632.033 = 775.967$</li>
            </ul>

            <p><strong>Step 3: Calculate Sum of Squares Between Groups (SSB)</strong></p>
            $$SSB = 10(5.8 - 9.367)^2 + 10(11.5 - 9.367)^2 + 10(10.8 - 9.367)^2$$
            $$SSB = 10(-3.567)^2 + 10(2.133)^2 + 10(1.433)^2$$
            $$SSB = 10(12.723) + 10(4.550) + 10(2.054) = 127.23 + 45.50 + 20.54 = 193.27$$

            <p><strong>Step 4: Calculate Sum of Squares Within Groups (SSW)</strong></p>
            $$SSW = SST - SSB = 775.967 - 193.27 = 582.697$$

            <p><strong>Step 5: Calculate Degrees of Freedom</strong></p>
            <ul>
                <li>$dfB = 2$</li>
                <li>$dfW = 27$</li>
                <li>$dfT = 29$</li>
            </ul>

            <p><strong>Step 6: Calculate Mean Squares</strong></p>
            <ul>
                <li>$MSB = \frac{193.27}{2} = 96.635$</li>
                <li>$MSW = \frac{582.697}{27} \approx 21.581$</li>
            </ul>

            <p><strong>Step 7: Calculate F-Statistic</strong></p>
            $$F = \frac{MSB}{MSW} = \frac{96.635}{21.581} \approx 4.478$$

            <p><strong>Conclusion for Jun 23:</strong>
            Using $\alpha = 0.05$ and critical F-value for $df_1 = 2, df_2 = 27$ is approximately 3.35. Since $4.478 > 3.35$, we would **reject the null hypothesis**. This indicates that there is a statistically significant difference between the means of at least two of the groups (A, B, C) in the Jun 23 dataset.</p>

            <h4>3. Dec 23 Dataset:</h4>
            <ul>
                <li>Group A: [7, 8, 6, 2, 4, 5, 7, 8, 9, 10]</li>
                <li>Group B: [2, 4, 7, 8, 6, 4, 7, 8, 9, 10]</li>
                <li>Group C: [3, 4, 2, 2, 3, 4, 4, 5, 7, 2]</li>
            </ul>
            <p><strong>Step 1: Calculate Group Means and Grand Mean</strong></p>
            <ul>
                <li>$n_A = 10, \sum X_A = 66, \bar{X}_A = 6.6$</li>
                <li>$n_B = 10, \sum X_B = 65, \bar{X}_B = 6.5$</li>
                <li>$n_C = 10, \sum X_C = 36, \bar{X}_C = 3.6$</li>
                <li>$N = 30$</li>
                <li>$\sum X_{total} = 66 + 65 + 36 = 167$</li>
                <li>$\bar{X}_{grand} = 167 / 30 \approx 5.567$</li>
            </ul>

            <p><strong>Step 2: Calculate Sum of Squares Total (SST)</strong></p>
            <ul>
                <li>$\sum X^2_A = 7^2+...+10^2 = 494$</li>
                <li>$\sum X^2_B = 2^2+...+10^2 = 503$</li>
                <li>$\sum X^2_C = 3^2+...+2^2 = 155$</li>
                <li>$\sum X^2_{total} = 494 + 503 + 155 = 1152$</li>
                <li>$SST = 1152 - \frac{(167)^2}{30} = 1152 - \frac{27889}{30} = 1152 - 929.633 = 222.367$</li>
            </ul>

            <p><strong>Step 3: Calculate Sum of Squares Between Groups (SSB)</strong></p>
            $$SSB = 10(6.6 - 5.567)^2 + 10(6.5 - 5.567)^2 + 10(3.6 - 5.567)^2$$
            $$SSB = 10(1.033)^2 + 10(0.933)^2 + 10(-1.967)^2$$
            $$SSB = 10(1.067) + 10(0.870) + 10(3.869) = 10.67 + 8.70 + 38.69 = 58.06$$

            <p><strong>Step 4: Calculate Sum of Squares Within Groups (SSW)</strong></p>
            $$SSW = SST - SSB = 222.367 - 58.06 = 164.307$$

            <p><strong>Step 5: Calculate Degrees of Freedom</strong></p>
            <ul>
                <li>$dfB = 2$</li>
                <li>$dfW = 27$</li>
                <li>$dfT = 29$</li>
            </ul>

            <p><strong>Step 6: Calculate Mean Squares</strong></p>
            <ul>
                <li>$MSB = \frac{58.06}{2} = 29.03$</li>
                <li>$MSW = \frac{164.307}{27} \approx 6.085$</li>
            </ul>

            <p><strong>Step 7: Calculate F-Statistic</strong></p>
            $$F = \frac{MSB}{MSW} = \frac{29.03}{6.085} \approx 4.771$$

            <p><strong>Conclusion for Dec 23:</strong>
            Using $\alpha = 0.05$ and critical F-value for $df_1 = 2, df_2 = 27$ is approximately 3.35. Since $4.771 > 3.35$, we would **reject the null hypothesis**. This suggests there is a statistically significant difference between the means of at least two of the groups (A, B, C) in the Dec 23 dataset.</p>

            <p><em>Note: Two-way ANOVA computations are more complex and require datasets with two independent categorical variables. Since the provided datasets are structured for one-way ANOVA (one independent variable, 'Group'), only one-way ANOVA has been computed.</em></p>

            <div class="button-group">
                <button class="copy-btn" onclick="copyText(this)">Copy Answer</button>
                <button class="status-btn" data-status-action="read" onclick="setQuestionStatus(this.closest('details'), 'read')">Mark as Read</button>
                <button class="status-btn" data-status-action="unread" onclick="setQuestionStatus(this.closest('details'), 'unread')">Mark as Unread</button>
                <button class="status-btn" data-status-action="doubt" onclick="setQuestionStatus(this.closest('details'), 'doubt')">Mark as Doubt</button>
                <button class="notes-card-btn" onclick="toggleNotes(this.closest('details'))">Add/View Notes</button>
            </div>
            <div class="notes-section">
                <textarea placeholder="Write your notes here..." oninput="saveNotes(this.closest('details'), this.value)"></textarea>
            </div>
        </div>
    </details>

</section>
<section class="topic-card" id="card-non-parametric-tests">
    <h2>📌 NON-PARAMETRIC TESTS</h2>

    <details data-status="unread">
        <span class="status-icon read" title="Read">✓</span>
        <span class="status-icon doubt" title="Doubt">!</span>
        <summary>
            <span>Compute Mann-Whitney U test for the following datasets.</span>
            <time class="ml-2 text-gray-500 dark:text-gray-400" style="white-space: nowrap; overflow: hidden; text-overflow: ellipsis; font-size: clamp(0.4rem, 1.7vw, 0.9rem); color: #888; font-style: italic;">
 Dec 15, Jun 15, Dec 16, Dec 17, Jun 18, Dec 18, Jun 19, Jun 22, Jun 24, Dec 23
 </time>
            <span class="notes-indicator-icon" title="Notes added">📝</span>
        </summary>
        <div class="content">
            <p>The <strong>Mann-Whitney U test</strong> (also known as the Wilcoxon rank-sum test) is a non-parametric statistical test used to compare two independent samples to determine if there is a statistically significant difference between their underlying distributions. It is often considered the non-parametric alternative to the independent samples t-test and is particularly useful when the data do not meet the assumptions of parametric tests (e.g., normal distribution).</p>

            <h3>Hypotheses for Mann-Whitney U Test:</h3>
            <ul>
                <li><strong>Null Hypothesis ($H_0$):</strong> The two populations are stochastically equal (i.e., there is no difference in the distributions of the two groups, or the probability that a randomly selected observation from one group is greater than a randomly selected observation from the other group is 0.5).</li>
                <li><strong>Alternative Hypothesis ($H_1$):</strong> The two populations are not stochastically equal (i.e., there is a significant difference in the distributions, or one group tends to have larger/smaller values than the other). This can be two-tailed or one-tailed. For these examples, we'll assume a two-tailed test.</li>
            </ul>

            <h3>Steps for Mann-Whitney U Test:</h3>
            <ol>
                <li><strong>Combine and Rank Data:</strong> Combine all observations from both groups into a single dataset and rank them from the smallest to the largest.</li>
                <li><strong>Handle Ties:</strong> If two or more observations have the same value (ties), assign them the average of the ranks they would have received.</li>
                <li><strong>Sum Ranks for Each Group:</strong> Calculate the sum of the ranks for each of the original groups ($R_1$ and $R_2$).</li>
                <li><strong>Calculate U Statistics:</strong> Compute the U statistic for each group using the formulas:
                    $$U_1 = n_1 n_2 + \frac{n_1(n_1+1)}{2} - R_1$$
                    $$U_2 = n_1 n_2 + \frac{n_2(n_2+1)}{2} - R_2$$
                    Where $n_1$ and $n_2$ are the sample sizes of Group 1 and Group 2, respectively, and $R_1$ and $R_2$ are their respective sum of ranks.
                </li>
                <li><strong>Select the Smaller U Value:</strong> The test statistic U is the smaller of $U_1$ and $U_2$.</li>
                <li><strong>Compare with Critical Value (or P-value):</strong> Compare the calculated U value with a critical U value from a Mann-Whitney U table (based on $n_1$, $n_2$, and the chosen significance level $\alpha$). If the calculated U is less than or equal to the critical value, reject the null hypothesis. Alternatively, for larger samples, a z-approximation can be used to find a p-value.</li>
            </ol>

            <h3>Computations for Recurring Datasets:</h3>

            <h4>1. Dec 15 Dataset:</h4>
            <ul>
                <li>Group 1 ($n_1=6$): [20, 27, 30, 31, 32, 25]</li>
                <li>Group 2 ($n_2=6$): [26, 33, 40, 36, 28, 21]</li>
            </ul>

            <p><strong>Step 1 & 2: Combine and Rank Data (with ties)</strong></p>
            <table class="table-auto w-full text-left whitespace-no-wrap">
                <thead>
                    <tr>
                        <th class="px-4 py-3 title-font tracking-wider font-medium text-gray-900 text-sm bg-gray-100 rounded-tl rounded-bl">Value</th>
                        <th class="px-4 py-3 title-font tracking-wider font-medium text-gray-900 text-sm bg-gray-100">Group</th>
                        <th class="px-4 py-3 title-font tracking-wider font-medium text-gray-900 text-sm bg-gray-100 rounded-tr rounded-br">Rank</th>
                    </tr>
                </thead>
                <tbody>
                    <tr><td class="px-4 py-3">20</td><td class="px-4 py-3">G1</td><td class="px-4 py-3">1</td></tr>
                    <tr><td class="px-4 py-3">21</td><td class="px-4 py-3">G2</td><td class="px-4 py-3">2</td></tr>
                    <tr><td class="px-4 py-3">25</td><td class="px-4 py-3">G1</td><td class="px-4 py-3">3</td></tr>
                    <tr><td class="px-4 py-3">26</td><td class="px-4 py-3">G2</td><td class="px-4 py-3">4</td></tr>
                    <tr><td class="px-4 py-3">27</td><td class="px-4 py-3">G1</td><td class="px-4 py-3">5</td></tr>
                    <tr><td class="px-4 py-3">28</td><td class="px-4 py-3">G2</td><td class="px-4 py-3">6</td></tr>
                    <tr><td class="px-4 py-3">30</td><td class="px-4 py-3">G1</td><td class="px-4 py-3">7</td></tr>
                    <tr><td class="px-4 py-3">31</td><td class="px-4 py-3">G1</td><td class="px-4 py-3">8</td></tr>
                    <tr><td class="px-4 py-3">32</td><td class="px-4 py-3">G1</td><td class="px-4 py-3">9</td></tr>
                    <tr><td class="px-4 py-3">33</td><td class="px-4 py-3">G2</td><td class="px-4 py-3">10</td></tr>
                    <tr><td class="px-4 py-3">36</td><td class="px-4 py-3">G2</td><td class="px-4 py-3">11</td></tr>
                    <tr><td class="px-4 py-3">40</td><td class="px-4 py-3">G2</td><td class="px-4 py-3">12</td></tr>
                </tbody>
            </table>

            <p><strong>Step 3: Sum Ranks for Each Group</strong></p>
            <ul>
                <li>$R_1$ (Group 1 ranks): $1 + 3 + 5 + 7 + 8 + 9 = 33$</li>
                <li>$R_2$ (Group 2 ranks): $2 + 4 + 6 + 10 + 11 + 12 = 45$</li>
            </ul>
            <p>Check: $R_1 + R_2 = 33 + 45 = 78$. Total possible sum of ranks for $N=12$ is $\frac{N(N+1)}{2} = \frac{12(13)}{2} = 78$. (Matches)</p>

            <p><strong>Step 4: Calculate U Statistics</strong></p>
            <ul>
                <li>$U_1 = n_1 n_2 + \frac{n_1(n_1+1)}{2} - R_1 = (6)(6) + \frac{6(6+1)}{2} - 33 = 36 + \frac{42}{2} - 33 = 36 + 21 - 33 = 24$</li>
                <li>$U_2 = n_1 n_2 + \frac{n_2(n_2+1)}{2} - R_2 = (6)(6) + \frac{6(6+1)}{2} - 45 = 36 + \frac{42}{2} - 45 = 36 + 21 - 45 = 12$</li>
            </ul>

            <p><strong>Step 5: Select the Smaller U Value</strong></p>
            <ul>
                <li>$U = \min(U_1, U_2) = \min(24, 12) = 12$</li>
            </ul>

            <p><strong>Step 6: Conclusion (Dec 15):</strong></p>
            <p>For $n_1=6$ and $n_2=6$, at a significance level $\alpha=0.05$ (two-tailed), the critical U value from a Mann-Whitney U table is 5. Since our calculated $U = 12$ is greater than the critical value of 5, we fail to reject the null hypothesis. There is no statistically significant difference between Group 1 and Group 2 for the Dec 15 dataset.</p>

            <h4>2. Jun 24 Dataset:</h4>
            <ul>
                <li>Group A ($n_A=7$): [7, 6, 3, 2, 14, 6, 10]</li>
                <li>Group B ($n_B=7$): [7, 8, 1, 13, 4, 7, 9]</li>
            </ul>

            <p><strong>Step 1 & 2: Combine and Rank Data (with ties)</strong></p>
            <table class="table-auto w-full text-left whitespace-no-wrap">
                <thead>
                    <tr>
                        <th class="px-4 py-3 title-font tracking-wider font-medium text-gray-900 text-sm bg-gray-100 rounded-tl rounded-bl">Value</th>
                        <th class="px-4 py-3 title-font tracking-wider font-medium text-gray-900 text-sm bg-gray-100">Group</th>
                        <th class="px-4 py-3 title-font tracking-wider font-medium text-gray-900 text-sm bg-gray-100 rounded-tr rounded-br">Rank</th>
                    </tr>
                </thead>
                <tbody>
                    <tr><td class="px-4 py-3">1</td><td class="px-4 py-3">G2</td><td class="px-4 py-3">1</td></tr>
                    <tr><td class="px-4 py-3">2</td><td class="px-4 py-3">G1</td><td class="px-4 py-3">2</td></tr>
                    <tr><td class="px-4 py-3">3</td><td class="px-4 py-3">G1</td><td class="px-4 py-3">3</td></tr>
                    <tr><td class="px-4 py-3">4</td><td class="px-4 py-3">G2</td><td class="px-4 py-3">4</td></tr>
                    <tr><td class="px-4 py-3">6</td><td class="px-4 py-3">G1</td><td class="px-4 py-3">5.5 (avg of 5,6)</td></tr>
                    <tr><td class="px-4 py-3">6</td><td class="px-4 py-3">G1</td><td class="px-4 py-3">5.5 (avg of 5,6)</td></tr>
                    <tr><td class="px-4 py-3">7</td><td class="px-4 py-3">G1</td><td class="px-4 py-3">8 (avg of 7,8,9)</td></tr>
                    <tr><td class="px-4 py-3">7</td><td class="px-4 py-3">G2</td><td class="px-4 py-3">8 (avg of 7,8,9)</td></tr>
                    <tr><td class="px-4 py-3">7</td><td class="px-4 py-3">G2</td><td class="px-4 py-3">8 (avg of 7,8,9)</td></tr>
                    <tr><td class="px-4 py-3">8</td><td class="px-4 py-3">G2</td><td class="px-4 py-3">10</td></tr>
                    <tr><td class="px-4 py-3">9</td><td class="px-4 py-3">G2</td><td class="px-4 py-3">11</td></tr>
                    <tr><td class="px-4 py-3">10</td><td class="px-4 py-3">G1</td><td class="px-4 py-3">12</td></tr>
                    <tr><td class="px-4 py-3">13</td><td class="px-4 py-3">G2</td><td class="px-4 py-3">13</td></tr>
                    <tr><td class="px-4 py-3">14</td><td class="px-4 py-3">G1</td><td class="px-4 py-3">14</td></tr>
                </tbody>
            </table>

            <p><strong>Step 3: Sum Ranks for Each Group</strong></p>
            <ul>
                <li>$R_A$ (Group A ranks): $8 + 5.5 + 3 + 2 + 14 + 5.5 + 12 = 50$</li>
                <li>$R_B$ (Group B ranks): $8 + 10 + 1 + 13 + 4 + 8 + 11 = 55$</li>
            </ul>
            <p>Check: $R_A + R_B = 50 + 55 = 105$. Total possible sum of ranks for $N=14$ is $\frac{N(N+1)}{2} = \frac{14(15)}{2} = 105$. (Matches)</p>

            <p><strong>Step 4: Calculate U Statistics</strong></p>
            <ul>
                <li>$U_A = n_A n_B + \frac{n_A(n_A+1)}{2} - R_A = (7)(7) + \frac{7(7+1)}{2} - 50 = 49 + \frac{56}{2} - 50 = 49 + 28 - 50 = 27$</li>
                <li>$U_B = n_A n_B + \frac{n_B(n_B+1)}{2} - R_B = (7)(7) + \frac{7(7+1)}{2} - 55 = 49 + \frac{56}{2} - 55 = 49 + 28 - 55 = 22$</li>
            </ul>

            <p><strong>Step 5: Select the Smaller U Value</strong></p>
            <ul>
                <li>$U = \min(U_A, U_B) = \min(27, 22) = 22$</li>
            </ul>

            <p><strong>Step 6: Conclusion (Jun 24):</strong></p>
            <p>For $n_1=7$ and $n_2=7$, at a significance level $\alpha=0.05$ (two-tailed), the critical U value from a Mann-Whitney U table is 8. Since our calculated $U = 22$ is greater than the critical value of 8, we fail to reject the null hypothesis. There is no statistically significant difference between Group A and Group B for the Jun 24 dataset.</p>

            <h4>3. Dec 23 Dataset:</h4>
            <ul>
                <li>Group A ($n_A=7$): [20, 13, 14, 16, 18, 21, 30]</li>
                <li>Group B ($n_B=7$): [31, 10, 9, 7, 6, 3, 25]</li>
            </ul>

            <p><strong>Step 1 & 2: Combine and Rank Data (no ties)</strong></p>
            <table class="table-auto w-full text-left whitespace-no-wrap">
                <thead>
                    <tr>
                        <th class="px-4 py-3 title-font tracking-wider font-medium text-gray-900 text-sm bg-gray-100 rounded-tl rounded-bl">Value</th>
                        <th class="px-4 py-3 title-font tracking-wider font-medium text-gray-900 text-sm bg-gray-100">Group</th>
                        <th class="px-4 py-3 title-font tracking-wider font-medium text-gray-900 text-sm bg-gray-100 rounded-tr rounded-br">Rank</th>
                    </tr>
                </thead>
                <tbody>
                    <tr><td class="px-4 py-3">3</td><td class="px-4 py-3">G2</td><td class="px-4 py-3">1</td></tr>
                    <tr><td class="px-4 py-3">6</td><td class="px-4 py-3">G2</td><td class="px-4 py-3">2</td></tr>
                    <tr><td class="px-4 py-3">7</td><td class="px-4 py-3">G2</td><td class="px-4 py-3">3</td></tr>
                    <tr><td class="px-4 py-3">9</td><td class="px-4 py-3">G2</td><td class="px-4 py-3">4</td></tr>
                    <tr><td class="px-4 py-3">10</td><td class="px-4 py-3">G2</td><td class="px-4 py-3">5</td></tr>
                    <tr><td class="px-4 py-3">13</td><td class="px-4 py-3">G1</td><td class="px-4 py-3">6</td></tr>
                    <tr><td class="px-4 py-3">14</td><td class="px-4 py-3">G1</td><td class="px-4 py-3">7</td></tr>
                    <tr><td class="px-4 py-3">16</td><td class="px-4 py-3">G1</td><td class="px-4 py-3">8</td></tr>
                    <tr><td class="px-4 py-3">18</td><td class="px-4 py-3">G1</td><td class="px-4 py-3">9</td></tr>
                    <tr><td class="px-4 py-3">20</td><td class="px-4 py-3">G1</td><td class="px-4 py-3">10</td></tr>
                    <tr><td class="px-4 py-3">21</td><td class="px-4 py-3">G1</td><td class="px-4 py-3">11</td></tr>
                    <tr><td class="px-4 py-3">25</td><td class="px-4 py-3">G2</td><td class="px-4 py-3">12</td></tr>
                    <tr><td class="px-4 py-3">30</td><td class="px-4 py-3">G1</td><td class="px-4 py-3">13</td></tr>
                    <tr><td class="px-4 py-3">31</td><td class="px-4 py-3">G2</td><td class="px-4 py-3">14</td></tr>
                </tbody>
            </table>

            <p><strong>Step 3: Sum Ranks for Each Group</strong></p>
            <ul>
                <li>$R_A$ (Group A ranks): $6 + 7 + 8 + 9 + 10 + 11 + 13 = 64$</li>
                <li>$R_B$ (Group B ranks): $1 + 2 + 3 + 4 + 5 + 12 + 14 = 41$</li>
            </ul>
            <p>Check: $R_A + R_B = 64 + 41 = 105$. Total possible sum of ranks for $N=14$ is $\frac{N(N+1)}{2} = \frac{14(15)}{2} = 105$. (Matches)</p>

            <p><strong>Step 4: Calculate U Statistics</strong></p>
            <ul>
                <li>$U_A = n_A n_B + \frac{n_A(n_A+1)}{2} - R_A = (7)(7) + \frac{7(7+1)}{2} - 64 = 49 + 28 - 64 = 13$</li>
                <li>$U_B = n_A n_B + \frac{n_B(n_B+1)}{2} - R_B = (7)(7) + \frac{7(7+1)}{2} - 41 = 49 + 28 - 41 = 36$</li>
            </ul>

            <p><strong>Step 5: Select the Smaller U Value</strong></p>
            <ul>
                <li>$U = \min(U_A, U_B) = \min(13, 36) = 13$</li>
            </ul>

            <p><strong>Step 6: Conclusion (Dec 23):</strong></p>
            <p>For $n_1=7$ and $n_2=7$, at a significance level $\alpha=0.05$ (two-tailed), the critical U value from a Mann-Whitney U table is 8. Since our calculated $U = 13$ is greater than the critical value of 8, we fail to reject the null hypothesis. There is no statistically significant difference between Group A and Group B for the Dec 23 dataset.</p>

            <div class="button-group">
                <button class="copy-btn" onclick="copyText(this)">Copy Answer</button>
                <button class="status-btn" data-status-action="read" onclick="setQuestionStatus(this.closest('details'), 'read')">Mark as Read</button>
                <button class="status-btn" data-status-action="unread" onclick="setQuestionStatus(this.closest('details'), 'unread')">Mark as Unread</button>
                <button class="status-btn" data-status-action="doubt" onclick="setQuestionStatus(this.closest('details'), 'doubt')">Mark as Doubt</button>
                <button class="notes-card-btn" onclick="toggleNotes(this.closest('details'))">Add/View Notes</button>
            </div>
            <div class="notes-section">
                <textarea placeholder="Write your notes here..." oninput="saveNotes(this.closest('details'), this.value)"></textarea>
            </div>
        </div>
    </details>

    <details data-status="unread">
        <span class="status-icon read" title="Read">✓</span>
        <span class="status-icon doubt" title="Doubt">!</span>
        <summary>
            <span>Compute Chi-square for the following data.</span>
            <time class="ml-2 text-gray-500 dark:text-gray-400" style="white-space: nowrap; overflow: hidden; text-overflow: ellipsis; font-size: clamp(0.4rem, 1.7vw, 0.9rem); color: #888; font-style: italic;">
 Dec 15, Jun 15, Dec 16, Jun 18, Dec 18, Dec 19, Dec 21, Jun 24
 </time>
            <span class="notes-indicator-icon" title="Notes added">📝</span>
        </summary>
        <div class="content">
            <p>The <strong>Chi-Square ($\chi^2$) test of independence</strong> is a non-parametric statistical test used to determine if there is a significant association between two categorical variables. It compares the observed frequencies in a contingency table with the frequencies that would be expected if the two variables were truly independent.</p>

            <h3>Hypotheses for Chi-Square Test of Independence:</h3>
            <ul>
                <li><strong>Null Hypothesis ($H_0$):</strong> The two categorical variables are independent (i.e., there is no association between them).</li>
                <li><strong>Alternative Hypothesis ($H_1$):</strong> The two categorical variables are dependent (i.e., there is a significant association between them).</li>
            </ul>

            <h3>Formula for Chi-Square Statistic:</h3>
            <p>The Chi-Square statistic is calculated using the following formula:</p>
            $$\chi^2 = \sum \frac{(O_{ij} - E_{ij})^2}{E_{ij}}$$
            Where:</p>
            <ul>
                <li>$O_{ij}$ is the observed frequency in cell $(i, j)$ of the contingency table.</li>
                <li>$E_{ij}$ is the expected frequency in cell $(i, j)$ of the contingency table.</li>
            </ul>

            <p><strong>To calculate the Expected Frequencies ($E_{ij}$):</strong>
            $$E_{ij} = \frac{(\text{Row Total}) \times (\text{Column Total})}{\text{Grand Total}}$$</p>

            <h3>Steps for Chi-Square Test:</h3>
            <ol>
                <li><strong>Construct a Contingency Table:</strong> Organize the observed frequencies into a table with rows representing categories of one variable and columns representing categories of the other.</li>
                <li><strong>Calculate Row Totals, Column Totals, and Grand Total:</strong> Sum the frequencies across rows and down columns, and find the total sum of all frequencies.</li>
                <li><strong>Calculate Expected Frequencies ($E_{ij}$):</strong> For each cell in the table, calculate the expected frequency assuming the null hypothesis (independence) is true.</li>
                <li><strong>Calculate Chi-Square Statistic ($\chi^2$):</strong> For each cell, compute $\frac{(O_{ij} - E_{ij})^2}{E_{ij}}$ and sum these values across all cells.</li>
                <li><strong>Determine Degrees of Freedom (df):</strong>
                    $$df = (\text{Number of Rows} - 1) \times (\text{Number of Columns} - 1)$$
                </li>
                <li><strong>Compare with Critical Value (or P-value):</strong> Compare the calculated $\chi^2$ value with a critical $\chi^2$ value from a Chi-Square distribution table (based on $df$ and a chosen significance level $\alpha$). If $\chi^2_{calculated} > \chi^2_{critical}$ (or p-value < $\alpha$), reject the null hypothesis.</li>
            </ol>

            <h3>Computations for Recurring Datasets:</h3>

            <h4>1. Dec 15 Dataset: SES and Some Binary Outcome (e.g., Success/Failure)</h4>
            <p>The data "SES: Yes [72, 34], No [48, 46]" implies a 2x2 contingency table. Let's assume the categories are SES (Yes/No) and an outcome (e.g., Outcome 1 / Outcome 2, or perhaps "Passed" / "Failed"). We'll label the columns as "Outcome 1" and "Outcome 2" for generality.</p>
            <p><strong>Observed Frequencies ($O_{ij}$):</strong></p>
            <table class="table-auto w-full text-left whitespace-no-wrap">
                <thead>
                    <tr>
                        <th class="px-4 py-3 title-font tracking-wider font-medium text-gray-900 text-sm bg-gray-100">SES</th>
                        <th class="px-4 py-3 title-font tracking-wider font-medium text-gray-900 text-sm bg-gray-100">Outcome 1</th>
                        <th class="px-4 py-3 title-font tracking-wider font-medium text-gray-900 text-sm bg-gray-100">Outcome 2</th>
                        <th class="px-4 py-3 title-font tracking-wider font-medium text-gray-900 text-sm bg-gray-100">Row Total</th>
                    </tr>
                </thead>
                <tbody>
                    <tr><td class="px-4 py-3">Yes</td><td class="px-4 py-3">72</td><td class="px-4 py-3">34</td><td class="px-4 py-3">106</td></tr>
                    <tr><td class="px-4 py-3">No</td><td class="px-4 py-3">48</td><td class="px-4 py-3">46</td><td class="px-4 py-3">94</td></tr>
                    <tr><td class="px-4 py-3"><strong>Column Total</strong></td><td class="px-4 py-3"><strong>120</strong></td><td class="px-4 py-3"><strong>80</strong></td><td class="px-4 py-3"><strong>Grand Total = 200</strong></td></tr>
                </tbody>
            </table>

            <p><strong>Step 3: Calculate Expected Frequencies ($E_{ij}$):</strong></p>
            <ul>
                <li>$E_{\text{Yes, Outcome 1}} = \frac{106 \times 120}{200} = \frac{12720}{200} = 63.6$</li>
                <li>$E_{\text{Yes, Outcome 2}} = \frac{106 \times 80}{200} = \frac{8480}{200} = 42.4$</li>
                <li>$E_{\text{No, Outcome 1}} = \frac{94 \times 120}{200} = \frac{11280}{200} = 56.4$</li>
                <li>$E_{\text{No, Outcome 2}} = \frac{94 \times 80}{200} = \frac{7520}{200} = 37.6$</li>
            </ul>

            <p><strong>Expected Frequencies ($E_{ij}$):</strong></p>
            <table class="table-auto w-full text-left whitespace-no-wrap">
                <thead>
                    <tr>
                        <th class="px-4 py-3 title-font tracking-wider font-medium text-gray-900 text-sm bg-gray-100">SES</th>
                        <th class="px-4 py-3 title-font tracking-wider font-medium text-gray-900 text-sm bg-gray-100">Outcome 1</th>
                        <th class="px-4 py-3 title-font tracking-wider font-medium text-gray-900 text-sm bg-gray-100">Outcome 2</th>
                    </tr>
                </thead>
                <tbody>
                    <tr><td class="px-4 py-3">Yes</td><td class="px-4 py-3">63.6</td><td class="px-4 py-3">42.4</td></tr>
                    <tr><td class="px-4 py-3">No</td><td class="px-4 py-3">56.4</td><td class="px-4 py-3">37.6</td></tr>
                </tbody>
            </table>

            <p><strong>Step 4: Calculate Chi-Square Statistic ($\chi^2$):</strong></p>
            <ul>
                <li>$\frac{(72 - 63.6)^2}{63.6} = \frac{8.4^2}{63.6} = \frac{70.56}{63.6} \approx 1.109$</li>
                <li>$\frac{(34 - 42.4)^2}{42.4} = \frac{(-8.4)^2}{42.4} = \frac{70.56}{42.4} \approx 1.664$</li>
                <li>$\frac{(48 - 56.4)^2}{56.4} = \frac{(-8.4)^2}{56.4} = \frac{70.56}{56.4} \approx 1.251$</li>
                <li>$\frac{(46 - 37.6)^2}{37.6} = \frac{8.4^2}{37.6} = \frac{70.56}{37.6} \approx 1.877$</li>
            </ul>
            <p>$\chi^2 = 1.109 + 1.664 + 1.251 + 1.877 = 5.901$</p>

            <p><strong>Step 5: Determine Degrees of Freedom (df):</strong></p>
            <ul>
                <li>$df = (\text{Rows} - 1) \times (\text{Columns} - 1) = (2 - 1) \times (2 - 1) = 1 \times 1 = 1$</li>
            </ul>

            <p><strong>Step 6: Conclusion (Dec 15):</strong></p>
            <p>For $df = 1$ and a significance level $\alpha=0.05$, the critical $\chi^2$ value is 3.841. Since our calculated $\chi^2 = 5.901$ is greater than the critical value of 3.841, we reject the null hypothesis. This means there is a statistically significant association between SES and the outcome for the Dec 15 dataset.</p>

            <h4>2. Jun 24 Dataset: Responses (e.g., from different groups/departments)</h4>
            <p>The data "Responses: Never [10, 6, 11, 7], Rarely [12, 4, 9, 3], Sometimes [8, 7, 4, 4], Always [10, 3, 6, 6]" implies a 4x4 contingency table where rows are Response Categories (Never, Rarely, Sometimes, Always) and columns are four different groups/conditions. Let's label the columns as Group 1, Group 2, Group 3, Group 4.</p>
            <p><strong>Observed Frequencies ($O_{ij}$):</strong></p>
            <table class="table-auto w-full text-left whitespace-no-wrap">
                <thead>
                    <tr>
                        <th class="px-4 py-3 title-font tracking-wider font-medium text-gray-900 text-sm bg-gray-100">Response</th>
                        <th class="px-4 py-3 title-font tracking-wider font-medium text-gray-900 text-sm bg-gray-100">Group 1</th>
                        <th class="px-4 py-3 title-font tracking-wider font-medium text-gray-900 text-sm bg-gray-100">Group 2</th>
                        <th class="px-4 py-3 title-font tracking-wider font-medium text-gray-900 text-sm bg-gray-100">Group 3</th>
                        <th class="px-4 py-3 title-font tracking-wider font-medium text-gray-900 text-sm bg-gray-100">Group 4</th>
                        <th class="px-4 py-3 title-font tracking-wider font-medium text-gray-900 text-sm bg-gray-100">Row Total</th>
                    </tr>
                </thead>
                <tbody>
                    <tr><td class="px-4 py-3">Never</td><td class="px-4 py-3">10</td><td class="px-4 py-3">6</td><td class="px-4 py-3">11</td><td class="px-4 py-3">7</td><td class="px-4 py-3">34</td></tr>
                    <tr><td class="px-4 py-3">Rarely</td><td class="px-4 py-3">12</td><td class="px-4 py-3">4</td><td class="px-4 py-3">9</td><td class="px-4 py-3">3</td><td class="px-4 py-3">28</td></tr>
                    <tr><td class="px-4 py-3">Sometimes</td><td class="px-4 py-3">8</td><td class="px-4 py-3">7</td><td class="px-4 py-3">4</td><td class="px-4 py-3">4</td><td class="px-4 py-3">23</td></tr>
                    <tr><td class="px-4 py-3">Always</td><td class="px-4 py-3">10</td><td class="px-4 py-3">3</td><td class="px-4 py-3">6</td><td class="px-4 py-3">6</td><td class="px-4 py-3">25</td></tr>
                    <tr><td class="px-4 py-3"><strong>Column Total</strong></td><td class="px-4 py-3"><strong>40</strong></td><td class="px-4 py-3"><strong>20</strong></td><td class="px-4 py-3"><strong>30</strong></td><td class="px-4 py-3"><strong>20</strong></td><td class="px-4 py-3"><strong>Grand Total = 110</strong></td></tr>
                </tbody>
            </table>

            <p><strong>Step 3: Calculate Expected Frequencies ($E_{ij}$):</strong></p>
            <ul>
                <li>$E_{\text{Never, G1}} = \frac{34 \times 40}{110} = \frac{1360}{110} \approx 12.36$</li>
                <li>$E_{\text{Never, G2}} = \frac{34 \times 20}{110} = \frac{680}{110} \approx 6.18$</li>
                <li>$E_{\text{Never, G3}} = \frac{34 \times 30}{110} = \frac{1020}{110} \approx 9.27$</li>
                <li>$E_{\text{Never, G4}} = \frac{34 \times 20}{110} = \frac{680}{110} \approx 6.18$</li>

                <li>$E_{\text{Rarely, G1}} = \frac{28 \times 40}{110} = \frac{1120}{110} \approx 10.18$</li>
                <li>$E_{\text{Rarely, G2}} = \frac{28 \times 20}{110} = \frac{560}{110} \approx 5.09$</li>
                <li>$E_{\text{Rarely, G3}} = \frac{28 \times 30}{110} = \frac{840}{110} \approx 7.64$</li>
                <li>$E_{\text{Rarely, G4}} = \frac{28 \times 20}{110} = \frac{560}{110} \approx 5.09$</li>

                <li>$E_{\text{Sometimes, G1}} = \frac{23 \times 40}{110} = \frac{920}{110} \approx 8.36$</li>
                <li>$E_{\text{Sometimes, G2}} = \frac{23 \times 20}{110} = \frac{460}{110} \approx 4.18$</li>
                <li>$E_{\text{Sometimes, G3}} = \frac{23 \times 30}{110} = \frac{690}{110} \approx 6.27$</li>
                <li>$E_{\text{Sometimes, G4}} = \frac{23 \times 20}{110} = \frac{460}{110} \approx 4.18$</li>

                <li>$E_{\text{Always, G1}} = \frac{25 \times 40}{110} = \frac{1000}{110} \approx 9.09$</li>
                <li>$E_{\text{Always, G2}} = \frac{25 \times 20}{110} = \frac{500}{110} \approx 4.55$</li>
                <li>$E_{\text{Always, G3}} = \frac{25 \times 30}{110} = \frac{750}{110} \approx 6.82$</li>
                <li>$E_{\text{Always, G4}} = \frac{25 \times 20}{110} = \frac{500}{110} \approx 4.55$</li>
            </ul>

            <p><strong>Expected Frequencies ($E_{ij}$):</strong></p>
            <table class="table-auto w-full text-left whitespace-no-wrap">
                <thead>
                    <tr>
                        <th class="px-4 py-3 title-font tracking-wider font-medium text-gray-900 text-sm bg-gray-100">Response</th>
                        <th class="px-4 py-3 title-font tracking-wider font-medium text-gray-900 text-sm bg-gray-100">Group 1</th>
                        <th class="px-4 py-3 title-font tracking-wider font-medium text-gray-900 text-sm bg-gray-100">Group 2</th>
                        <th class="px-4 py-3 title-font tracking-wider font-medium text-gray-900 text-sm bg-gray-100">Group 3</th>
                        <th class="px-4 py-3 title-font tracking-wider font-medium text-gray-900 text-sm bg-gray-100">Group 4</th>
                    </tr>
                </thead>
                <tbody>
                    <tr><td class="px-4 py-3">Never</td><td class="px-4 py-3">12.36</td><td class="px-4 py-3">6.18</td><td class="px-4 py-3">9.27</td><td class="px-4 py-3">6.18</td></tr>
                    <tr><td class="px-4 py-3">Rarely</td><td class="px-4 py-3">10.18</td><td class="px-4 py-3">5.09</td><td class="px-4 py-3">7.64</td><td class="px-4 py-3">5.09</td></tr>
                    <tr><td class="px-4 py-3">Sometimes</td><td class="px-4 py-3">8.36</td><td class="px-4 py-3">4.18</td><td class="px-4 py-3">6.27</td><td class="px-4 py-3">4.18</td></tr>
                    <tr><td class="px-4 py-3">Always</td><td class="px-4 py-3">9.09</td><td class="px-4 py-3">4.55</td><td class="px-4 py-3">6.82</td><td class="px-4 py-3">4.55</td></tr>
                </tbody>
            </table>

            <p><strong>Step 4: Calculate Chi-Square Statistic ($\chi^2$):</strong></p>
            <ul>
                <li>$(\frac{(10 - 12.36)^2}{12.36}) + (\frac{(6 - 6.18)^2}{6.18}) + (\frac{(11 - 9.27)^2}{9.27}) + (\frac{(7 - 6.18)^2}{6.18}) \approx 0.446 + 0.005 + 0.323 + 0.109 = 0.883$</li>
                <li>$(\frac{(12 - 10.18)^2}{10.18}) + (\frac{(4 - 5.09)^2}{5.09}) + (\frac{(9 - 7.64)^2}{7.64}) + (\frac{(3 - 5.09)^2}{5.09}) \approx 0.325 + 0.237 + 0.245 + 0.852 = 1.659$</li>
                <li>$(\frac{(8 - 8.36)^2}{8.36}) + (\frac{(7 - 4.18)^2}{4.18}) + (\frac{(4 - 6.27)^2}{6.27}) + (\frac{(4 - 4.18)^2}{4.18}) \approx 0.015 + 1.905 + 0.825 + 0.008 = 2.753$</li>
                <li>$(\frac{(10 - 9.09)^2}{9.09}) + (\frac{(3 - 4.55)^2}{4.55}) + (\frac{(6 - 6.82)^2}{6.82}) + (\frac{(6 - 4.55)^2}{4.55}) \approx 0.088 + 0.536 + 0.099 + 0.471 = 1.194$</li>
            </ul>
            <p>$\chi^2 = 0.883 + 1.659 + 2.753 + 1.194 = 6.489$</p>
            <p>(Note: Due to rounding of expected values, the sum might slightly vary, but the method is accurate.)</p>

            <p><strong>Step 5: Determine Degrees of Freedom (df):</strong></p>
            <ul>
                <li>$df = (\text{Rows} - 1) \times (\text{Columns} - 1) = (4 - 1) \times (4 - 1) = 3 \times 3 = 9$</li>
            </ul>

            <p><strong>Step 6: Conclusion (Jun 24):</strong></p>
            <p>For $df = 9$ and a significance level $\alpha=0.05$, the critical $\chi^2$ value is 16.919. Since our calculated $\chi^2 = 6.489$ is less than the critical value of 16.919, we fail to reject the null hypothesis. This means there is no statistically significant association between the response categories and the groups for the Jun 24 dataset.</p>

            <div class="button-group">
                <button class="copy-btn" onclick="copyText(this)">Copy Answer</button>
                <button class="status-btn" data-status-action="read" onclick="setQuestionStatus(this.closest('details'), 'read')">Mark as Read</button>
                <button class="status-btn" data-status-action="unread" onclick="setQuestionStatus(this.closest('details'), 'unread')">Mark as Unread</button>
                <button class="status-btn" data-status-action="doubt" onclick="setQuestionStatus(this.closest('details'), 'doubt')">Mark as Doubt</button>
                <button class="notes-card-btn" onclick="toggleNotes(this.closest('details'))">Add/View Notes</button>
            </div>
            <div class="notes-section">
                <textarea placeholder="Write your notes here..." oninput="saveNotes(this.closest('details'), this.value)"></textarea>
            </div>
        </div>
    </details>


    <details data-status="unread">
        <span class="status-icon read" title="Read">✓</span>
        <span class="status-icon doubt" title="Doubt">!</span>
        <summary>
            <span>Explain Kruskal-Wallis ANOVA test with examples.</span>
            <time class="ml-2 text-gray-500 dark:text-gray-400" style="white-space: nowrap; overflow: hidden; text-overflow: ellipsis; font-size: clamp(0.4rem, 1.7vw, 0.9rem); color: #888; font-style: italic;">
 Dec 17, Jun 22, Dec 23, Jun 24
 </time>
            <span class="notes-indicator-icon" title="Notes added">📝</span>
        </summary>
        <div class="content">
            <h3>Kruskal-Wallis H Test (One-Way ANOVA on Ranks)</h3>
            <p>The <strong>Kruskal-Wallis H test</strong> is a non-parametric alternative to the one-way ANOVA. It is used to determine if there are statistically significant differences between two or more independent groups on a continuous or ordinal dependent variable. Unlike ANOVA, it does not assume normality of the data or homogeneity of variances.</p>

            <h4>When to Use:</h4>
            <ul>
                <li>When you have three or more independent groups.</li>
                <li>When the dependent variable is ordinal or continuous but not normally distributed.</li>
                <li>When sample sizes are small or unequal across groups.</li>
            </ul>

            <h4>Hypotheses:</h4>
            <ul>
                <li><strong>Null Hypothesis ($H_0$):</strong> The medians (or mean ranks) of the populations from which the samples are drawn are equal. That is, the samples come from the same distribution.</li>
                <li><strong>Alternative Hypothesis ($H_1$):</strong> At least one population median (or mean rank) is different from the others.</li>
            </ul>

            <h4>Steps for Kruskal-Wallis H Test:</h4>
            <ol>
                <li><strong>Combine and Rank All Data:</strong> Pool all observations from all groups into a single dataset and rank them from the smallest to the largest.</li>
                <li><strong>Handle Ties:</strong> If ties occur, assign each tied observation the average of the ranks they would have received.</li>
                <li><strong>Sum Ranks for Each Group:</strong> Calculate the sum of the ranks ($R_i$) for each of the $k$ groups.</li>
                <li><strong>Calculate the Kruskal-Wallis H Statistic:</strong> The formula for the H statistic is:
                    $$H = \left[ \frac{12}{N(N+1)} \sum_{i=1}^{k} \frac{R_i^2}{n_i} \right] - 3(N+1)$$
                    Where:
                    <ul>
                        <li>$N$ = total number of observations across all groups</li>
                        <li>$k$ = number of groups</li>
                        <li>$n_i$ = number of observations in group $i$</li>
                        <li>$R_i$ = sum of ranks for group $i$</li>
                    </ul>
                </li>
                <li><strong>Determine Degrees of Freedom (df):</strong>
                    $$df = k - 1$$
                </li>
                <li><strong>Compare H with Critical Value (or P-value):</strong> Compare the calculated H value to a critical value from the Chi-Square ($\chi^2$) distribution table with $df = k-1$ at a chosen significance level ($\alpha$). If $H_{calculated} > \chi^2_{critical}$ (or p-value < $\alpha$), reject the null hypothesis.</li>
            </ol>

            <h4>Example: Evaluating the Effectiveness of Three Different Teaching Methods</h4>
            <p>A researcher wants to compare the effectiveness of three different teaching methods (Method A, Method B, Method C) on student test scores. The scores are not normally distributed, and the sample sizes are small. The scores are as follows:</p>
            <ul>
                <li><strong>Method A:</strong> [75, 80, 85, 78, 82] ($n_A=5$)</li>
                <li><strong>Method B:</strong> [60, 65, 70, 62] ($n_B=4$)</li>
                <li><strong>Method C:</strong> [90, 92, 88, 95, 91, 89] ($n_C=6$)</li>
            </ul>
            <p><strong>Total number of observations ($N$) = $5 + 4 + 6 = 15$</strong></p>

            <p><strong>Step 1 & 2: Combine and Rank All Data (with ties)</strong></p>
            <table class="table-auto w-full text-left whitespace-no-wrap">
                <thead>
                    <tr>
                        <th class="px-4 py-3 title-font tracking-wider font-medium text-gray-900 text-sm bg-gray-100 rounded-tl rounded-bl">Score</th>
                        <th class="px-4 py-3 title-font tracking-wider font-medium text-gray-900 text-sm bg-gray-100">Method</th>
                        <th class="px-4 py-3 title-font tracking-wider font-medium text-gray-900 text-sm bg-gray-100 rounded-tr rounded-br">Rank</th>
                    </tr>
                </thead>
                <tbody>
                    <tr><td class="px-4 py-3">60</td><td class="px-4 py-3">B</td><td class="px-4 py-3">1</td></tr>
                    <tr><td class="px-4 py-3">62</td><td class="px-4 py-3">B</td><td class="px-4 py-3">2</td></tr>
                    <tr><td class="px-4 py-3">65</td><td class="px-4 py-3">B</td><td class="px-4 py-3">3</td></tr>
                    <tr><td class="px-4 py-3">70</td><td class="px-4 py-3">B</td><td class="px-4 py-3">4</td></tr>
                    <tr><td class="px-4 py-3">75</td><td class="px-4 py-3">A</td><td class="px-4 py-3">5</td></tr>
                    <tr><td class="px-4 py-3">78</td><td class="px-4 py-3">A</td><td class="px-4 py-3">6</td></tr>
                    <tr><td class="px-4 py-3">80</td><td class="px-4 py-3">A</td><td class="px-4 py-3">7</td></tr>
                    <tr><td class="px-4 py-3">82</td><td class="px-4 py-3">A</td><td class="px-4 py-3">8</td></tr>
                    <tr><td class="px-4 py-3">85</td><td class="px-4 py-3">A</td><td class="px-4 py-3">9</td></tr>
                    <tr><td class="px-4 py-3">88</td><td class="px-4 py-3">C</td><td class="px-4 py-3">10</td></tr>
                    <tr><td class="px-4 py-3">89</td><td class="px-4 py-3">C</td><td class="px-4 py-3">11</td></tr>
                    <tr><td class="px-4 py-3">90</td><td class="px-4 py-3">C</td><td class="px-4 py-3">12</td></tr>
                    <tr><td class="px-4 py-3">91</td><td class="px-4 py-3">C</td><td class="px-4 py-3">13</td></tr>
                    <tr><td class="px-4 py-3">92</td><td class="px-4 py-3">C</td><td class="px-4 py-3">14</td></tr>
                    <tr><td class="px-4 py-3">95</td><td class="px-4 py-3">C</td><td class="px-4 py-3">15</td></tr>
                </tbody>
            </table>

            <p><strong>Step 3: Sum Ranks for Each Group</strong></p>
            <ul>
                <li>$R_A$ (Method A ranks): $5 + 6 + 7 + 8 + 9 = 35$</li>
                <li>$R_B$ (Method B ranks): $1 + 2 + 3 + 4 = 10$</li>
                <li>$R_C$ (Method C ranks): $10 + 11 + 12 + 13 + 14 + 15 = 75$</li>
            </ul>
            <p>Check: $R_A + R_B + R_C = 35 + 10 + 75 = 120$. Total possible sum of ranks for $N=15$ is $\frac{N(N+1)}{2} = \frac{15(16)}{2} = 120$. (Matches)</p>

            <p><strong>Step 4: Calculate the Kruskal-Wallis H Statistic</strong></p>
            $$H = \left[ \frac{12}{N(N+1)} \left( \frac{R_A^2}{n_A} + \frac{R_B^2}{n_B} + \frac{R_C^2}{n_C} \right) \right] - 3(N+1)$$
            $$H = \left[ \frac{12}{15(15+1)} \left( \frac{35^2}{5} + \frac{10^2}{4} + \frac{75^2}{6} \right) \right] - 3(15+1)$$
            $$H = \left[ \frac{12}{15 \times 16} \left( \frac{1225}{5} + \frac{100}{4} + \frac{5625}{6} \right) \right] - 3(16)$$
            $$H = \left[ \frac{12}{240} (245 + 25 + 937.5) \right] - 48$$
            $$H = \left[ 0.05 \times 1207.5 \right] - 48$$
            $$H = 60.375 - 48 = 12.375$$

            <p><strong>Step 5: Determine Degrees of Freedom (df):</strong></p>
            <ul>
                <li>$df = k - 1 = 3 - 1 = 2$</li>
            </ul>

            <p><strong>Step 6: Conclusion (Example):</strong></p>
            <p>For $df = 2$ and a significance level $\alpha=0.05$, the critical $\chi^2$ value from a Chi-Square table is 5.991. Since our calculated $H = 12.375$ is greater than the critical value of 5.991, we reject the null hypothesis. This indicates that there is a statistically significant difference in test scores among at least two of the three teaching methods.</p>
            <p><em>(Note: If the Kruskal-Wallis test is significant, post-hoc tests (e.g., Dunn's test) would typically be performed to identify which specific pairs of groups differ.)</em></p>

            <div class="button-group">
                <button class="copy-btn" onclick="copyText(this)">Copy Answer</button>
                <button class="status-btn" data-status-action="read" onclick="setQuestionStatus(this.closest('details'), 'read')">Mark as Read</button>
                <button class="status-btn" data-status-action="unread" onclick="setQuestionStatus(this.closest('details'), 'unread')">Mark as Unread</button>
                <button class="status-btn" data-status-action="doubt" onclick="setQuestionStatus(this.closest('details'), 'doubt')">Mark as Doubt</button>
                <button class="notes-card-btn" onclick="toggleNotes(this.closest('details'))">Add/View Notes</button>
            </div>
            <div class="notes-section">
                <textarea placeholder="Write your notes here..." oninput="saveNotes(this.closest('details'), this.value)"></textarea>
            </div>
        </div>
    </details>

    <details data-status="unread">
        <span class="status-icon read" title="Read">✓</span>
        <span class="status-icon doubt" title="Doubt">!</span>
        <summary>
            <span>Explain Wilcoxon Matched Pair Signed Rank Test with examples.</span>
            <time class="ml-2 text-gray-500 dark:text-gray-400" style="white-space: nowrap; overflow: hidden; text-overflow: ellipsis; font-size: clamp(0.4rem, 1.7vw, 0.9rem); color: #888; font-style: italic;">
 Dec 17, Jun 22, Dec 23, Jun 24
 </time>
            <span class="notes-indicator-icon" title="Notes added">📝</span>
        </summary>
        <div class="content">
            <h3>Wilcoxon Matched Pair Signed Rank Test</h3>
            <p>The <strong>Wilcoxon Matched Pair Signed Rank Test</strong> (often simply called the Wilcoxon signed-rank test) is a non-parametric statistical test used to compare two dependent samples (paired data) to assess whether their population mean ranks differ. It is the non-parametric equivalent of the paired-samples t-test. It is particularly useful when the assumption of normality for the differences between paired observations is violated.</p>

            <h4>When to Use:</h4>
            <ul>
                <li>When you have two related (matched or paired) samples. This often involves "before-and-after" measurements on the same subjects, or measurements on matched pairs of subjects.</li>
                <li>When the dependent variable is ordinal or continuous but the differences between pairs are not normally distributed.</li>
            </ul>

            <h4>Hypotheses:</h4>
            <ul>
                <li><strong>Null Hypothesis ($H_0$):</strong> The median difference between the paired observations is zero (i.e., there is no difference between the two related groups).</li>
                <li><strong>Alternative Hypothesis ($H_1$):</strong> The median difference between the paired observations is not zero (i.e., there is a significant difference between the two related groups). This can be two-tailed or one-tailed.</li>
            </ul>

            <h4>Steps for Wilcoxon Matched Pair Signed Rank Test:</h4>
            <ol>
                <li><strong>Calculate Differences:</strong> For each pair, find the difference between the two measurements ($d_i = \text{Measurement 2} - \text{Measurement 1}$).</li>
                <li><strong>Exclude Zero Differences:</strong> Discard any pairs where the difference is zero. Adjust the sample size ($N$) accordingly.</li>
                <li><strong>Take Absolute Differences:</strong> Find the absolute value of each non-zero difference ($|d_i|$).</li>
                <li><strong>Rank Absolute Differences:</strong> Rank the absolute differences from smallest to largest. If there are ties, assign them the average of the ranks they would have received.</li>
                <li><strong>Assign Signs to Ranks:</strong> Reassign the original sign (positive or negative) to each rank based on the sign of the original difference ($d_i$).</li>
                <li><strong>Sum Positive and Negative Ranks:</strong> Calculate the sum of the positive ranks ($T_+$) and the sum of the negative ranks ($T_-$).</li>
                <li><strong>Determine the Test Statistic (W):</strong> The test statistic is the smaller of $T_+$ and $T_-$.</li>
                <li><strong>Compare W with Critical Value (or P-value):</strong> Compare the calculated W value with a critical W value from a Wilcoxon signed-rank table (based on the adjusted sample size $N$ and chosen significance level $\alpha$). If $W_{calculated} \le W_{critical}$ (or p-value < $\alpha$), reject the null hypothesis.</li>
            </ol>

            <h4>Example: Assessing the Effect of a Training Program on Productivity</h4>
            <p>A company implements a new training program and wants to see if it improves employee productivity. Productivity scores (on a scale of 0-100) are recorded for 8 employees before and after the training program.</p>

            <p><strong>Observed Data:</strong></p>
            <table class="table-auto w-full text-left whitespace-no-wrap">
                <thead>
                    <tr>
                        <th class="px-4 py-3 title-font tracking-wider font-medium text-gray-900 text-sm bg-gray-100">Employee</th>
                        <th class="px-4 py-3 title-font tracking-wider font-medium text-gray-900 text-sm bg-gray-100">Before (Score 1)</th>
                        <th class="px-4 py-3 title-font tracking-wider font-medium text-gray-900 text-sm bg-gray-100">After (Score 2)</th>
                    </tr>
                </thead>
                <tbody>
                    <tr><td class="px-4 py-3">1</td><td class="px-4 py-3">60</td><td class="px-4 py-3">65</td></tr>
                    <tr><td class="px-4 py-3">2</td><td class="px-4 py-3">70</td><td class="px-4 py-3">72</td></tr>
                    <tr><td class="px-4 py-3">3</td><td class="px-4 py-3">55</td><td class="px-4 py-3">50</td></tr>
                    <tr><td class="px-4 py-3">4</td><td class="px-4 py-3">80</td><td class="px-4 py-3">85</td></tr>
                    <tr><td class="px-4 py-3">5</td><td class="px-4 py-3">75</td><td class="px-4 py-3">75</td></tr>
                    <tr><td class="px-4 py-3">6</td><td class="px-4 py-3">68</td><td class="px-4 py-3">78</td></tr>
                    <tr><td class="px-4 py-3">7</td><td class="px-4 py-3">90</td><td class="px-4 py-3">88</td></tr>
                    <tr><td class="px-4 py-3">8</td><td class="px-4 py-3">62</td><td class="px-4 py-3">68</td></tr>
                </tbody>
            </table>

            <p><strong>Step 1 & 2: Calculate Differences and Exclude Zero Differences</strong></p>
            <table class="table-auto w-full text-left whitespace-no-wrap">
                <thead>
                    <tr>
                        <th class="px-4 py-3 title-font tracking-wider font-medium text-gray-900 text-sm bg-gray-100">Employee</th>
                        <th class="px-4 py-3 title-font tracking-wider font-medium text-gray-900 text-sm bg-gray-100">Difference ($d_i$)</th>
                        <th class="px-4 py-3 title-font tracking-wider font-medium text-gray-900 text-sm bg-gray-100">Absolute Difference ($|d_i|$)</th>
                        <th class="px-4 py-3 title-font tracking-wider font-medium text-gray-900 text-sm bg-gray-100">Rank of $|d_i|$</th>
                        <th class="px-4 py-3 title-font tracking-wider font-medium text-gray-900 text-sm bg-gray-100">Signed Rank</th>
                    </tr>
                </thead>
                <tbody>
                    <tr><td class="px-4 py-3">1</td><td class="px-4 py-3">$65-60=5$</td><td class="px-4 py-3">5</td><td class="px-4 py-3">4.5 (avg of 4,5)</td><td class="px-4 py-3">+4.5</td></tr>
                    <tr><td class="px-4 py-3">2</td><td class="px-4 py-3">$72-70=2$</td><td class="px-4 py-3">2</td><td class="px-4 py-3">2</td><td class="px-4 py-3">+2</td></tr>
                    <tr><td class="px-4 py-3">3</td><td class="px-4 py-3">$50-55=-5$</td><td class="px-4 py-3">5</td><td class="px-4 py-3">4.5 (avg of 4,5)</td><td class="px-4 py-3">-4.5</td></tr>
                    <tr><td class="px-4 py-3">4</td><td class="px-4 py-3">$85-80=5$</td><td class="px-4 py-3">5</td><td class="px-4 py-3">4.5 (avg of 4,5)</td><td class="px-4 py-3">+4.5</td></tr>
                    <tr><td class="px-4 py-3">5</td><td class="px-4 py-3">$75-75=0$</td><td class="px-4 py-3">---</td><td class="px-4 py-3">---</td><td class="px-4 py-3">--- (Excluded)</td></tr>
                    <tr><td class="px-4 py-3">6</td><td class="px-4 py-3">$78-68=10$</td><td class="px-4 py-3">10</td><td class="px-4 py-3">7</td><td class="px-4 py-3">+7</td></tr>
                    <tr><td class="px-4 py-3">7</td><td class="px-4 py-3">$88-90=-2$</td><td class="px-4 py-3">2</td><td class="px-4 py-3">2</td><td class="px-4 py-3">-2</td></tr>
                    <tr><td class="px-4 py-3">8</td><td class="px-4 py-3">$68-62=6$</td><td class="px-4 py-3">6</td><td class="px-4 py-3">6</td><td class="px-4 py-3">+6</td></tr>
                </tbody>
            </table>
            <p>Adjusted sample size ($N$) = 7 (after excluding Employee 5 with a zero difference).</p>

            <p><strong>Step 3, 4, 5: Absolute Differences, Ranks, and Signed Ranks (consolidated in table above)</strong></p>

            <p><strong>Step 6: Sum Positive and Negative Ranks</strong></p>
            <ul>
                <li>Positive Ranks ($T_+$): $4.5 + 2 + 4.5 + 7 + 6 = 24$</li>
                <li>Negative Ranks ($T_-$): $4.5 + 2 = 6.5$</li>
            </ul>
            <p>Check: Sum of ranks for $N=7$ is $\frac{N(N+1)}{2} = \frac{7(8)}{2} = 28$. $T_+ + T_- = 24 + 6.5 = 30.5$. (Slight discrepancy due to tie-averaging rules in some texts. For calculation of W, just pick the smaller.)</p>
            <p>Let's re-calculate the sum of ranks on the ranks shown in the table: $4.5+2+4.5+4.5+7+2+6 = 30.5$. The sum of ranks should be $\frac{N_{non-zero}(N_{non-zero}+1)}{2} = \frac{7(8)}{2} = 28$.
            Let's correct the ranks to ensure the sum of ranks is correct:
            Differences: +5, +2, -5, +5, +10, -2, +6
            Absolute Differences: 2, 2, 5, 5, 5, 6, 10
            Ranks:
            2 (for diff 2): Rank 1.5 (avg of 1,2)
            2 (for diff -2): Rank 1.5 (avg of 1,2)
            5 (for diff 5): Rank 4 (avg of 3,4,5)
            5 (for diff 5): Rank 4 (avg of 3,4,5)
            5 (for diff -5): Rank 4 (avg of 3,4,5)
            6 (for diff 6): Rank 6
            10 (for diff 10): Rank 7

            Revised table for clarity:
            </p>
            <table class="table-auto w-full text-left whitespace-no-wrap">
                <thead>
                    <tr>
                        <th class="px-4 py-3 title-font tracking-wider font-medium text-gray-900 text-sm bg-gray-100">Employee</th>
                        <th class="px-4 py-3 title-font tracking-wider font-medium text-gray-900 text-sm bg-gray-100">Difference ($d_i$)</th>
                        <th class="px-4 py-3 title-font tracking-wider font-medium text-gray-900 text-sm bg-gray-100">Absolute Difference ($|d_i|$)</th>
                        <th class="px-4 py-3 title-font tracking-wider font-medium text-gray-900 text-sm bg-gray-100">Rank of $|d_i|$</th>
                        <th class="px-4 py-3 title-font tracking-wider font-medium text-gray-900 text-sm bg-gray-100">Signed Rank</th>
                    </tr>
                </thead>
                <tbody>
                    <tr><td class="px-4 py-3">1</td><td class="px-4 py-3">5</td><td class="px-4 py-3">5</td><td class="px-4 py-3">4</td><td class="px-4 py-3">+4</td></tr>
                    <tr><td class="px-4 py-3">2</td><td class="px-4 py-3">2</td><td class="px-4 py-3">2</td><td class="px-4 py-3">1.5</td><td class="px-4 py-3">+1.5</td></tr>
                    <tr><td class="px-4 py-3">3</td><td class="px-4 py-3">-5</td><td class="px-4 py-3">5</td><td class="px-4 py-3">4</td><td class="px-4 py-3">-4</td></tr>
                    <tr><td class="px-4 py-3">4</td><td class="px-4 py-3">5</td><td class="px-4 py-3">5</td><td class="px-4 py-3">4</td><td class="px-4 py-3">+4</td></tr>
                    <tr><td class="px-4 py-3">5</td><td class="px-4 py-3">0</td><td class="px-4 py-3">---</td><td class="px-4 py-3">---</td><td class="px-4 py-3">--- (Excluded)</td></tr>
                    <tr><td class="px-4 py-3">6</td><td class="px-4 py-3">10</td><td class="px-4 py-3">10</td><td class="px-4 py-3">7</td><td class="px-4 py-3">+7</td></tr>
                    <tr><td class="px-4 py-3">7</td><td class="px-4 py-3">-2</td><td class="px-4 py-3">2</td><td class="px-4 py-3">1.5</td><td class="px-4 py-3">-1.5</td></tr>
                    <tr><td class="px-4 py-3">8</td><td class="px-4 py-3">6</td><td class="px-4 py-3">6</td><td class="px-4 py-3">6</td><td class="px-4 py-3">+6</td></tr>
                </tbody>
            </table>
            <p>Adjusted sample size ($N$) = 7.</p>
            <p><strong>Step 6 (Recalculated with correct ranks): Sum Positive and Negative Ranks</strong></p>
            <ul>
                <li>Positive Ranks ($T_+$): $4 + 1.5 + 4 + 7 + 6 = 22.5$</li>
                <li>Negative Ranks ($T_-$): $4 + 1.5 = 5.5$</li>
            </ul>
            <p>Check: Sum of ranks for $N=7$ is $\frac{N(N+1)}{2} = \frac{7(8)}{2} = 28$. $T_+ + T_- = 22.5 + 5.5 = 28$. (Matches)</p>

            <p><strong>Step 7: Determine the Test Statistic (W)</strong></p>
            <ul>
                <li>$W = \min(T_+, T_-) = \min(22.5, 5.5) = 5.5$</li>
            </ul>

            <p><strong>Step 8: Conclusion (Example):</strong></p>
            <p>For $N = 7$ and a significance level $\alpha=0.05$ (two-tailed), the critical W value from a Wilcoxon signed-rank table is 2. Since our calculated $W = 5.5$ is greater than the critical value of 2, we fail to reject the null hypothesis. There is no statistically significant evidence to conclude that the training program had an effect on employee productivity.</p>

            <div class="button-group">
                <button class="copy-btn" onclick="copyText(this)">Copy Answer</button>
                <button class="status-btn" data-status-action="read" onclick="setQuestionStatus(this.closest('details'), 'read')">Mark as Read</button>
                <button class="status-btn" data-status-action="unread" onclick="setQuestionStatus(this.closest('details'), 'unread')">Mark as Unread</button>
                <button class="status-btn" data-status-action="doubt" onclick="setQuestionStatus(this.closest('details'), 'doubt')">Mark as Doubt</button>
                <button class="notes-card-btn" onclick="toggleNotes(this.closest('details'))">Add/View Notes</button>
            </div>
            <div class="notes-section">
                <textarea placeholder="Write your notes here..." oninput="saveNotes(this.closest('details'), this.value)"></textarea>
            </div>
        </div>
    </details>
</section>
<section class="topic-card" id="card-normal-distribution-divergence">
    <h2>📌 NORMAL DISTRIBUTION, DIVERGENCE, SKEWNESS, KURTOSIS <time class="ml-2 text-gray-500 dark:text-gray-400" style="white-space: nowrap; overflow: hidden; text-overflow: ellipsis; font-size: clamp(0.4rem, 1.7vw, 0.9rem); color: #888; font-style: italic;">
Jun 16, Dec 16, Jun 18, Dec 19, Dec 21, Dec 22, Jun 24
</time></h2>
	            

    <details data-status="unread">
        <span class="status-icon read" title="Read">✓</span>
        <span class="status-icon doubt" title="Doubt">!</span>
        <summary>
            <span>Explain normal curve, properties of normal probability curve, divergence from normality, skewness, and kurtosis.</span>

            <span class="notes-indicator-icon" title="Notes added">📝</span>
        </summary>
        <div class="content">
            <h3>Normal Distribution (Normal Curve / Gaussian Distribution)</h3>
            <p>The <strong>normal distribution</strong>, often referred to as the normal curve or bell curve, is a symmetrical, bell-shaped probability distribution that describes how the values of a variable are distributed around its mean. It is one of the most important concepts in statistics because many natural phenomena and measurements (e.g., height, blood pressure, IQ scores) tend to follow this pattern. It is foundational for many statistical inference methods.</p>
<img src="https://i.upmath.me/svg/%5Cbegin%7Btikzpicture%7D%5Bscale%3D1.0544%5D%0A%5Cbegin%7Baxis%7D%5B%0A%20%20%20%20axis%20line%20style%3Dgray%2C%0A%20%20%20%20samples%3D120%2C%0A%20%20%20%20width%3D9.0cm%2C%20height%3D6.4cm%2C%0A%20%20%20%20xmin%3D-4%2C%20xmax%3D4%2C%0A%20%20%20%20ymin%3D0%2C%20ymax%3D2.6%2C%20%25%20Increased%20y-axis%20range%20for%20taller%20appearance%0A%20%20%20%20restrict%20y%20to%20domain%3D-0.06%3A2.6%2C%0A%20%20%20%20ytick%3D%7B0.5%2C%201.0%2C%201.5%2C%202.0%2C%202.5%7D%2C%20%25%20Adjusted%20y-ticks%20for%20clarity%0A%20%20%20%20xtick%3D%7B-3%2C-2%2C-1%2C0%2C1%2C2%2C3%7D%2C%0A%20%20%20%20axis%20equal%20image%2C%20%25%20Maintain%20proper%20aspect%20ratio%0A%20%20%20%20axis%20x%20line%3Dcenter%2C%0A%20%20%20%20axis%20y%20line%3Dcenter%2C%0A%20%20%20%20xlabel%3D%24x%24%2C%20ylabel%3D%24f(x)%24%5D%0A%5Caddplot%5Bblue%2Cdomain%3D-4%3A4%2Csemithick%5D%7B1%2Fsqrt(2*pi*0.266%5E2)*exp(-x%5E2%2F(2*0.5%5E2))%7D%20%25%20Decreased%20sigma%20(0.5%20instead%20of%201)%0A%20%20%20%20node%5Bpos%3D0.7%2C%20above%20right%2C%20font%3D%5Csmall%5D%20%7BNormal%7D%3B%20%25%20Label%20for%20the%20curve%0A%5Cpath%20(axis%20cs%3A0%2C0)%20node%20%5Banchor%3Dnorth%20west%2Cyshift%3D-0.07cm%5D%20%7B0%7D%3B%0A%5Cend%7Baxis%7D%0A%5Cend%7Btikzpicture%7D">
            <h4>Properties of the Normal Probability Curve:</h4>
            <ol>
                <li><strong>Symmetry:</strong> The normal curve is perfectly symmetrical around its mean. This means that the left side of the curve is a mirror image of the right side.</li>
                <li><strong>Mean, Median, and Mode Coincide:</strong> For a perfectly normal distribution, the mean, median, and mode are all located at the exact center of the distribution.</li>
                <li><strong>Bell-Shaped:</strong> The distribution has a distinct bell shape, peaking at the mean and tapering off symmetrically towards both tails.</li>
                <li><strong>Asymptotic to the X-axis:</strong> The tails of the normal curve extend infinitely in both directions, approaching the horizontal (x-axis) but never quite touching it. This implies that there's always a theoretical, albeit very small, probability of observing extreme values.</li>
                <li><strong>Unimodal:</strong> The normal distribution has only one peak (mode).</li>
                <li><strong>Total Area Under the Curve:</strong> The total area under the normal probability curve is equal to 1, or 100%, representing the total probability of all possible outcomes.</li>
                <li><strong>Empirical Rule (68-95-99.7 Rule):</strong> This rule provides a quick estimate of the spread of data in a normal distribution:
                    <ul>
                        <li>Approximately <strong>68%</strong> of the data falls within $\pm 1$ standard deviation ($\sigma$) of the mean ($\mu$).</li>
                        <li>Approximately <strong>95%</strong> of the data falls within $\pm 2$ standard deviations ($\sigma$) of the mean ($\mu$).</li>
                        <li>Approximately <strong>99.7%</strong> of the data falls within $\pm 3$ standard deviations ($\sigma$) of the mean ($\mu$).</li>
                    </ul>
                </li>
                <li><strong>Defined by Mean ($\mu$) and Standard Deviation ($\sigma$):</strong> A normal distribution is completely characterized by its mean ($\mu$) and standard deviation ($\sigma$). The mean determines the location of the center of the curve, and the standard deviation determines the spread or width of the curve.</li>
            </ol>

            <h3>Divergence from Normality</h3>
            <p>While the normal distribution is widely used, real-world data often deviate from this ideal shape. <strong>Divergence from normality</strong> refers to the extent to which a dataset's distribution differs from a perfect normal distribution. Understanding these divergences is crucial because many statistical tests (parametric tests like t-tests and ANOVA) assume normality. Violating this assumption can lead to incorrect conclusions.</p>

            <h4>Skewness:</h4>
            <p><strong>Skewness</strong> is a measure of the asymmetry of the probability distribution of a real-valued random variable about its mean. In a perfectly normal distribution, skewness is zero.</p>
            <ul>
                <li><strong>Positive Skew (Right-Skewed):</strong>
                    <ul>
                        <li>The tail on the right side of the distribution is longer or fatter than the left side.</li>
                        <li>The majority of the data points (the peak) are concentrated on the left.</li>
                        <li>Mean > Median > Mode.</li>
                        <li><strong>Diagram:</strong> Imagine a bell curve where the right side stretches out longer.
                            <pre>
                  <img src="https://i.upmath.me/svg/%5Cbegin%7Btikzpicture%7D%5Csmall%0A%5Cbegin%7Baxis%7D%5B%0A%20%20%20%20axis%20line%20style%3Dgray%2C%0A%20%20%20%20samples%3D100%2C%0A%20%20%20%20width%3D9.0cm%2C%20height%3D6.4cm%2C%0A%20%20%20%20xmin%3D-4%2C%20xmax%3D4%2C%0A%20%20%20%20ymin%3D0%2C%20ymax%3D0.5%2C%0A%20%20%20%20restrict%20y%20to%20domain%3D-0.05%3A0.6%2C%0A%20%20%20%20xtick%3D%7B-3%2C%200%2C%203%7D%2C%0A%20%20%20%20ytick%3D%7B0%2C%200.2%2C%200.4%7D%2C%0A%20%20%20%20axis%20x%20line%3Dcenter%2C%0A%20%20%20%20axis%20y%20line%3Dleft%2C%0A%20%20%20%20xlabel%3D%24x%24%2C%0A%20%20%20%20ylabel%3DFrequency%2C%0A%20%20%20%20title%3D%5Ctextbf%7BPositive%20Skew%20(Right-Skewed)%7D%2C%0A%20%20%20%20title%20style%3D%7Byshift%3D0.7em%7D%2C%0A%20%20%20%20grid%3Dvertical%2C%0A%20%20%20%20grid%20style%3D%7Bdashed%2C%20gray!30%7D%0A%5D%0A%5Caddplot%5Bblue!70!black%2C%20line%20width%3D0.8pt%2C%20domain%3D-4%3A4%5D%7B%25%0A%20%20%20%20%25%20This%20is%20a%20custom%20function%20to%20visually%20represent%20positive%20skew%0A%20%20%20%20%25%20It's%20a%20slightly%20manipulated%20normal%20distribution%0A%20%20%20%200.35%20*%20exp(-((x-1.5)%5E2)%2F0.8)%20%2B%200.05%20*%20exp(-((x%2B2)%5E2)%2F3)%0A%7D%3B%0A%25%20Indicate%20Mode%2C%20Median%2C%20Mean%0A%5Cdraw%5Bdashed%2C%20red%5D%20(axis%20cs%3A1.5%2C0)%20--%20(axis%20cs%3A1.5%2C0.35)%3B%20%25%20Mode%0A%5Cnode%5Bred%2C%20anchor%3Dnorth%5D%20at%20(axis%20cs%3A1.5%2C%20-0.01)%20%7BMode%7D%3B%0A%5Cdraw%5Bdashed%2C%20green!70!black%5D%20(axis%20cs%3A0.5%2C0)%20--%20(axis%20cs%3A0.5%2C0.25)%3B%20%25%20Median%20(approx)%0A%5Cnode%5Bgreen!70!black%2C%20anchor%3Dnorth%5D%20at%20(axis%20cs%3A0.5%2C%20-0.01)%20%7BMedian%7D%3B%0A%5Cdraw%5Bdashed%2C%20orange%5D%20(axis%20cs%3A-0.2%2C0)%20--%20(axis%20cs%3A-0.2%2C0.15)%3B%20%25%20Mean%20(approx)%0A%5Cnode%5Borange%2C%20anchor%3Dnorth%5D%20at%20(axis%20cs%3A-0.2%2C%20-0.01)%20%7BMean%7D%3B%0A%5Cnode%5Babove%20right%2C%20text%20width%3D4cm%2C%20align%3Dleft%5D%20at%20(axis%20cs%3A0.5%2C0.4)%20%7BMean%20%24%3E%24%20Median%20%24%3E%24%20Mode%7D%3B%0A%5Cend%7Baxis%7D%0A%5Cend%7Btikzpicture%7D">
                            </pre>
                        </li>
                    </ul>
                </li>
                <li><strong>Negative Skew (Left-Skewed):</strong>
                    <ul>
                        <li>The tail on the left side of the distribution is longer or fatter than the right side.</li>
                        <li>The majority of the data points (the peak) are concentrated on the right.</li>
                        <li>Mean < Median < Mode.</li>
                        <li><strong>Diagram:</strong> Imagine a bell curve where the left side stretches out longer.
                            <pre>
<img src="https://i.upmath.me/svg/%5Cbegin%7Btikzpicture%7D%5Csmall%0A%5Cbegin%7Baxis%7D%5B%0A%20%20%20%20axis%20line%20style%3Dgray%2C%0A%20%20%20%20samples%3D100%2C%0A%20%20%20%20width%3D9.0cm%2C%20height%3D6.4cm%2C%0A%20%20%20%20xmin%3D-4%2C%20xmax%3D4%2C%0A%20%20%20%20ymin%3D0%2C%20ymax%3D0.5%2C%0A%20%20%20%20restrict%20y%20to%20domain%3D-0.05%3A0.6%2C%0A%20%20%20%20xtick%3D%7B-3%2C%200%2C%203%7D%2C%0A%20%20%20%20ytick%3D%7B0%2C%200.2%2C%200.4%7D%2C%0A%20%20%20%20axis%20x%20line%3Dcenter%2C%0A%20%20%20%20axis%20y%20line%3Dleft%2C%0A%20%20%20%20xlabel%3D%24x%24%2C%0A%20%20%20%20ylabel%3DFrequency%2C%0A%20%20%20%20title%3D%5Ctextbf%7BNegative%20Skew%20(Left-Skewed)%7D%2C%0A%20%20%20%20title%20style%3D%7Byshift%3D0.7em%7D%2C%0A%20%20%20%20grid%3Dvertical%2C%0A%20%20%20%20grid%20style%3D%7Bdashed%2C%20gray!30%7D%0A%5D%0A%5Caddplot%5Bblue!70!black%2C%20line%20width%3D0.8pt%2C%20domain%3D-4%3A4%5D%7B%25%0A%20%20%20%20%25%20This%20is%20a%20custom%20function%20to%20visually%20represent%20negative%20skew%0A%20%20%20%20%25%20It's%20a%20slightly%20manipulated%20normal%20distribution%0A%20%20%20%200.35%20*%20exp(-((x%2B1.5)%5E2)%2F0.8)%20%2B%200.05%20*%20exp(-((x-2)%5E2)%2F3)%0A%7D%3B%0A%25%20Indicate%20Mode%2C%20Median%2C%20Mean%0A%5Cdraw%5Bdashed%2C%20red%5D%20(axis%20cs%3A-1.5%2C0)%20--%20(axis%20cs%3A-1.5%2C0.35)%3B%20%25%20Mode%0A%5Cnode%5Bred%2C%20anchor%3Dnorth%5D%20at%20(axis%20cs%3A-1.5%2C%20-0.01)%20%7BMode%7D%3B%0A%5Cdraw%5Bdashed%2C%20green!70!black%5D%20(axis%20cs%3A-0.5%2C0)%20--%20(axis%20cs%3A-0.5%2C0.25)%3B%20%25%20Median%20(approx)%0A%5Cnode%5Bgreen!70!black%2C%20anchor%3Dnorth%5D%20at%20(axis%20cs%3A-0.5%2C%20-0.01)%20%7BMedian%7D%3B%0A%5Cdraw%5Bdashed%2C%20orange%5D%20(axis%20cs%3A0.2%2C0)%20--%20(axis%20cs%3A0.2%2C0.15)%3B%20%25%20Mean%20(approx)%0A%5Cnode%5Borange%2C%20anchor%3Dnorth%5D%20at%20(axis%20cs%3A0.2%2C%20-0.01)%20%7BMean%7D%3B%0A%5Cnode%5Babove%20right%2C%20text%20width%3D4cm%2C%20align%3Dleft%5D%20at%20(axis%20cs%3A0.5%2C0.4)%20%7BMean%20%24%3C%24%20Median%20%24%3C%24%20Mode%7D%3B%0A%5Cend%7Baxis%7D%0A%5Cend%7Btikzpicture%7D">

                            </pre>
                        </li>
                    </ul>
                </li>
            </ul>

            <h4>Kurtosis:</h4>
            <p><strong>Kurtosis</strong> is a measure of the "tailedness" of the probability distribution of a real-valued random variable. It describes the shape of the distribution's tails in relation to its peak. In a perfectly normal distribution, kurtosis (excess kurtosis) is zero.</p>
            <ul>
                <li><strong>Leptokurtic (Positive Kurtosis):</strong>
                    <ul>
                        <li>The distribution has fatter tails and a higher, sharper peak than a normal distribution.</li>
                        <li>Indicates more extreme outliers than a normal distribution.</li>
                        <li><strong>Diagram:</strong> A very tall, thin bell curve with long tails.
                            <pre>
<img src="https://i.upmath.me/svg/%5Cbegin%7Btikzpicture%7D%5Bscale%3D1.0544%5D%0A%5Cbegin%7Baxis%7D%5B%0A%20%20%20%20axis%20line%20style%3Dgray%2C%0A%20%20%20%20samples%3D120%2C%0A%20%20%20%20width%3D9.0cm%2C%20height%3D6.4cm%2C%0A%20%20%20%20xmin%3D-4%2C%20xmax%3D4%2C%0A%20%20%20%20ymin%3D0%2C%20ymax%3D2.6%2C%0A%20%20%20%20restrict%20y%20to%20domain%3D-0.05%3A2.6%2C%0A%20%20%20%20ytick%3D%7B0.5%2C%201.0%2C%201.5%2C%202.0%2C%202.5%7D%2C%0A%20%20%20%20xtick%3D%7B-3%2C-2%2C-1%2C0%2C1%2C2%2C3%7D%2C%0A%20%20%20%20axis%20equal%20image%2C%0A%20%20%20%20axis%20x%20line%3Dcenter%2C%0A%20%20%20%20axis%20y%20line%3Dcenter%2C%0A%20%20%20%20xlabel%3D%24x%24%2C%20ylabel%3D%24f(x)%24%5D%0A%5Caddplot%5Bred%2Cdomain%3D-4%3A4%2Csemithick%5D%7B1%2Fsqrt(2*pi*0.17%5E2)*exp(-x%5E2%2F(2*0.45%5E2))%7D%0A%20%20%20%20node%5Bpos%3D0.8%2C%20above%20right%2C%20font%3D%5Csmall%5D%20%7BLeptokurtic%7D%3B%0A%5Cend%7Baxis%7D%0A%5Cend%7Btikzpicture%7D">
                            </pre>
                        </li>
                    </ul>
                </li>
                <li><strong>Mesokurtic (Zero Kurtosis):</strong>
                    <ul>
                        <li>The distribution has a kurtosis similar to that of a normal distribution.</li>
                        <li>The "ideal" bell curve shape.</li>
                        <li><strong>Diagram:</strong> The standard bell curve.
                            <pre>
<img src="https://i.upmath.me/svg/%5Cbegin%7Btikzpicture%7D%5Bscale%3D1.0544%5D%0A%5Cbegin%7Baxis%7D%5B%0A%20%20%20%20axis%20line%20style%3Dgray%2C%0A%20%20%20%20samples%3D120%2C%0A%20%20%20%20width%3D9.0cm%2C%20height%3D6.4cm%2C%0A%20%20%20%20xmin%3D-4%2C%20xmax%3D4%2C%0A%20%20%20%20ymin%3D0%2C%20ymax%3D2.6%2C%0A%20%20%20%20restrict%20y%20to%20domain%3D-0.05%3A2.6%2C%0A%20%20%20%20ytick%3D%7B0.5%2C%201.0%2C%201.5%2C%202.0%2C%202.5%7D%2C%0A%20%20%20%20xtick%3D%7B-3%2C-2%2C-1%2C0%2C1%2C2%2C3%7D%2C%0A%20%20%20%20axis%20equal%20image%2C%0A%20%20%20%20axis%20x%20line%3Dcenter%2C%0A%20%20%20%20axis%20y%20line%3Dcenter%2C%0A%20%20%20%20xlabel%3D%24x%24%2C%20ylabel%3D%24f(x)%24%5D%0A%5Caddplot%5Bblue%2Cdomain%3D-4%3A4%2Csemithick%5D%7B1%2Fsqrt(2*pi*0.10)*exp(-x%5E2%2F(2*0.75%5E2))%7D%0A%20%20%20%20node%5Bpos%3D0.2%2C%20above%20left%2C%20font%3D%5Csmall%5D%20%7BNormal%7D%3B%0A%5Cend%7Baxis%7D%0A%5Cend%7Btikzpicture%7D">
                            </pre>
                        </li>
                    </ul>
                </li>
                <li><strong>Platykurtic (Negative Kurtosis):</strong>
                    <ul>
                        <li>The distribution has thinner tails and a flatter, broader peak than a normal distribution.</li>
                        <li>Indicates fewer extreme outliers than a normal distribution.</li>
                        <li><strong>Diagram:</strong> A flat, wide bell curve with short tails.
                            <pre>
<img src="https://i.upmath.me/svg/%5Cbegin%7Btikzpicture%7D%5Bscale%3D1.0544%5D%0A%5Cbegin%7Baxis%7D%5B%0A%20%20%20%20axis%20line%20style%3Dgray%2C%0A%20%20%20%20samples%3D120%2C%0A%20%20%20%20width%3D9.0cm%2C%20height%3D6.4cm%2C%0A%20%20%20%20xmin%3D-4%2C%20xmax%3D4%2C%0A%20%20%20%20ymin%3D0%2C%20ymax%3D2.6%2C%0A%20%20%20%20restrict%20y%20to%20domain%3D-0.05%3A2.6%2C%0A%20%20%20%20ytick%3D%7B0.5%2C%201.0%2C%201.5%2C%202.0%2C%202.5%7D%2C%0A%20%20%20%20xtick%3D%7B-3%2C-2%2C-1%2C0%2C1%2C2%2C3%7D%2C%0A%20%20%20%20axis%20equal%20image%2C%0A%20%20%20%20axis%20x%20line%3Dcenter%2C%0A%20%20%20%20axis%20y%20line%3Dcenter%2C%0A%20%20%20%20xlabel%3D%24x%24%2C%20ylabel%3D%24f(x)%24%5D%0A%5Caddplot%5Bgreen%2Cdomain%3D-4%3A4%2Csemithick%5D%7B1%2Fsqrt(2*pi*1.2%5E2)*exp(-x%5E2%2F(2*1.7%5E2))%7D%0A%20%20%20%20node%5Bpos%3D1.1%2C%20below%2C%20font%3D%5Csmall%5D%20%7BPlatykurtic%7D%3B%0A%5Cend%7Baxis%7D%0A%5Cend%7Btikzpicture%7D">
                            </pre>
                        </li>
                    </ul>
                </li>
            </ul>
        </div>
    </details>

    <details data-status="unread">
        <span class="status-icon read" title="Read">✓</span>
        <span class="status-icon doubt" title="Doubt">!</span>
        <summary>
            <span>Describe divergence in normality with diagrams and factors causing divergence.</span>

            <span class="notes-indicator-icon" title="Notes added">📝</span>
        </summary>
        <div class="content">
            <h3>Divergence in Normality</h3>
            <p>As discussed, divergence from normality refers to how a dataset's distribution deviates from the ideal symmetrical, bell-shaped normal curve. The primary ways this divergence manifests are through <strong>skewness</strong> (asymmetry) and <strong>kurtosis</strong> (tailedness/peakedness).</p>

            <h4>Diagrams for Divergence:</h4>
            <p><strong>1. Skewness Diagrams:</strong></p>
            <div style="font-family: monospace; font-size: 0.9em; line-height: 1.2;">
                <p><strong>Negative Skew (Left Skew):</strong> Tail extends to the left, peak shifted right.</p>
                <pre>
                 ___
               /     \
             /         \
           /             \
         /                 \
        /                   \__
      /_______________________)
    Mode > Median > Mean
                </pre>
                <p><strong>Symmetrical (Normal/Zero Skew):</strong> Even tails, peak in center.</p>
                <pre>
            ___/^\___
           /         \
          /           \
         /             \
        /_______________\
      Mean = Median = Mode
                </pre>
                <p><strong>Positive Skew (Right Skew):</strong> Tail extends to the right, peak shifted left.</p>
                <pre>
        (_______________________
           \                   /
            \                 /
             \               /
              \             /
               \           /
                \___/
     Mean > Median > Mode
                </pre>
            </div>

            <p><strong>2. Kurtosis Diagrams:</strong></p>
            <div style="font-family: monospace; font-size: 0.9em; line-height: 1.2;">
                <p><strong>Leptokurtic (High Peak, Fat Tails):</strong></p>
                <pre>
<img src="https://i.upmath.me/svg/%5Cbegin%7Btikzpicture%7D%5Bscale%3D1.0544%5D%0A%5Cbegin%7Baxis%7D%5B%0A%20%20%20%20axis%20line%20style%3Dgray%2C%0A%20%20%20%20samples%3D120%2C%0A%20%20%20%20width%3D9.0cm%2C%20height%3D6.4cm%2C%0A%20%20%20%20xmin%3D-4%2C%20xmax%3D4%2C%0A%20%20%20%20ymin%3D0%2C%20ymax%3D2.6%2C%0A%20%20%20%20restrict%20y%20to%20domain%3D-0.05%3A2.6%2C%0A%20%20%20%20ytick%3D%7B0.5%2C%201.0%2C%201.5%2C%202.0%2C%202.5%7D%2C%0A%20%20%20%20xtick%3D%7B-3%2C-2%2C-1%2C0%2C1%2C2%2C3%7D%2C%0A%20%20%20%20axis%20equal%20image%2C%0A%20%20%20%20axis%20x%20line%3Dcenter%2C%0A%20%20%20%20axis%20y%20line%3Dcenter%2C%0A%20%20%20%20xlabel%3D%24x%24%2C%20ylabel%3D%24f(x)%24%5D%0A%5Caddplot%5Bred%2Cdomain%3D-4%3A4%2Csemithick%5D%7B1%2Fsqrt(2*pi*0.17%5E2)*exp(-x%5E2%2F(2*0.45%5E2))%7D%0A%20%20%20%20node%5Bpos%3D0.8%2C%20above%20right%2C%20font%3D%5Csmall%5D%20%7BLeptokurtic%7D%3B%0A%5Cend%7Baxis%7D%0A%5Cend%7Btikzpicture%7D">
                </pre>
                <p><strong>Mesokurtic (Normal Kurtosis):</strong></p>
                <pre>
<img src="https://i.upmath.me/svg/%5Cbegin%7Btikzpicture%7D%5Bscale%3D1.0544%5D%0A%5Cbegin%7Baxis%7D%5B%0A%20%20%20%20axis%20line%20style%3Dgray%2C%0A%20%20%20%20samples%3D120%2C%0A%20%20%20%20width%3D9.0cm%2C%20height%3D6.4cm%2C%0A%20%20%20%20xmin%3D-4%2C%20xmax%3D4%2C%0A%20%20%20%20ymin%3D0%2C%20ymax%3D2.6%2C%0A%20%20%20%20restrict%20y%20to%20domain%3D-0.05%3A2.6%2C%0A%20%20%20%20ytick%3D%7B0.5%2C%201.0%2C%201.5%2C%202.0%2C%202.5%7D%2C%0A%20%20%20%20xtick%3D%7B-3%2C-2%2C-1%2C0%2C1%2C2%2C3%7D%2C%0A%20%20%20%20axis%20equal%20image%2C%0A%20%20%20%20axis%20x%20line%3Dcenter%2C%0A%20%20%20%20axis%20y%20line%3Dcenter%2C%0A%20%20%20%20xlabel%3D%24x%24%2C%20ylabel%3D%24f(x)%24%5D%0A%5Caddplot%5Bblue%2Cdomain%3D-4%3A4%2Csemithick%5D%7B1%2Fsqrt(2*pi*0.10)*exp(-x%5E2%2F(2*0.75%5E2))%7D%0A%20%20%20%20node%5Bpos%3D0.2%2C%20above%20left%2C%20font%3D%5Csmall%5D%20%7BNormal%7D%3B%0A%5Cend%7Baxis%7D%0A%5Cend%7Btikzpicture%7D">
                </pre>
                <p><strong>Platykurtic (Flat Peak, Thin Tails):</strong></p>
                <pre>
<img src="https://i.upmath.me/svg/%5Cbegin%7Btikzpicture%7D%5Bscale%3D1.0544%5D%0A%5Cbegin%7Baxis%7D%5B%0A%20%20%20%20axis%20line%20style%3Dgray%2C%0A%20%20%20%20samples%3D120%2C%0A%20%20%20%20width%3D9.0cm%2C%20height%3D6.4cm%2C%0A%20%20%20%20xmin%3D-4%2C%20xmax%3D4%2C%0A%20%20%20%20ymin%3D0%2C%20ymax%3D2.6%2C%0A%20%20%20%20restrict%20y%20to%20domain%3D-0.05%3A2.6%2C%0A%20%20%20%20ytick%3D%7B0.5%2C%201.0%2C%201.5%2C%202.0%2C%202.5%7D%2C%0A%20%20%20%20xtick%3D%7B-3%2C-2%2C-1%2C0%2C1%2C2%2C3%7D%2C%0A%20%20%20%20axis%20equal%20image%2C%0A%20%20%20%20axis%20x%20line%3Dcenter%2C%0A%20%20%20%20axis%20y%20line%3Dcenter%2C%0A%20%20%20%20xlabel%3D%24x%24%2C%20ylabel%3D%24f(x)%24%5D%0A%5Caddplot%5Bgreen%2Cdomain%3D-4%3A4%2Csemithick%5D%7B1%2Fsqrt(2*pi*1.2%5E2)*exp(-x%5E2%2F(2*1.7%5E2))%7D%0A%20%20%20%20node%5Bpos%3D1.1%2C%20below%2C%20font%3D%5Csmall%5D%20%7BPlatykurtic%7D%3B%0A%5Cend%7Baxis%7D%0A%5Cend%7Btikzpicture%7D">
                </pre>
            </div>

            <h4>Factors Causing Divergence from Normality:</h4>
            <p>Several factors can lead to a dataset diverging from a normal distribution:</p>
            <ol>
                <li><strong>Outliers:</strong> Extreme values (either very high or very low) that are far from the majority of the data can pull the mean away from the median, causing skewness, and can significantly affect kurtosis by extending the tails.</li>
                <li><strong>Measurement Limitations (Floor/Ceiling Effects):</strong>
                    <ul>
                        <li><strong>Floor Effect (Positive Skew):</strong> When data cannot fall below a certain value (e.g., test scores cannot be below 0), results tend to cluster at the low end and tail off to the high end.</li>
                        <li><strong>Ceiling Effect (Negative Skew):</strong> When data cannot exceed a certain value (e.g., a very easy test where many score 100%), results cluster at the high end and tail off to the low end.</li>
                    </ul>
                </li>
                <li><strong>Sampling Bias:</strong> If the sample is not representative of the population, it can lead to a skewed or non-normal distribution. For example, sampling only from a specific subgroup.</li>
                <li><strong>Non-Homogeneous Populations:</strong> If the data are drawn from multiple distinct populations that have different means or distributions, combining them can result in a multimodal or non-normal distribution.</li>
                <li><strong>Nature of the Variable:</strong> Some variables are inherently non-normal. For example:
                    <ul>
                        <li><strong>Income:</strong> Often positively skewed (few very rich people, many with lower incomes).</li>
                        <li><strong>Reaction Times:</strong> Often positively skewed (a lower bound of 0, but a long tail of slow reactions).</li>
                        <li><strong>Count Data:</strong> (e.g., number of traffic accidents, number of defects) often follow Poisson or negative binomial distributions, especially when means are low.</li>
                    </ul>
                </li>
                <li><strong>Errors in Data Entry or Measurement:</strong> Mistakes during data collection or input can introduce spurious extreme values, leading to skewness or heavy tails.</li>
                <li><strong>Transformations:</strong> Applying certain mathematical transformations (e.g., logarithm, square root) to normalize skewed data can sometimes inadvertently create other forms of non-normality if not used appropriately.</li>
                <li><strong>Small Sample Sizes:</strong> While small samples don't inherently cause non-normality in the population, they are less likely to perfectly reflect the population distribution and can appear non-normal by chance, making it harder to definitively assess normality.</li>
            </ol>
            <p>Detecting divergence from normality is usually done through visual inspection (histograms, Q-Q plots) and statistical tests (e.g., Shapiro-Wilk test, Kolmogorov-Smirnov test).</p>
            <div class="button-group">
                <button class="copy-btn" onclick="copyText(this)">Copy Answer</button>
                <button class="status-btn" data-status-action="read" onclick="setQuestionStatus(this.closest('details'), 'read')">Mark as Read</button>
                <button class="status-btn" data-status-action="unread" onclick="setQuestionStatus(this.closest('details'), 'unread')">Mark as Unread</button>
                <button class="status-btn" data-status-action="doubt" onclick="setQuestionStatus(this.closest('details'), 'doubt')">Mark as Doubt</button>
                <button class="notes-card-btn" onclick="toggleNotes(this.closest('details'))">Add/View Notes</button>
            </div>
            <div class="notes-section">
                <textarea placeholder="Write your notes here..." oninput="saveNotes(this.closest('details'), this.value)"></textarea>
            </div>
        </div>
    </details>

    <details data-status="unread">
        <span class="status-icon read" title="Read">✓</span>
        <span class="status-icon doubt" title="Doubt">!</span>
        <summary>
            <span>Explain Type I/II errors and outliers.</span>

            <span class="notes-indicator-icon" title="Notes added">📝</span>
        </summary>
        <div class="content">
            <h3>Type I and Type II Errors in Hypothesis Testing</h3>
            <p>In statistical hypothesis testing, we make decisions about a population based on sample data. Since we are dealing with probabilities and samples, there's always a risk of making an incorrect decision. These incorrect decisions are categorized as Type I and Type II errors.</p>

            <table class="table-auto w-full text-left whitespace-no-wrap">
                <thead>
                    <tr>
                        <th class="px-4 py-3 title-font tracking-wider font-medium text-gray-900 text-sm bg-gray-100">Decision</th>
                        <th class="px-4 py-3 title-font tracking-wider font-medium text-gray-900 text-sm bg-gray-100">H₀ is True (No Effect/Difference)</th>
                        <th class="px-4 py-3 title-font tracking-wider font-medium text-gray-900 text-sm bg-gray-100">H₀ is False (Effect/Difference Exists)</th>
                    </tr>
                </thead>
                <tbody>
                    <tr><td class="px-4 py-3"><strong>Reject H₀</strong></td><td class="px-4 py-3"><strong>Type I Error ($\alpha$)</strong><br>(False Positive)</td><td class="px-4 py-3">Correct Decision<br>(Power: $1-\beta$)</td></tr>
                    <tr><td class="px-4 py-3"><strong>Fail to Reject H₀</strong></td><td class="px-4 py-3">Correct Decision</td><td class="px-4 py-3"><strong>Type II Error ($\beta$)</strong><br>(False Negative)</td></tr>
                </tbody>
            </table>

            <h4>1. Type I Error ($\alpha$ - Alpha Error / False Positive):</h4>
            <ul>
                <li><strong>Definition:</strong> A Type I error occurs when you **incorrectly reject a true null hypothesis**. In simpler terms, you conclude that there is a significant effect, relationship, or difference when, in reality, there is none.</li>
                <li><strong>Analogy:</strong> A medical test indicates a person has a disease when they actually don't (false positive). Or, in a court of law, convicting an innocent person.</li>
                <li><strong>Probability:</strong> The probability of making a Type I error is denoted by $\alpha$ (alpha), which is also known as the <strong>significance level</strong>. Researchers set $\alpha$ before conducting the test (commonly 0.05 or 0.01).</li>
                <li><strong>Control:</strong> You have direct control over $\alpha$. Decreasing $\alpha$ (e.g., from 0.05 to 0.01) reduces the chance of a Type I error, but it increases the chance of a Type II error.</li>
                <li><strong>Consequences:</strong> Can lead to wasting resources pursuing a non-existent effect, implementing ineffective treatments, or misinforming.</li>
            </ul>

            <h4>2. Type II Error ($\beta$ - Beta Error / False Negative):</h4>
            <ul>
                <li><strong>Definition:</strong> A Type II error occurs when you **fail to reject a false null hypothesis**. In simpler terms, you conclude that there is no significant effect, relationship, or difference when, in reality, there is one.</li>
                <li><strong>Analogy:</strong> A medical test indicates a person does not have a disease when they actually do (false negative). Or, in a court of law, letting a guilty person go free.</li>
                <li><strong>Probability:</strong> The probability of making a Type II error is denoted by $\beta$ (beta).</li>
                <li><strong>Power:</strong> The complement of a Type II error is statistical power ($1 - \beta$), which is the probability of correctly rejecting a false null hypothesis (i.e., detecting an effect when it truly exists).</li>
                <li><strong>Factors Affecting $\beta$:</strong> Sample size (larger samples generally reduce $\beta$), effect size (larger effects are easier to detect, thus lower $\beta$), and significance level $\alpha$ (decreasing $\alpha$ increases $\beta$).</li>
                <li><strong>Consequences:</strong> Can lead to missing out on important discoveries, failing to implement effective treatments, or overlooking genuine problems.</li>
            </ul>
            <p>There's an inverse relationship between Type I and Type II errors: decreasing one typically increases the other. The researcher must balance these risks based on the consequences of each type of error in their specific research context.</p>

            <h3>Outliers</h3>
            <p>An <strong>outlier</strong> is an observation point that is distant from other observations. In other words, an outlier is an observation that lies an abnormal distance from other values in a random sample from a population.</p>

            <h4>Characteristics of Outliers:</h4>
            <ul>
                <li>They can be much larger or much smaller than the rest of the data.</li>
                <li>They deviate significantly from the overall pattern of the data.</li>
            </ul>

            <h4>Causes of Outliers:</h4>
            <ol>
                <li><strong>Measurement Error:</strong> Mistakes during data collection, entry, or instrument malfunction (e.g., a faulty sensor reading).</li>
                <li><strong>Data Entry Error:</strong> A typo when inputting data (e.g., typing 1000 instead of 100).</li>
                <li><strong>Natural Variation:</strong> Genuine, but extreme, observations that are part of the true variability of the population (e.g., an exceptionally tall person in a height dataset).</li>
                <li><strong>Experimental Error:</strong> A deviation in the experimental procedure or conditions.</li>
                <li><strong>Intentional Outliers:</strong> Sometimes, subjects may intentionally provide incorrect data (e.g., survey respondents).</li>
                <li><strong>Sampling Error:</strong> An unusual case being included in a small sample by chance.</li>
                <li><strong>Population Heterogeneity:</strong> The sample might contain data from different underlying populations (e.g., mixing data from children and adults without proper segmentation).</li>
            </ol>

            <h4>Impact of Outliers:</h4>
            <ul>
                <li><strong>Distortion of Statistics:</strong> Outliers can heavily influence descriptive statistics like the mean and standard deviation, pulling the mean towards the outlier. The median is more robust to outliers.</li>
                <li><strong>Violation of Assumptions:</strong> Many parametric statistical tests (like t-tests, ANOVA, linear regression) assume normality and homogeneity of variance. Outliers can violate these assumptions, leading to invalid test results.</li>
                <li><strong>Misleading Models:</strong> In regression analysis, outliers can significantly alter the slope and intercept of the regression line, leading to a poor fit and inaccurate predictions.</li>
                <li><strong>Reduced Statistical Power:</strong> They can increase variability, making it harder to detect true effects.</li>
            </ul>

            <h4>Detection and Treatment of Outliers:</h4>
            <p><strong>Detection Methods:</strong></p>
            <ul>
                <li><strong>Visual Inspection:</strong> Box plots, histograms, scatter plots.</li>
                <li><strong>Statistical Tests:</strong> Grubb's Test, Dixon's Q Test.</li>
                <li><strong>IQR Rule:</strong> Data points below $Q_1 - 1.5 \times IQR$ or above $Q_3 + 1.5 \times IQR$ are considered potential outliers.</li>
                <li><strong>Z-scores:</strong> Values with Z-scores beyond $\pm 2$ or $\pm 3$ standard deviations from the mean.</li>
            </ul>
            <p><strong>Treatment Methods (should be done carefully and justified):</strong></p>
            <ul>
                <li><strong>Correction:</strong> If it's a data entry error, correct it.</li>
                <li><strong>Removal:</strong> If the outlier is due to a clear error and cannot be corrected, it might be removed (e.g., an individual who didn't follow instructions). However, this should be done cautiously and explicitly reported.</li>
                <li><strong>Transformation:</strong> Data transformations (e.g., logarithmic, square root) can reduce the impact of extreme values and make the data more normally distributed.</li>
                <li><strong>Non-parametric Methods:</strong> Use statistical tests that are less sensitive to outliers (e.g., Mann-Whitney U test, Kruskal-Wallis H test, median regression).</li>
                <li><strong>Robust Statistics:</strong> Use statistical methods that are designed to be less affected by outliers (e.g., trimmed mean, median absolute deviation).</li>
                <li><strong>Keep and Investigate:</strong> Sometimes outliers are the most interesting data points, revealing unusual phenomena or new insights. They should not be removed automatically without investigation.</li>
            </ul>
            <p>The decision to remove or adjust outliers should never be arbitrary. It requires careful consideration of the context, potential causes, and impact on the analysis, and should always be transparently reported.</p>

            <div class="button-group">
                <button class="copy-btn" onclick="copyText(this)">Copy Answer</button>
                <button class="status-btn" data-status-action="read" onclick="setQuestionStatus(this.closest('details'), 'read')">Mark as Read</button>
                <button class="status-btn" data-status-action="unread" onclick="setQuestionStatus(this.closest('details'), 'unread')">Mark as Unread</button>
                <button class="status-btn" data-status-action="doubt" onclick="setQuestionStatus(this.closest('details'), 'doubt')">Mark as Doubt</button>
                <button class="notes-card-btn" onclick="toggleNotes(this.closest('details'))">Add/View Notes</button>
            </div>
            <div class="notes-section">
                <textarea placeholder="Write your notes here..." oninput="saveNotes(this.closest('details'), this.value)"></textarea>
            </div>
        </div>
    </details>
</section>

<section class="topic-card" id="card-errors-standard-error-degrees-of-freedom">
    <h2>📌 ERRORS, STANDARD ERROR, DEGREES OF FREEDOM</h2>

    <details data-status="unread">
        <span class="status-icon read" title="Read">✓</span>
        <span class="status-icon doubt" title="Doubt">!</span>
        <summary>
            <span>Write short notes on Type I/II errors, standard error, and degrees of freedom. Discuss the importance and application of standard error of means.</span>
            <time class="ml-2 text-gray-500 dark:text-gray-400" style="white-space: nowrap; overflow: hidden; text-overflow: ellipsis; font-size: clamp(0.4rem, 1.7vw, 0.9rem); color: #888; font-style: italic;">
Dec 15, Dec 17, Jun 18, Dec 19, Dec 22, Jun 24
</time>
            <span class="notes-indicator-icon" title="Notes added">📝</span>
        </summary>
        <div class="content">
            <h3>Type I and Type II Errors</h3>
            <p><strong>Type I and Type II errors</strong> are critical concepts in hypothesis testing, representing the two types of incorrect conclusions that can be made when evaluating a null hypothesis. I've covered these in detail in the <a href="#card-normal-distribution-divergence">Normal Distribution, Divergence, Skewness, Kurtosis</a> section, under the explanation of "Type I/II errors and outliers." Briefly:</p>
            <ul>
                <li><strong>Type I Error ($\alpha$ / False Positive):</strong> Incorrectly rejecting a true null hypothesis. The probability of this error is set by the significance level ($\alpha$).</li>
                <li><strong>Type II Error ($\beta$ / False Negative):</strong> Failing to reject a false null hypothesis. The probability of this error is denoted by $\beta$, and its complement ($1-\beta$) is statistical power.</li>
            </ul>

            <h3>Standard Error</h3>
            <p>The <strong>standard error (SE)</strong> is a measure of the statistical accuracy of an estimate. It quantifies how much the sample statistic (e.g., sample mean, sample proportion, regression coefficient) is likely to vary from the true population parameter if we were to take many different samples from the same population. Essentially, it's the standard deviation of the sampling distribution of a statistic.</p>

            <h4>Standard Error of the Mean (SEM):</h4>
            <p>The most common type of standard error is the <strong>standard error of the mean (SEM)</strong>. It tells us how precisely we have estimated the true population mean using our sample mean. The formula for the SEM is:</p>
            $$SEM = \frac{\sigma}{\sqrt{n}}$$
            Where:</p>
            <ul>
                <li>$\sigma$ is the population standard deviation.</li>
                <li>$n$ is the sample size.</li>
            </ul>
            <p>If the population standard deviation ($\sigma$) is unknown (which is usually the case), we estimate it using the sample standard deviation ($s$):</p>
            $$SEM \approx \frac{s}{\sqrt{n}}$$
            Where:</p>
            <ul>
                <li>$s$ is the sample standard deviation.</li>
                <li>$n$ is the sample size.</li>
            </ul>

            <h4>Importance and Application of Standard Error of Means:</h4>
            <ol>
                <li><strong>Measure of Precision:</strong> The SEM is a direct measure of how precise the sample mean is as an estimate of the population mean. A smaller SEM indicates a more precise estimate.</li>
                <li><strong>Relationship with Sample Size:</strong> As the sample size ($n$) increases, the $\sqrt{n}$ in the denominator increases, which leads to a decrease in the SEM. This mathematically illustrates that larger samples yield more precise estimates of the population mean. This aligns with the intuition that more data generally lead to better estimations.</li>
                <li><strong>Construction of Confidence Intervals:</strong> The SEM is a critical component in constructing confidence intervals for the population mean. A confidence interval provides a range of values within which the true population mean is likely to fall. For example, a 95% confidence interval for the mean is often calculated as:
                    $$\bar{X} \pm (t_{\alpha/2} \times SEM)$$
                    or
                    $$\bar{X} \pm (Z_{\alpha/2} \times SEM)$$
                    where $\bar{X}$ is the sample mean, $t_{\alpha/2}$ or $Z_{\alpha/2}$ are critical values from the t or Z distribution, respectively, and SEM is the standard error of the mean.</li>
                <li><strong>Hypothesis Testing:</strong> The SEM is used in the calculation of test statistics for many hypothesis tests involving means (e.g., t-tests). For example, a one-sample t-statistic is calculated as:
                    $$t = \frac{\bar{X} - \mu_0}{SEM}$$
                    where $\mu_0$ is the hypothesized population mean. A smaller SEM will result in a larger t-value for the same observed difference, making it more likely to reject the null hypothesis if a real difference exists.</li>
                <li><strong>Comparison Across Studies:</strong> The SEM allows researchers to compare the precision of mean estimates across different studies, even if they have different sample sizes or standard deviations.</li>
                <li><strong>Interpretation of Results:</strong> Reporting the SEM alongside the mean gives a more complete picture of the data than just the mean alone. It helps readers understand the variability of the sample mean and its reliability as an estimate of the population mean.</li>
                <li><strong>Impact on Statistical Power:</strong> A smaller SEM (due to larger sample size or less data variability) contributes to higher statistical power, meaning a greater ability to detect a true effect if one exists.</li>
            </ol>
            <p>In essence, the standard error quantifies the uncertainty or sampling variability associated with a sample statistic, enabling more robust statistical inference.</p>

            <h3>Degrees of Freedom (df)</h3>
            <p><strong>Degrees of freedom (df)</strong> refer to the number of independent pieces of information that are free to vary in a data set for a given statistical estimation. In simpler terms, it's the number of values in the final calculation of a statistic that are free to vary.</p>

            <h4>Concept of Degrees of Freedom:</h4>
            <p>Imagine you have a set of numbers, and you calculate their mean. If you know the mean and all but one of the values, the last value is fixed (it has no freedom to vary) because it must satisfy the condition that the sum of all values divided by their count equals the mean. For example, if you have 5 numbers and their mean is 10, and you know four of them (e.g., 8, 12, 9, 11), the fifth number *must* be 10 to make the mean equal to 10. In this case, 4 values were free to vary, but the 5th was not. So, you have $n-1$ degrees of freedom when estimating variance from a sample mean.</p>

            <h4>Importance and Application of Degrees of Freedom:</h4>
            <ol>
                <li><strong>Statistical Inference:</strong> Degrees of freedom are crucial for determining the correct sampling distribution (e.g., t-distribution, Chi-square distribution, F-distribution) to use for hypothesis testing and confidence interval estimation. Different distributions (and their critical values) depend on the specific degrees of freedom.</li>
                <li><strong>Correcting for Bias:</strong> Using $n-1$ (instead of $n$) in the denominator when calculating sample variance ($s^2$) makes the sample variance an unbiased estimator of the population variance ($\sigma^2$). This is because one degree of freedom is "lost" by using the sample mean in the calculation.</li>
                <li><strong>Context-Specific Calculation:</strong> The calculation of degrees of freedom varies depending on the statistical test or model being used, reflecting the number of independent pieces of information available for estimating parameters or testing hypotheses.</li>
            </ol>

            <h4>Examples of Degrees of Freedom in Various Tests:</h4>
            <ul>
                <li><strong>One-Sample T-test:</strong>
                    <ul>
                        <li>$df = n - 1$</li>
                        <li>(where $n$ is the sample size). One degree of freedom is lost because the sample mean is used to estimate the population mean.</li>
                    </ul>
                </li>
                <li><strong>Independent Samples T-test:</strong>
                    <ul>
                        <li>Pooled variance: $df = n_1 + n_2 - 2$</li>
                        <li>(where $n_1$ and $n_2$ are the sample sizes of the two groups). Two degrees of freedom are lost because two sample means are used to estimate two population means.</li>
                    </ul>
                </li>
                <li><strong>One-Way ANOVA (F-test):</strong>
                    <ul>
                        <li>Between-Groups $df$: $k - 1$ (where $k$ is the number of groups)</li>
                        <li>Within-Groups (Error) $df$: $N_{total} - k$ (where $N_{total}$ is the total number of observations)</li>
                        <li>The F-statistic uses both these degrees of freedom.</li>
                    </ul>
                </li>
                <li><strong>Chi-Square Test of Independence:</strong>
                    <ul>
                        <li>$df = (\text{number of rows} - 1) \times (\text{number of columns} - 1)$</li>
                        <li>This formula reflects the number of cell frequencies that are free to vary once the row and column totals (which are derived from the data) are fixed.</li>
                    </ul>
                </li>
                <li><strong>Regression Analysis:</strong>
                    <ul>
                        <li>Residual $df = n - k - 1$ (where $n$ is sample size, $k$ is number of independent variables). One degree of freedom is lost for the intercept, and $k$ for the slopes of the predictors.</li>
                    </ul>
                </li>
            </ul>
            <p>Understanding degrees of freedom ensures that the statistical tests are applied correctly and that the results are interpreted accurately, especially when comparing calculated test statistics to critical values from theoretical distributions.</p>
            <div class="button-group">
                <button class="copy-btn" onclick="copyText(this)">Copy Answer</button>
                <button class="status-btn" data-status-action="read" onclick="setQuestionStatus(this.closest('details'), 'read')">Mark as Read</button>
                <button class="status-btn" data-status-action="unread" onclick="setQuestionStatus(this.closest('details'), 'unread')">Mark as Unread</button>
                <button class="status-btn" data-status-action="doubt" onclick="setQuestionStatus(this.closest('details'), 'doubt')">Mark as Doubt</button>
                <button class="notes-card-btn" onclick="toggleNotes(this.closest('details'))">Add/View Notes</button>
            </div>
            <div class="notes-section">
                <textarea placeholder="Write your notes here..." oninput="saveNotes(this.closest('details'), this.value)"></textarea>
            </div>
        </div>
    </details>
</section>

<section class="topic-card" id="card-short-notes-definitions">
    <h2>📝 SHORT NOTES / DEFINITIONS</h2>

    <details data-status="unread">
        <span class="status-icon read" title="Read">✓</span>
        <span class="status-icon doubt" title="Doubt">!</span>
        <summary>
            <span>Short notes on Level of Significance, Linear vs. Non-linear Relationships, Kurtosis, Tetrachoric Correlation, and Scatter Plot.</span>
            <time class="ml-2 text-gray-500 dark:text-gray-400" style="white-space: nowrap; overflow: hidden; text-overflow: ellipsis; font-size: clamp(0.4rem, 1.7vw, 0.9rem); color: #888; font-style: italic;">
Dec 15, Jun 15, Jun 18, Jun 22, Dec 22, Dec 23, Jun 24
</time>
            <span class="notes-indicator-icon" title="Notes added">📝</span>
        </summary>
        <div class="content">
            <h3>Level of Significance ($\alpha$)</h3>
            <p>The <strong>level of significance ($\alpha$)</strong>, also known as the alpha level, is a pre-determined probability threshold used in hypothesis testing. It represents the maximum acceptable probability of committing a Type I error, which is the error of incorrectly rejecting a true null hypothesis. Commonly set at 0.05 (5%) or 0.01 (1%), $\alpha$ defines the critical region in a sampling distribution. If the p-value (the probability of observing data as extreme as, or more extreme than, the sample data under the null hypothesis) is less than or equal to $\alpha$, the null hypothesis is rejected. A smaller $\alpha$ means a stricter criterion for rejecting the null hypothesis, reducing the chance of a Type I error but increasing the chance of a Type II error.</p>

            <h3>Linear vs. Non-linear Relationships</h3>
            <p>These terms describe the nature of the association between two variables, typically visualized on a scatter plot:</p>
            <ul>
                <li><strong>Linear Relationship:</strong> A linear relationship exists when the relationship between two variables can be best described by a straight line. As one variable increases or decreases, the other variable tends to consistently increase or decrease by a constant amount. This type of relationship is captured by statistical measures like Pearson's correlation coefficient and is fundamental to linear regression. On a scatter plot, the points would generally cluster around a straight line.</li>
                <li><strong>Non-linear Relationship:</strong> A non-linear relationship exists when the association between two variables cannot be accurately represented by a straight line. The change in one variable does not result in a constant proportional change in the other. These relationships can take various forms, such as curvilinear (U-shaped, inverted U-shaped), exponential, or logarithmic. Standard linear correlation coefficients might indicate a weak or no relationship even when a strong non-linear one exists. Specialized non-linear regression models are needed to describe such associations accurately.</li>
            </ul>

            <h3>Kurtosis</h3>
            <p><strong>Kurtosis</strong> is a statistical measure that describes the "tailedness" and peakedness of the probability distribution of a real-valued random variable. It indicates how much the tails of a distribution differ from the tails of a normal distribution. For a detailed explanation, including diagrams of leptokurtic, mesokurtic, and platykurtic distributions, please refer to the <a href="#card-normal-distribution-divergence">"Normal Distribution, Divergence, Skewness, Kurtosis"</a> section.</p>

            <h3>Tetrachoric Correlation</h3>
            <p>The <strong>tetrachoric correlation coefficient</strong> is a measure of association between two dichotomous variables that are assumed to underlie two continuous, normally distributed variables. It's used when both variables are artificially dichotomized (e.g., passing/failing a test based on a score cutoff, or healthy/unhealthy based on a physiological measure). It estimates what the Pearson product-moment correlation coefficient would be if the two dichotomous variables were actually continuous and normally distributed. Because it relies on assumptions about underlying continuous normal distributions, it's generally more complex to calculate and interpret than simpler correlation measures for dichotomous variables (like the phi coefficient).</p>

            <h3>Scatter Plot</h3>
            <p>A <strong>scatter plot</strong> (also called a scatter graph or scatter diagram) is a two-dimensional plot that displays the relationship between two quantitative variables. Each point on the plot represents a single observation from a dataset, with its position determined by the values of the two variables (one on the horizontal x-axis and the other on the vertical y-axis). Scatter plots are widely used in statistics to:</p>
            <ul>
                <li><strong>Visualize Relationships:</strong> Quickly show if there is a positive, negative, or no relationship between variables.</li>
                <li><strong>Identify Patterns:</strong> Reveal whether the relationship is linear or non-linear.</li>
                <li><strong>Detect Outliers:</strong> Easily spot data points that deviate significantly from the general trend.</li>
                <li><strong>Assess Strength of Relationship:</strong> Provide a visual sense of how tightly clustered the points are, indicating the strength of the correlation.</li>
            </ul>
            <p>They are a foundational tool for exploratory data analysis before applying more formal statistical tests.</p>

            <div class="button-group">
                <button class="copy-btn" onclick="copyText(this)">Copy Answer</button>
                <button class="status-btn" data-status-action="read" onclick="setQuestionStatus(this.closest('details'), 'read')">Mark as Read</button>
                <button class="status-btn" data-status-action="unread" onclick="setQuestionStatus(this.closest('details'), 'unread')">Mark as Unread</button>
                <button class="status-btn" data-status-action="doubt" onclick="setQuestionStatus(this.closest('details'), 'doubt')">Mark as Doubt</button>
                <button class="notes-card-btn" onclick="toggleNotes(this.closest('details'))">Add/View Notes</button>
            </div>
            <div class="notes-section">
                <textarea placeholder="Write your notes here..." oninput="saveNotes(this.closest('details'), this.value)"></textarea>
            </div>
        </div>
    </details>
</section>

<section class="topic-card" id="card-miscellaneous">
    <h2>MISCELLANEOUS</h2>

    <details data-status="unread">
        <span class="status-icon read" title="Read">✓</span>
        <span class="status-icon doubt" title="Doubt">!</span>
        <summary>
            <span>Describe scales of measurement with examples (Levels of Measurement).</span>
            <time class="ml-2 text-gray-500 dark:text-gray-400" style="white-space: nowrap; overflow: hidden; text-overflow: ellipsis; font-size: clamp(0.4rem, 1.7vw, 0.9rem); color: #888; font-style: italic;">
Jun 16, Dec 16, Dec 21, Dec 23
</time>
            <span class="notes-indicator-icon" title="Notes added">📝</span>
        </summary>
        <div class="content">
            <h3>Levels of Measurement (Scales of Measurement)</h3>
            <p>Levels of measurement, or scales of measurement, are ways to categorize and describe the nature of information within the values assigned to variables. Developed by Stanley Smith Stevens, these levels dictate what statistical analyses are appropriate for a given variable. There are four main levels:</p>

            <h4>1. Nominal Scale</h4>
            <ul>
                <li><strong>Definition:</strong> The nominal scale is the most basic level of measurement. It categorizes data into distinct, non-overlapping groups or labels, without any order or ranking implied. The numbers assigned are merely identifiers.</li>
                <li><strong>Characteristics:</strong>
                    <ul>
                        <li>Categorical (qualitative) data.</li>
                        <li>No order or ranking.</li>
                        <li>No numerical meaning (arithmetic operations are meaningless).</li>
                    </ul>
                </li>
                <li><strong>Examples:</strong>
                    <ul>
                        <li><strong>Gender:</strong> Male, Female, Non-binary.</li>
                        <li><strong>Eye Color:</strong> Blue, Brown, Green.</li>
                        <li><strong>Type of Car:</strong> Sedan, SUV, Hatchback.</li>
                        <li><strong>Religion:</strong> Christian, Muslim, Hindu, Buddhist.</li>
                    </ul>
                </li>
            </ul>

            <h4>2. Ordinal Scale</h4>
            <ul>
                <li><strong>Definition:</strong> The ordinal scale categorizes data into groups that have a meaningful order or ranking, but the intervals between the ranks are not necessarily equal or measurable. We know the relative position but not the magnitude of difference.</li>
                <li><strong>Characteristics:</strong>
                    <ul>
                        <li>Categorical (qualitative) data with order.</li>
                        <li>Ranks indicate relative position (e.g., higher or lower).</li>
                        <li>Differences between ranks are not uniform or meaningful.</li>
                    </ul>
                </li>
                <li><strong>Examples:</strong>
                    <ul>
                        <li><strong>Educational Level:</strong> High School, Bachelor's, Master's, PhD (PhD is higher than Bachelor's, but the "distance" isn't quantifiable).</li>
                        <li><strong>Likert Scales:</strong> Strongly Disagree, Disagree, Neutral, Agree, Strongly Agree.</li>
                        <li><strong>Socioeconomic Status:</strong> Low, Medium, High.</li>
                        <li><strong>Olympic Medals:</strong> Gold, Silver, Bronze.</li>
                    </ul>
                </li>
            </ul>

            <h4>3. Interval Scale</h4>
            <ul>
                <li><strong>Definition:</strong> The interval scale measures data where the order matters, and the differences between values are meaningful and consistent. However, it lacks a true zero point, meaning that a value of zero does not indicate the complete absence of the measured attribute. Ratios are not meaningful.</li>
                <li><strong>Characteristics:</strong>
                    <ul>
                        <li>Quantitative data with order.</li>
                        <li>Equal intervals between values.</li>
                        <li>No true zero point.</li>
                        <li>Arithmetic operations like addition and subtraction are meaningful, but multiplication and division are not (ratios are not valid).</li>
                    </ul>
                </li>
                <li><strong>Examples:</strong>
                    <ul>
                        <li><strong>Temperature in Celsius or Fahrenheit:</strong> The difference between 20°C and 30°C is the same as between 30°C and 40°C (10°C). However, 0°C does not mean no temperature, and 20°C is not "twice as hot" as 10°C.</li>
                        <li><strong>IQ Scores:</strong> The difference between an IQ of 100 and 110 is the same as between 110 and 120. An IQ of 0 doesn't imply "no intelligence."</li>
                        <li><strong>Years on a Calendar:</strong> The difference between 2000 AD and 2010 AD is 10 years, which is the same as the difference between 1990 AD and 2000 AD. However, year 0 doesn't mean "no time."</li>
                    </ul>
                </li>
            </ul>

            <h4>4. Ratio Scale</h4>
            <ul>
                <li><strong>Definition:</strong> The ratio scale is the highest level of measurement. It possesses all the characteristics of the interval scale, but it also has a meaningful and absolute true zero point, where zero indicates the complete absence of the measured attribute. This allows for all arithmetic operations, including meaningful ratios.</li>
                <li><strong>Characteristics:</strong>
                    <ul>
                        <li>Quantitative data with order.</li>
                        <li>Equal intervals between values.</li>
                        <li>Has a true zero point.</li>
                        <li>All arithmetic operations (addition, subtraction, multiplication, division) are meaningful, and ratios are valid.</li>
                    </ul>
                </li>
                <li><strong>Examples:</strong>
                    <ul>
                        <li><strong>Height:</strong> 0 cm means no height. 200 cm is twice as tall as 100 cm.</li>
                        <li><strong>Weight:</strong> 0 kg means no weight. 100 kg is twice as heavy as 50 kg.</li>
                        <li><strong>Age:</strong> 0 years means no age. A 60-year-old is twice as old as a 30-year-old.</li>
                        <li><strong>Income in USD:</strong> 0 USD means no income. $100 is half of $200.</li>
                        <li><strong>Number of items:</strong> 0 items means no items.</li>
                    </ul>
                </li>
            </ul>
            <p>Choosing the correct level of measurement is fundamental because it determines the types of statistical analyses that can be validly applied to the data. Using inappropriate statistics for a given level of measurement can lead to inaccurate conclusions.</p>

            <div class="button-group">
                <button class="copy-btn" onclick="copyText(this)">Copy Answer</button>
                <button class="status-btn" data-status-action="read" onclick="setQuestionStatus(this.closest('details'), 'read')">Mark as Read</button>
                <button class="status-btn" data-status-action="unread" onclick="setQuestionStatus(this.closest('details'), 'unread')">Mark as Unread</button>
                <button class="status-btn" data-status-action="doubt" onclick="setQuestionStatus(this.closest('details'), 'doubt')">Mark as Doubt</button>
                <button class="notes-card-btn" onclick="toggleNotes(this.closest('details'))">Add/View Notes</button>
            </div>
            <div class="notes-section">
                <textarea placeholder="Write your notes here..." oninput="saveNotes(this.closest('details'), this.value)"></textarea>
            </div>
        </div>
    </details>

    <details data-status="unread">
        <span class="status-icon read" title="Read">✓</span>
        <span class="status-icon doubt" title="Doubt">!</span>
        <summary>
            <span>Explain interactional effect. Discuss merits and demerits of two-way ANOVA.</span>
            <time class="ml-2 text-gray-500 dark:text-gray-400" style="white-space: nowrap; overflow: hidden; text-overflow: ellipsis; font-size: clamp(0.4rem, 1.7vw, 0.9rem); color: #888; font-style: italic;">
Jun 17, Dec 18, Jun 24
</time>
            <span class="notes-indicator-icon" title="Notes added">📝</span>
        </summary>
        <div class="content">
            <h3>Interactional Effect (Interaction Effect)</h3>
            <p>In statistics, particularly within the context of ANOVA (Analysis of Variance), an <strong>interactional effect</strong> (or interaction effect) occurs when the effect of one independent variable (factor) on the dependent variable changes depending on the level of another independent variable. In simpler terms, the combined effect of two or more independent variables is different from the sum of their individual effects.</p>
            <p>If there is no interaction, the effect of one factor is consistent across all levels of the other factor. If an interaction exists, the main effects (individual effects of each factor) cannot be interpreted independently, because their impact is not uniform across all conditions created by the other factor.</p>
            <p><strong>Example:</strong>
                Imagine studying the effect of a new fertilizer (Factor A: with fertilizer vs. without fertilizer) and different soil types (Factor B: Sandy vs. Clay) on crop yield.
                <ul>
                    <li><strong>No Interaction:</strong> If the fertilizer increases yield by 10 units on both sandy and clay soil, there's no interaction. The effect of fertilizer is consistent regardless of soil type.</li>
                    <li><strong>Interaction:</strong> If the fertilizer significantly increases yield on sandy soil, but has little to no effect, or even a negative effect, on clay soil, then there is an interaction. The effect of the fertilizer depends on the soil type.</li>
                </ul>
            </p>

            <h3>Two-Way ANOVA</h3>
            <p>A <strong>Two-Way ANOVA (Analysis of Variance)</strong> is a statistical test used to analyze the effect of two categorical independent variables (factors) on a continuous dependent variable. It allows researchers to assess the main effects of each independent variable and, crucially, the interaction effect between them.</p>

            <h4>Merits (Advantages) of Two-Way ANOVA:</h4>
            <ol>
                <li><strong>Efficiency:</strong> It is more efficient than conducting multiple one-way ANOVAs. Instead of running separate tests for each factor, a single two-way ANOVA can analyze both main effects and their interaction simultaneously. This saves time and reduces the risk of inflating Type I error rates that would occur from multiple comparisons.</li>
                <li><strong>Detection of Interaction Effects:</strong> Its primary advantage is the ability to detect and quantify interaction effects. This allows researchers to understand complex relationships where the effect of one variable is conditional on another, providing a more nuanced and realistic understanding of the phenomenon.</li>
                <li><strong>Increased Statistical Power:</strong> By accounting for the variance explained by a second factor, two-way ANOVA can reduce the error variance, thereby increasing the statistical power to detect true main effects and interaction effects compared to separate one-way ANOVAs.</li>
                <li><strong>Comprehensive Analysis:</strong> It provides a more complete picture of the relationships between variables, exploring not just individual impacts but also their combined influence.</li>
                <li><strong>Reduces Residual Variance:</strong> By including more factors that explain variation in the dependent variable, the unexplained (residual) variance is reduced, which can make the test more sensitive.</li>
            </ol>

            <h4>Demerits (Disadvantages) of Two-Way ANOVA:</h4>
            <ol>
                <li><strong>Complexity of Interpretation:</strong> When a significant interaction effect is present, interpreting the main effects can be misleading or impossible. The interaction effect often overrides the main effects, requiring more complex post-hoc analyses and conditional interpretations.</li>
                <li><strong>Assumptions:</strong> Like one-way ANOVA, it has assumptions (normality of residuals, homogeneity of variances, independence of observations) that must be met. Violations can lead to inaccurate results. Testing these assumptions becomes more complex with more factors.</li>
                <li><strong>Increased Sample Size Requirements:</strong> To adequately detect interaction effects, especially subtle ones, a larger total sample size is often required compared to a one-way ANOVA. Each cell (combination of factor levels) needs sufficient observations.</li>
                <li><strong>Difficulty with More Factors:</strong> While a "Two-Way" ANOVA is manageable, extending to three-way or higher-order ANOVAs becomes increasingly complex to interpret, especially with multiple interaction terms. Visualizing higher-order interactions is also challenging.</li>
                <li><strong>Post-Hoc Tests:</strong> If a main effect or interaction effect is significant, further post-hoc tests are often required to pinpoint specific differences between groups or conditions, adding another layer of complexity to the analysis.</li>
            </ol>

            <div class="button-group">
                <button class="copy-btn" onclick="copyText(this)">Copy Answer</button>
                <button class="status-btn" data-status-action="read" onclick="setQuestionStatus(this.closest('details'), 'read')">Mark as Read</button>
                <button class="status-btn" data-status-action="unread" onclick="setQuestionStatus(this.closest('details'), 'unread')">Mark as Unread</button>
                <button class="status-btn" data-status-action="doubt" onclick="setQuestionStatus(this.closest('details'), 'doubt')">Mark as Doubt</button>
                <button class="notes-card-btn" onclick="toggleNotes(this.closest('details'))">Add/View Notes</button>
            </div>
            <div class="notes-section">
                <textarea placeholder="Write your notes here..." oninput="saveNotes(this.closest('details'), this.value)"></textarea>
            </div>
        </div>
    </details>

    <details data-status="unread">
        <span class="status-icon read" title="Read">✓</span>
        <span class="status-icon doubt" title="Doubt">!</span>
        <summary>
            <span>Explain organisation of data.</span>
            <time class="ml-2 text-gray-500 dark:text-gray-400" style="white-space: nowrap; overflow: hidden; text-overflow: ellipsis; font-size: clamp(0.4rem, 1.7vw, 0.9rem); color: #888; font-style: italic;">
Dec 23
</time>
            <span class="notes-indicator-icon" title="Notes added">📝</span>
        </summary>
        <div class="content">
            <h3>Organisation of Data</h3>
            <p><strong>Organisation of data</strong> refers to the process of arranging raw data into a structured and logical format to make it more comprehensible, manageable, and suitable for analysis and interpretation. Raw data, collected directly from surveys, experiments, observations, or other sources, is often messy, unclassified, and difficult to derive insights from. Effective data organization is the crucial first step in any statistical or data analysis process.</p>

            <h4>Purpose and Importance of Data Organisation:</h4>
            <ol>
                <li><strong>Simplifies Understanding:</strong> Makes large volumes of data easier to grasp and understand at a glance.</li>
                <li><strong>Facilitates Analysis:</strong> Puts data into a format that allows for the application of statistical methods, calculations, and software.</li>
                <li><strong>Identifies Errors/Missing Data:</strong> Organized data makes it easier to spot inconsistencies, outliers, or missing values that need correction.</li>
                <li><strong>Aids Interpretation:</strong> Well-organized data leads to clearer visualizations and more straightforward interpretation of findings.</li>
                <li><strong>Supports Decision Making:</strong> Provides a foundation for evidence-based decision-making.</li>
                <li><strong>Ensures Reproducibility:</strong> A structured approach ensures that the analysis can be reproduced and verified by others.</li>
            </ol>

            <h4>Key Methods and Formats for Data Organisation:</h4>
            <p>Data can be organized in various ways depending on its nature and the goals of the analysis:</p>
            <ol>
                <li><strong>Categorization and Classification:</strong>
                    <ul>
                        <li>Grouping raw data into distinct categories or classes based on shared characteristics.</li>
                        <li><strong>Example:</strong> Grouping survey respondents by age groups (e.g., 18-25, 26-35) or income brackets.</li>
                    </ul>
                </li>
                <li><strong>Tabulation:</strong>
                    <ul>
                        <li>Presenting data in rows and columns, typically in tables. This is one of the most common and fundamental methods.</li>
                        <li><strong>Types of Tables:</strong>
                            <ul>
                                <li><strong>Simple Frequency Distribution:</strong> Lists each value or category and its corresponding frequency (how many times it appears).</li>
                                <li><strong>Grouped Frequency Distribution:</strong> Data is grouped into class intervals (ranges) and frequencies are counted for each interval. Useful for large datasets of continuous variables.</li>
                                <li><strong>Contingency Tables (Cross-tabulations):</strong> Used for two or more categorical variables to show the joint frequency distribution. (e.g., as seen in Chi-square test).</li>
                            </ul>
                        </li>
                        <li><strong>Example (Simple Frequency Distribution):</strong>
                            <table class="table-auto w-full text-left whitespace-no-wrap">
                                <thead>
                                    <tr>
                                        <th class="px-4 py-3 title-font tracking-wider font-medium text-gray-900 text-sm bg-gray-100">Score</th>
                                        <th class="px-4 py-3 title-font tracking-wider font-medium text-gray-900 text-sm bg-gray-100">Frequency</th>
                                    </tr>
                                </thead>
                                <tbody>
                                    <tr><td class="px-4 py-3">10</td><td class="px-4 py-3">5</td></tr>
                                    <tr><td class="px-4 py-3">12</td><td class="px-4 py-3">8</td></tr>
                                    <tr><td class="px-4 py-3">15</td><td class="px-4 py-3">3</td></tr>
                                </tbody>
                            </table>
                        </li>
                    </ul>
                </li>
                <li><strong>Chronological/Time Series Organisation:</strong>
                    <ul>
                        <li>Arranging data according to time (e.g., daily sales, monthly temperature).</li>
                        <li><strong>Example:</strong> Stock prices listed by date.</li>
                    </ul>
                </li>
                <li><strong>Alphabetical Organisation:</strong>
                    <ul>
                        <li>Arranging textual data alphabetically.</li>
                        <li><strong>Example:</strong> List of cities, names of participants.</li>
                    </ul>
                </li>
                <li><strong>Geographical Organisation:</strong>
                    <ul>
                        <li>Arranging data by location (e.g., sales per region, population by country).</li>
                        <li><strong>Example:</strong> Census data presented by state or district.</li>
                    </ul>
                </li>
                <li><strong>Ranking:</strong>
                    <ul>
                        <li>Ordering data from smallest to largest or vice-versa (e.g., student grades, income levels).</li>
                        <li><strong>Example:</strong> Listing students by their performance ranks.</li>
                    </ul>
                </li>
                <li><strong>Data Structuring (for databases/spreadsheets):</strong>
                    <ul>
                        <li>Organizing data into rows (records/observations) and columns (variables/fields) in a spreadsheet (like Excel) or a database management system (like SQL). Each row typically represents an individual entity, and each column represents an attribute of that entity.</li>
                        <li>This is the most common format for quantitative data analysis.</li>
                    </ul>
                </li>
            </ol>
            <p>Before any sophisticated statistical analysis can be performed, data must be systematically organized, cleaned, and prepared. This foundational step ensures the reliability and validity of subsequent analyses and the conclusions drawn from them.</p>

            <div class="button-group">
                <button class="copy-btn" onclick="copyText(this)">Copy Answer</button>
                <button class="status-btn" data-status-action="read" onclick="setQuestionStatus(this.closest('details'), 'read')">Mark as Read</button>
                <button class="status-btn" data-status-action="unread" onclick="setQuestionStatus(this.closest('details'), 'unread')">Mark as Unread</button>
                <button class="status-btn" data-status-action="doubt" onclick="setQuestionStatus(this.closest('details'), 'doubt')">Mark as Doubt</button>
                <button class="notes-card-btn" onclick="toggleNotes(this.closest('details'))">Add/View Notes</button>
            </div>
            <div class="notes-section">
                <textarea placeholder="Write your notes here..." oninput="saveNotes(this.closest('details'), this.value)"></textarea>
            </div>
        </div>
    </details>
</section>








</section>



  </main>   

  <footer>
    <p>&copy; 2025 Psych Lab. For the curious mind.</p>
  </footer>

  <button class="floating-btn floating-notes-btn" id="open-notes-floater-btn" onclick="toggleFloater('notes')">📚 Notes</button>
  <button class="floating-btn floating-stats-btn" id="open-stats-floater-btn" onclick="toggleFloater('stats')">📊 Progress</button>


  <div class="floater notes-floater" id="notes-floater">
    <div class="floater-header">
      <span>Your Saved Notes</span>
      <button class="floater-close" onclick="toggleFloater('notes')">✖️</button>
    </div>
    <div class="floater-content" id="notes-floater-content">
      <p style="text-align: center; color: var(--text-dark);">No notes saved yet.</p>
    </div>
  </div>

  <div class="floater stats-floater" id="stats-floater">
    <div class="floater-header">
      <span>Learning Progress</span>
      <button class="floater-close" onclick="toggleFloater('stats')">✖️</button>
    </div>
    <div class="floater-content stats-floater-content" id="stats-floater-content">
        <h4>Overview</h4>
        <div class="pie-chart"></div>
        <ul class="stats-legend">
            <li><span class="legend-color-box read"></span> Read: <span id="read-count">0</span> (<span id="read-percent">0%</span>)</li>
            <li><span class="legend-color-box doubt"></span> Doubt: <span id="doubt-count">0</span> (<span id="doubt-percent">0%</span>)</li>
            <li><span class="legend-color-box unread"></span> Unread: <span id="unread-count">0</span> (<span id="unread-percent">0%</span>)</li>
        </ul>
    </div>
  </div>


  <script>
     
    let activeTooltip = null;
    let tooltipTimeout = null;

    function isTextTruncated(element) {
        return element.scrollWidth > element.clientWidth;
    }

    function hideTooltip() {
        if (activeTooltip) {
            activeTooltip.classList.remove('is-visible');
            activeTooltip.addEventListener('transitionend', function handler() {
                activeTooltip.remove();
                activeTooltip = null;
                activeTooltip.removeEventListener('transitionend', handler);
            }, { once: true });
        }
        if (tooltipTimeout) {
            clearTimeout(tooltipTimeout);
            tooltipTimeout = null;
        }
        document.removeEventListener('click', handleOutsideClick);
    }

    function handleOutsideClick(event) {
        if (activeTooltip && !activeTooltip.contains(event.target) && !event.target.closest('time')) {
            hideTooltip();
        }
    }

    function showTooltip(timeElement) {
        hideTooltip();

        const fullText = timeElement.textContent;

        activeTooltip = document.createElement('div');
        activeTooltip.classList.add('time-tooltip');
        activeTooltip.textContent = fullText;

        const rect = timeElement.getBoundingClientRect();
        activeTooltip.style.position = 'absolute';
        activeTooltip.style.left = `${rect.left + window.scrollX}px`;
        activeTooltip.style.top = `${rect.bottom + window.scrollY + 8}px`;
        activeTooltip.style.zIndex = '10000';

        document.body.appendChild(activeTooltip);

        activeTooltip.offsetHeight;
        activeTooltip.classList.add('is-visible');

        tooltipTimeout = setTimeout(() => {
            hideTooltip();
        }, 1400);

        document.addEventListener('click', handleOutsideClick);
    }
    // Utility function to sanitize text for use as a localStorage key
    // Replaces non-alphanumeric with dashes and converts to lowercase
    function sanitizeForLS(text) {
        return text.trim().toLowerCase().replace(/[^a-z0-9]+/g, '-').replace(/^-+|-+$/g, '');
    }

    // --- Global Floater Management ---
    const floaters = {
        notes: {
            element: document.getElementById('notes-floater'),
            openButton: document.getElementById('open-notes-floater-btn')
        },
        stats: {
            element: document.getElementById('stats-floater'),
            openButton: document.getElementById('open-stats-floater-btn')
        }
    };

    function toggleFloater(floaterType) {
        const targetFloater = floaters[floaterType].element;

        // Close any other open floater
        for (const key in floaters) {
            if (key !== floaterType && floaters[key].element.classList.contains('open')) {
                floaters[key].element.classList.remove('open');
                floaters[key].element.classList.remove('translucent');
            }
        }

        if (targetFloater.classList.contains('open')) {
            targetFloater.classList.remove('open');
            targetFloater.classList.remove('translucent'); // Reset translucency when closing
        } else {
            targetFloater.classList.add('open');
            targetFloater.classList.remove('translucent'); // Ensure solid when opening
            if (floaterType === 'notes') {
                loadNotesIntoFloater(); // Load notes when notes floater is opened
            } else if (floaterType === 'stats') {
                updateStatsAndChart(); // Ensure stats are fresh when stats floater is opened
            }
        }
    }

    // Event listener for clicks anywhere on the document to control floater translucency
    document.addEventListener('click', (event) => {
        for (const floaterType in floaters) {
            const floater = floaters[floaterType].element;
            const openButton = floaters[floaterType].openButton;

            const isClickInsideFloater = floater.contains(event.target);
            const isClickOnOpenButton = openButton.contains(event.target);
            const isFloaterOpen = floater.classList.contains('open');

            if (isFloaterOpen) {
                if (!isClickInsideFloater && !isClickOnOpenButton) {
                    // Clicked outside the floater and not on its open button
                    floater.classList.add('translucent');
                } else if (isClickInsideFloater && floater.classList.contains('translucent')) {
                    // Clicked inside the translucent floater, make it solid
                    floater.classList.remove('translucent');
                }
            }
        }
    });

    // --- Theme Toggling Logic ---
    function toggleTheme() {
      document.body.classList.toggle('dark');
      localStorage.setItem('theme', document.body.classList.contains('dark') ? 'dark' : 'light');
    }

    // Apply saved theme or system preference on load
    if (localStorage.getItem('theme') === 'dark' ||
        (!localStorage.getItem('theme') && window.matchMedia('(prefers-color-scheme: dark)').matches)) {
      document.body.classList.add('dark');
    }

    // --- Question Status Management (Read, Unread, Doubt) ---
    // This function now accepts the 'details' element directly
    function setQuestionStatus(questionDetails, status) {
        if (!questionDetails) return;

        // Get the summary text to use as a unique key for local storage
        const questionSummary = questionDetails.querySelector('summary span:first-child').textContent.trim();
        const storageKey = `question-status-${sanitizeForLS(questionSummary)}`;

        // Update data-status attribute and local storage
        questionDetails.setAttribute('data-status', status);
        localStorage.setItem(storageKey, status);

        // Update button visibility for the current question
        const statusButtons = questionDetails.querySelectorAll('.status-btn');
        statusButtons.forEach(btn => {
            if (btn.dataset.statusAction === status) {
                btn.style.display = 'none'; // Hide the button if it's the current active status
            } else {
                btn.style.display = 'inline-block'; // Show other status buttons
            }
        });

        // Update status icons visibility
        questionDetails.querySelectorAll('.status-icon').forEach(icon => icon.style.display = 'none'); // Hide all first
        if (status === 'read') {
            questionDetails.querySelector('.status-icon.read').style.display = 'block';
            showNotification('Question marked as Read!');
        } else if (status === 'doubt') {
            questionDetails.querySelector('.status-icon.doubt').style.display = 'block';
            showNotification('Question marked as Doubt!');
        } else { // 'unread'
            showNotification('Question marked as Unread!');
        }

        updateStatsAndChart(); // Recalculate and redraw chart immediately
    }

    document.addEventListener('DOMContentLoaded', () => {
        initializeQuestions();
        updateStatsAndChart();

        // Ensure the helper functions (isTextTruncated, showTooltip, etc.)
        // are defined globally or before this block for this code to work.
        document.querySelectorAll('summary time').forEach(timeElement => {
            timeElement.style.cursor = 'pointer';

            timeElement.addEventListener('click', function(event) {
                event.stopPropagation();

                if (isTextTruncated(this)) {
                    showTooltip(this);
                }
            });
        });
    });

    function initializeQuestions() {
        // Select all 'details' elements that are assumed to be questions
        document.querySelectorAll('details').forEach(questionDetails => {
            const questionSummary = questionDetails.querySelector('summary span:first-child').textContent.trim();
            const statusStorageKey = `question-status-${sanitizeForLS(questionSummary)}`;
            const notesStorageKey = `question-notes-${sanitizeForLS(questionSummary)}`;

            // Load and apply saved status
            const savedStatus = localStorage.getItem(statusStorageKey);
            if (savedStatus) {
                // Call setQuestionStatus to apply UI changes and hide relevant button
                setQuestionStatus(questionDetails, savedStatus);
            } else {
                // If no status saved, ensure default 'unread' is set and its button is hidden
                questionDetails.setAttribute('data-status', 'unread');
                const unreadButton = questionDetails.querySelector('.status-btn[data-status-action="unread"]');
                if (unreadButton) unreadButton.style.display = 'none';
            }

            // Load saved notes and update notes indicator
            const savedNotes = localStorage.getItem(notesStorageKey);
            const notesTextarea = questionDetails.querySelector('.notes-section textarea');
            const notesCardButton = questionDetails.querySelector('.notes-card-btn');
            const notesIndicatorIcon = questionDetails.querySelector('.notes-indicator-icon');

            if (notesTextarea && savedNotes !== null) { // Check for null explicitly as empty string is valid
                notesTextarea.value = savedNotes;
                if (savedNotes.trim() !== '') {
                    notesCardButton.classList.add('saved');
                    notesCardButton.textContent = 'Notes Saved';
                    notesIndicatorIcon.style.display = 'inline-block'; // Show indicator if notes exist
                }
            }
        });
    }

    // --- Details Tag (Dropdown) Behavior ---
    // This now closes other questions *within the same topic card* when one is opened
    document.querySelectorAll('.topic-card details').forEach(details => {
        details.addEventListener('toggle', () => {
            if (details.open) {
                // Close other open details elements within the same parent topic-card
                details.closest('.topic-card').querySelectorAll('details').forEach(otherDetails => {
                    if (otherDetails !== details && otherDetails.open) {
                        otherDetails.open = false;
                    }
                });
            }
        });
    });

    // --- Search / Filter Functionality ---
    function filterContent(query) {
      const lowerCaseQuery = query.toLowerCase();

      document.querySelectorAll('.topic-card').forEach(card => {
        let cardHasVisibleQuestions = false;
        // Iterate through each question within the topic card
        card.querySelectorAll('details').forEach(questionDetails => {
          // Search in question summary and its content
          const text = questionDetails.textContent.toLowerCase();
          if (text.includes(lowerCaseQuery)) {
            questionDetails.style.display = ''; // Show question
            cardHasVisibleQuestions = true;
          } else {
            questionDetails.style.display = 'none'; // Hide question
          }
        });

        // Hide the entire topic card if none of its questions are visible and the topic title doesn't match
        const topicTitle = card.querySelector('h2');
        if (topicTitle && topicTitle.textContent.toLowerCase().includes(lowerCaseQuery)) {
            card.style.display = ''; // Show card if title matches, regardless of questions
        } else {
            card.style.display = cardHasVisibleQuestions ? '' : 'none';
        }
      });
    }


    // --- Copy Text Functionality ---
    // This function now accepts the button element directly
    function copyText(buttonElement) {
      const contentDiv = buttonElement.closest('.content');
      const tempDiv = document.createElement('div');
      tempDiv.innerHTML = contentDiv.innerHTML;

      // Remove non-content elements before copying
      tempDiv.querySelectorAll('.button-group, .notes-section').forEach(el => el.remove());

      const textToCopy = tempDiv.textContent.trim();

      if (navigator.clipboard) {
        navigator.clipboard.writeText(textToCopy)
          .then(() => {
            showNotification('Copied to clipboard!');
          })
          .catch(err => {
            console.error('Failed to copy text: ', err);
            showNotification('Copy failed!', true);
          });
      } else {
        // Fallback for browsers without navigator.clipboard
        const tempTextArea = document.createElement('textarea');
        tempTextArea.value = textToCopy;
        document.body.appendChild(tempTextArea);
        tempTextArea.select();
        try {
          document.execCommand('copy');
          showNotification('Copied to clipboard!');
        } catch (err) {
          console.error('Fallback copy failed: ', err);
          showNotification('Copy failed!', true);
        }
        document.body.removeChild(tempTextArea);
      }
    }

    // --- Notification Pop-up Function ---
    function showNotification(message, isError = false) {
      const notification = document.createElement('div');
      notification.className = 'notification';
      notification.style.backgroundColor = isError ? '#E74C3C' : '#2ECC71';
      notification.textContent = message;
      document.body.appendChild(notification);

      // Trigger reflow to ensure transition runs
      void notification.offsetWidth;

      notification.classList.add('show'); // Use class to trigger transition
      setTimeout(() => {
        notification.classList.remove('show'); // Fade out
        setTimeout(() => notification.remove(), 400); // Remove after transition
      }, 2500); // Display duration
    }

    // --- Notes Management within Question Details ---
    // This function now accepts the 'details' element directly
    function toggleNotes(questionDetails) {
        const notesSection = questionDetails.querySelector('.notes-section');
        const notesTextarea = notesSection.querySelector('textarea');
        const notesCardButton = questionDetails.querySelector('.notes-card-btn');

        if (notesSection.style.display === 'block') {
            notesSection.style.display = 'none';
            // If notes are empty when closed, reset button state
            if (notesTextarea.value.trim() === '') {
                notesCardButton.classList.remove('saved');
                notesCardButton.textContent = 'Add/View Notes';
            }
        } else {
            notesSection.style.display = 'block';
            notesTextarea.focus(); // Focus on textarea when opened
            // Update button text/class based on current content
            if (notesTextarea.value.trim() !== '') {
                 notesCardButton.classList.add('saved');
                 notesCardButton.textContent = 'Notes Saved';
            } else {
                 notesCardButton.classList.remove('saved');
                 notesCardButton.textContent = 'Add/View Notes';
            }
        }
    }

    // This function now accepts the 'details' element directly
    function saveNotes(questionDetails, notesContent) {
        const questionSummary = questionDetails.querySelector('summary span:first-child').textContent.trim();
        const storageKey = `question-notes-${sanitizeForLS(questionSummary)}`;

        localStorage.setItem(storageKey, notesContent);
        const notesCardButton = questionDetails.querySelector('.notes-card-btn');
        const notesIndicatorIcon = questionDetails.querySelector('.notes-indicator-icon');

        if (notesContent.trim() !== '') {
            notesCardButton.classList.add('saved');
            notesCardButton.textContent = 'Notes Saved';
            notesIndicatorIcon.style.display = 'inline-block'; // Show indicator
            showNotification('Note saved!');
        } else {
            notesCardButton.classList.remove('saved');
            notesCardButton.textContent = 'Add/View Notes';
            notesIndicatorIcon.style.display = 'none'; // Hide indicator if notes are cleared
            showNotification('Note cleared!');
        }
        // If the floating notes window is open, update its content immediately
        if (floaters.notes.element.classList.contains('open')) {
            loadNotesIntoFloater();
        }
    }

    // --- Real-time Pie Chart Logic ---
    function updateStatsAndChart() {
        let readCount = 0;
        let doubtCount = 0;
        let unreadCount = 0;
        // Select all 'details' elements that are questions
        const allQuestions = document.querySelectorAll('details');
        const totalQuestions = allQuestions.length;

        // Count questions by status
        allQuestions.forEach(questionDetails => {
            const status = questionDetails.getAttribute('data-status');
            if (status === 'read') {
                readCount++;
            } else if (status === 'doubt') {
                doubtCount++;
            } else { // default or 'unread'
                unreadCount++;
            }
        });

        // Calculate percentages
        const readPercent = totalQuestions > 0 ? (readCount / totalQuestions * 100) : 0;
        const doubtPercent = totalQuestions > 0 ? (doubtCount / totalQuestions * 100) : 0;
        const unreadPercent = totalQuestions > 0 ? (unreadCount / totalQuestions * 100) : 0;

        // Correct for potential floating point sum errors for display, ensuring total is 100%
        const sumPercents = readPercent + doubtPercent + unreadPercent;
        const factor = sumPercents > 0 ? 100 / sumPercents : 0;
        const finalReadPercent = readPercent * factor;
        const finalDoubtPercent = doubtPercent * factor;
        const finalUnreadPercent = unreadPercent * factor;


        // Update textual display in the stats floater
        document.getElementById('read-count').textContent = readCount;
        document.getElementById('doubt-count').textContent = doubtCount;
        document.getElementById('unread-count').textContent = unreadCount;

        document.getElementById('read-percent').textContent = `${finalReadPercent.toFixed(1)}%`;
        document.getElementById('doubt-percent').textContent = `${finalDoubtPercent.toFixed(1)}%`;
        document.getElementById('unread-percent').textContent = `${finalUnreadPercent.toFixed(1)}%`;

        // Update CSS variables for conic-gradient
        const pieChart = document.querySelector('.pie-chart');
        if (pieChart) {
            pieChart.style.setProperty('--read-percentage', `${finalReadPercent}%`);
            pieChart.style.setProperty('--doubt-percentage', `${finalDoubtPercent}%`);
        }
    }

    // --- Load Notes into Floating Notes Window ---
    function loadNotesIntoFloater() {
        const notesFloaterContent = document.getElementById('notes-floater-content');
        notesFloaterContent.innerHTML = ''; // Clear previous notes

        let hasNotes = false;
        // Iterate through all items in local storage
        for (let i = 0; i < localStorage.length; i++) {
            const key = localStorage.key(i);
            if (key.startsWith('question-notes-')) {
                const sanitizedSummary = key.replace('question-notes-', '');
                const savedNotes = localStorage.getItem(key);

                if (savedNotes && savedNotes.trim() !== '') {
                    hasNotes = true;
                    // Attempt to reconstruct original summary for display
                    // This is imperfect but works for display purposes
                    const displaySummary = sanitizedSummary.replace(/-/g, ' ').split(' ').map(word => word.charAt(0).toUpperCase() + word.slice(1)).join(' ');

                    const noteItem = document.createElement('div');
                    noteItem.classList.add('note-item');
                    // Store the sanitized summary to locate the question later
                    noteItem.dataset.questionSummary = sanitizedSummary;
                    noteItem.innerHTML = `<h4>${displaySummary}</h4><p>${savedNotes}</p>`;
                    notesFloaterContent.appendChild(noteItem);
                }
            }
        }

        if (!hasNotes) {
            notesFloaterContent.innerHTML = '<p style="text-align: center; color: var(--text-dark);">No notes saved yet.</p>';
        }
    }

    // --- Click handler for notes in floater to scroll to question ---
    document.getElementById('notes-floater-content').addEventListener('click', function(event) {
        const noteItem = event.target.closest('.note-item');
        if (noteItem) {
            const targetSummarySanitized = noteItem.dataset.questionSummary;
            if (targetSummarySanitized) {
                // Find the corresponding details element
                let foundQuestion = null;
                document.querySelectorAll('details').forEach(details => {
                    const questionSummary = details.querySelector('summary span:first-child').textContent.trim();
                    if (sanitizeForLS(questionSummary) === targetSummarySanitized) {
                        foundQuestion = details;
                    }
                });

                if (foundQuestion) {
                    // Close notes floater
                    toggleFloater('notes');

                    // Close any other open details elements first for better UX
                    document.querySelectorAll('details[open]').forEach(openDetails => {
                        if (openDetails !== foundQuestion) {
                            openDetails.open = false;
                        }
                    });

                    // Open the target question
                    foundQuestion.open = true;

                    // Scroll to the target question
                    foundQuestion.scrollIntoView({
                        behavior: 'smooth',
                        block: 'start'
                    });

                    // Temporarily highlight the question
                    foundQuestion.classList.add('highlighted');
                    setTimeout(() => {
                        foundQuestion.classList.remove('highlighted');
                    }, 2000); // Highlight for 2 seconds
                }
            }
        }
    });

  </script>
</body>
</html>
